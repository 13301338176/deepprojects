{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.1.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import string\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# keras architecture visualization\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Keras version: %s' % keras.__version__)\n",
    "\n",
    "PATH = \"data/aclImdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read files in the given tree, using subfolders as the target classes\n",
    "def read_files(folder, subfolders):\n",
    "    corpus, labels = [], []\n",
    "    for index, label in enumerate(subfolders):\n",
    "        path = '/'.join([folder, label, '*.txt'])\n",
    "        for filename in glob.glob(path):\n",
    "            corpus.append(open(filename, 'r').read())\n",
    "            labels.append(index)\n",
    "    return corpus, np.array(labels).astype(np.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coprus_train_pos = [open(filename, 'r').read() for filename in glob.glob(PATH + '/train/pos/*.txt')]\n",
    "#coprus_train_neg = [open(filename, 'r').read() for filename in glob.glob(PATH + '/train/neg/*.txt')]\n",
    "corpus_train, y_train = read_files(PATH + '/train', ['neg', 'pos'])\n",
    "corpus_test, y_test = read_files(PATH + '/test', ['neg', 'pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,\n",
       " 25000,\n",
       " 'Hi, Everyone, If you saw \"Singing in the Rain,\" you remember the scene of Gene Kelly dancing in the rain. You also remember the dance number of Donald O\\'Connor, \"Make \\'em Laugh.\" If you saw \"Royal Wedding,\" you will remember Fred Astaire dancing on the ceiling. If you saw \"Jailhouse Rock,\" you will even remember the title dance number choreographed by The King himself.<br /><br />That is what is missing here. There could have been some blockbuster dance numbers in this presentation. The closest was Chuck McGowan\\'s \"I Can Do That.\" the mere fact that you have some talented people on stage moving together does not make a great dance film. Richard Attenborough was to blame for this failure. He pointed the camera at the stage and thought that would be a good thing.<br /><br />Yelling at people auditioning for a part in a Broadway production is not entertainment. Michael Douglas would be just as badly cast if he were in a Western or a comedy. He is OK when he is in a Michael Douglas movie where we see him yelling at someone we would like to yell at. It does not work here.<br /><br />The cast was good except for Michael, of course. A good movie could have been made even using the songs that were in the stage production, but someone should have thought about how to film it.<br /><br />Next time they do one of these I hope they call me first.<br /><br />Tom Willett',\n",
       " 0,\n",
       " 'One of the very best Three Stooges shorts ever. A spooky house full of evil guys and \"The Goon\" challenge the Alert Detective Agency\\'s best men. Shemp is in top form in the famous in-the-dark scene. Emil Sitka provides excellent support in his Mr. Goodrich role, as the target of a murder plot. Before it\\'s over, Shemp\\'s \"trusty little shovel\" is employed to great effect. This 16 minute gem moves about as fast as any Stooge\\'s short and packs twice the wallop. Highly recommended.',\n",
       " 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_train), len(y_train), corpus_train[0], y_train[0], corpus_train[24999], y_train[24999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,\n",
       " 25000,\n",
       " 'Yes, in this movie you are treated to multiple little snowmen on the attack in apparently a very warm climate so yes this movie is definitely not to be taken seriously. It is in fact a much worse movie than the original as at least with that one the whole production looked like it cost more than a couple of bucks and a video camera to make. It has its funny moments, but really playing off the cheapness of your movie and making that be your intended laughs is kind of weak film making if you ask me. You can not come up with a good story, your effects are going to really be bad, hey let us just make the movie look as bad as possible with horrible one liners and we have our movie. The first one at least had a somewhat credible story as the snowman in that one attacked during the winter and not what amounts to a resort. It also had better effects too, this one is just a step or two ahead of \"Hobgoblins\" as far as the monsters are concerned and you really want to be more than a step a two above a bunch of hand puppets. Still, it makes up for all of this with a super ending that depicts a great sea vessel being taken out by the mighty frost. Actually, I am just kidding, but really it was the funniest part of the movie.',\n",
       " 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_test), len(y_test), corpus_test[0], y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorizing training/test sequence data.\n",
    "class Vectorizer():\n",
    "    def __init__(self, vocab_size, max_len):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_len = max_len\n",
    "        # init tokenizer\n",
    "        self.tokenizer = Tokenizer(num_words=vocab_size)\n",
    "\n",
    "    # this is old don't use this\n",
    "    def __tranform(self, corpus):\n",
    "        sequences, lengths = [], []\n",
    "        # transform word sequences into indices sequences\n",
    "        for sentence in tqdm(corpus_train):\n",
    "            encoded = one_hot(sentence, self.vocab_size)\n",
    "            sequences.append(encoded)\n",
    "            lengths.append(len(encoded))\n",
    "        # pad sequences to have one length\n",
    "        sequences = pad_sequences(sequences, maxlen=self.max_len)\n",
    "        return np.array(sequences), lengths\n",
    "    \n",
    "    def fit_transform(self, corpus):\n",
    "        \"\"\"Use this with training set to initialzer the tokenizer word dictionnary\n",
    "        \"\"\"\n",
    "        # train tokenizer on training corpus\n",
    "        self.tokenizer.fit_on_texts(corpus)\n",
    "        return self.transform(corpus)\n",
    "    \n",
    "    def transform(self, corpus):\n",
    "        \"\"\"Use this with test set\n",
    "        \"\"\"\n",
    "        # generate sequences of indices\n",
    "        sequences = self.tokenizer.texts_to_sequences(corpus)\n",
    "        # pad sequences to have one length\n",
    "        sequences = pad_sequences(sequences, maxlen=self.max_len, padding='post')\n",
    "        return sequences\n",
    "    \n",
    "    @property\n",
    "    def get_vocab_size(self):\n",
    "        return self.vocab_size\n",
    "    \n",
    "    @property\n",
    "    def get_sentence_max_len(self):\n",
    "        return self.max_len\n",
    "    \n",
    "    def get_words(self):\n",
    "        \"\"\"Get the list of words learned by this tokenizer\n",
    "        \"\"\"\n",
    "        return [word for word, index in self.tokenizer.word_index.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate the index sequences\n",
    "indexer = Vectorizer(vocab_size=50000, max_len=200)\n",
    "term_idx_train = indexer.fit_transform(corpus_train)\n",
    "term_idx_test = indexer.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 200), (25000, 200))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_idx_train.shape, term_idx_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  374,     1,   422,   833,   608,  4311,    31,     1,   708,\n",
       "         306,     7,     7,    12,     6,    48,     6,  1009,   130,\n",
       "          47,    97,    25,    74,    46,  2640,   833,  1391,     8,\n",
       "          11,  2974,     1,  4483,    13,  3432, 40830,    10,    67,\n",
       "          78,    12,     1,  2682,   189,    12,    22,    25,    46,\n",
       "        1016,    81,    20,   864,   724,   292,   124,    21,    94,\n",
       "           3,    84,   833,    19,   742,  6259,    13,     5,  1816,\n",
       "          15,    11,  2095,    26,  3366,     1,   367,    30,     1,\n",
       "         864,     2,   194,    12,    59,    27,     3,    49,   151,\n",
       "           7,     7,  4558,    30,    81, 11926,    15,     3,   170,\n",
       "           8,     3,  2130,   362,     6,    21,   718,   485,  1763,\n",
       "          59,    27,    40,    14,   906,   174,    44,    26,    68,\n",
       "           8,     3,  1005,    39,     3,   209,    26,     6,   605,\n",
       "          51,    26,     6,     8,     3,   485,  1763,    17,   118,\n",
       "          72,    64,    87,  4558,    30,   291,    72,    59,    37,\n",
       "           5,  7693,    30,     9,   124,    21,   154,   130,     7,\n",
       "           7,     1,   174,    13,    49,   546,    15,   485,     4,\n",
       "         261,     3,    49,    17,    97,    25,    74,    90,    57,\n",
       "         769,     1,   687,    12,    68,     8,     1,   864,   362,\n",
       "          18,   291,   141,    25,   194,    41,    86,     5,    19,\n",
       "           9,     7,     7,   372,    55,    33,    78,    28,     4,\n",
       "         131,    10,   437,    33,   680,    69,    83,     7,     7,\n",
       "         824, 34701], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_idx_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input params\n",
    "vocab_size             = indexer.get_vocab_size\n",
    "word_embed_vector_size = 16\n",
    "sentence_len_max       = indexer.get_sentence_max_len\n",
    "epochs                 = 100\n",
    "batch_size             = 1024\n",
    "\n",
    "# load pre-trained embedding GloVe https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "# Keras model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=word_embed_vector_size, input_length=sentence_len_max))\n",
    "model.add(Dropout(0.04))\n",
    "model.add(LSTM(units=64))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 16)           800000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200, 16)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                20736     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 820,801\n",
      "Trainable params: 820,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "adam = Adam(lr=1e-4)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', 'binary_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store the network architecture visualization graph to disk \n",
    "#plot_model(model, to_file='model.png', show_shapes=True)\n",
    "\n",
    "# obtain the pydot.Graph object and render it\n",
    "#SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size=50000 sentence_len_max=200 training=(50000, 200) label=50000\n"
     ]
    }
   ],
   "source": [
    "# combine all data\n",
    "X = np.concatenate((term_idx_train, term_idx_test), axis=0)\n",
    "y = np.append([], [y_train, y_test])\n",
    "\n",
    "print('vocab_size=%s sentence_len_max=%s training=%s label=%s' % (vocab_size, sentence_len_max, X.shape, len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 15s 382us/step - loss: 0.6885 - acc: 0.6178 - binary_accuracy: 0.6178 - val_loss: 0.7349 - val_acc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.73487, saving model to sentiment_weights.01-0.73.hdf5\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 13s 315us/step - loss: 0.6775 - acc: 0.6250 - binary_accuracy: 0.6250 - val_loss: 0.8464 - val_acc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 12s 302us/step - loss: 0.6640 - acc: 0.6250 - binary_accuracy: 0.6250 - val_loss: 0.9546 - val_acc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 12s 299us/step - loss: 0.6618 - acc: 0.6250 - binary_accuracy: 0.6250 - val_loss: 0.9571 - val_acc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 13s 316us/step - loss: 0.6606 - acc: 0.6250 - binary_accuracy: 0.6250 - val_loss: 0.9948 - val_acc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 12s 312us/step - loss: 0.6595 - acc: 0.6250 - binary_accuracy: 0.6250 - val_loss: 0.9829 - val_acc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 12s 310us/step - loss: 0.6581 - acc: 0.6250 - binary_accuracy: 0.6250 - val_loss: 0.9703 - val_acc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 12s 309us/step - loss: 0.6556 - acc: 0.6250 - binary_accuracy: 0.6250 - val_loss: 0.9780 - val_acc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 12s 304us/step - loss: 0.6309 - acc: 0.6250 - binary_accuracy: 0.6250 - val_loss: 1.1319 - val_acc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 12s 301us/step - loss: 0.5407 - acc: 0.6266 - binary_accuracy: 0.6266 - val_loss: 1.0207 - val_acc: 0.0095 - val_binary_accuracy: 0.0095\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 12s 308us/step - loss: 0.4758 - acc: 0.6481 - binary_accuracy: 0.6481 - val_loss: 0.9761 - val_acc: 0.1077 - val_binary_accuracy: 0.1077\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 12s 308us/step - loss: 0.4288 - acc: 0.7365 - binary_accuracy: 0.7365 - val_loss: 0.9089 - val_acc: 0.4507 - val_binary_accuracy: 0.4507\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 12s 308us/step - loss: 0.3990 - acc: 0.8679 - binary_accuracy: 0.8679 - val_loss: 0.7672 - val_acc: 0.8483 - val_binary_accuracy: 0.8483\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 12s 300us/step - loss: 0.3886 - acc: 0.8818 - binary_accuracy: 0.8818 - val_loss: 0.7289 - val_acc: 0.8878 - val_binary_accuracy: 0.8878\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.73487 to 0.72885, saving model to sentiment_weights.14-0.73.hdf5\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 12s 305us/step - loss: 0.3774 - acc: 0.8882 - binary_accuracy: 0.8882 - val_loss: 0.8919 - val_acc: 0.8213 - val_binary_accuracy: 0.8213\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 12s 312us/step - loss: 0.3483 - acc: 0.8999 - binary_accuracy: 0.8999 - val_loss: 0.8035 - val_acc: 0.8627 - val_binary_accuracy: 0.8627\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 12s 311us/step - loss: 0.3324 - acc: 0.9048 - binary_accuracy: 0.9048 - val_loss: 0.8668 - val_acc: 0.8469 - val_binary_accuracy: 0.8469\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 12s 305us/step - loss: 0.3167 - acc: 0.9095 - binary_accuracy: 0.9095 - val_loss: 0.8849 - val_acc: 0.8347 - val_binary_accuracy: 0.8347\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 12s 304us/step - loss: 0.3022 - acc: 0.9099 - binary_accuracy: 0.9099 - val_loss: 0.8163 - val_acc: 0.8475 - val_binary_accuracy: 0.8475\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 12s 311us/step - loss: 0.2852 - acc: 0.9138 - binary_accuracy: 0.9138 - val_loss: 0.7730 - val_acc: 0.8384 - val_binary_accuracy: 0.8384\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 12s 302us/step - loss: 0.2665 - acc: 0.9159 - binary_accuracy: 0.9159 - val_loss: 0.7036 - val_acc: 0.8399 - val_binary_accuracy: 0.8399\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.72885 to 0.70358, saving model to sentiment_weights.21-0.70.hdf5\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 12s 308us/step - loss: 0.2450 - acc: 0.9175 - binary_accuracy: 0.9175 - val_loss: 0.5796 - val_acc: 0.8383 - val_binary_accuracy: 0.8383\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.70358 to 0.57961, saving model to sentiment_weights.22-0.58.hdf5\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 12s 300us/step - loss: 0.2175 - acc: 0.9241 - binary_accuracy: 0.9241 - val_loss: 0.5655 - val_acc: 0.8237 - val_binary_accuracy: 0.8237\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.57961 to 0.56552, saving model to sentiment_weights.23-0.57.hdf5\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 12s 310us/step - loss: 0.1986 - acc: 0.9321 - binary_accuracy: 0.9321 - val_loss: 0.6020 - val_acc: 0.8201 - val_binary_accuracy: 0.8201\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 12s 312us/step - loss: 0.1852 - acc: 0.9390 - binary_accuracy: 0.9390 - val_loss: 0.6936 - val_acc: 0.8044 - val_binary_accuracy: 0.8044\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 12s 309us/step - loss: 0.1742 - acc: 0.9431 - binary_accuracy: 0.9431 - val_loss: 0.6733 - val_acc: 0.8185 - val_binary_accuracy: 0.8185\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 12s 311us/step - loss: 0.1645 - acc: 0.9467 - binary_accuracy: 0.9467 - val_loss: 0.6779 - val_acc: 0.8149 - val_binary_accuracy: 0.8149\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 12s 296us/step - loss: 0.1558 - acc: 0.9495 - binary_accuracy: 0.9495 - val_loss: 0.7675 - val_acc: 0.7970 - val_binary_accuracy: 0.7970\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 12s 312us/step - loss: 0.1483 - acc: 0.9535 - binary_accuracy: 0.9535 - val_loss: 0.7440 - val_acc: 0.8015 - val_binary_accuracy: 0.8015\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 12s 302us/step - loss: 0.1399 - acc: 0.9566 - binary_accuracy: 0.9566 - val_loss: 0.7783 - val_acc: 0.8003 - val_binary_accuracy: 0.8003\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 13s 322us/step - loss: 0.1343 - acc: 0.9582 - binary_accuracy: 0.9582 - val_loss: 0.7505 - val_acc: 0.8080 - val_binary_accuracy: 0.8080\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 13s 315us/step - loss: 0.1255 - acc: 0.9620 - binary_accuracy: 0.9620 - val_loss: 0.7851 - val_acc: 0.7972 - val_binary_accuracy: 0.7972\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 13s 314us/step - loss: 0.1209 - acc: 0.9648 - binary_accuracy: 0.9648 - val_loss: 0.7316 - val_acc: 0.8106 - val_binary_accuracy: 0.8106\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 12s 308us/step - loss: 0.1133 - acc: 0.9670 - binary_accuracy: 0.9670 - val_loss: 0.8344 - val_acc: 0.7913 - val_binary_accuracy: 0.7913\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 13s 314us/step - loss: 0.1064 - acc: 0.9696 - binary_accuracy: 0.9696 - val_loss: 0.7010 - val_acc: 0.8282 - val_binary_accuracy: 0.8282\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 12s 301us/step - loss: 0.1020 - acc: 0.9706 - binary_accuracy: 0.9706 - val_loss: 0.7070 - val_acc: 0.8314 - val_binary_accuracy: 0.8314\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 12s 298us/step - loss: 0.0982 - acc: 0.9730 - binary_accuracy: 0.9730 - val_loss: 0.7789 - val_acc: 0.8107 - val_binary_accuracy: 0.8107\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 12s 304us/step - loss: 0.0922 - acc: 0.9751 - binary_accuracy: 0.9751 - val_loss: 0.8376 - val_acc: 0.8011 - val_binary_accuracy: 0.8011\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 12s 303us/step - loss: 0.0883 - acc: 0.9765 - binary_accuracy: 0.9765 - val_loss: 0.8177 - val_acc: 0.7967 - val_binary_accuracy: 0.7967\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 12s 306us/step - loss: 0.0829 - acc: 0.9789 - binary_accuracy: 0.9789 - val_loss: 0.7232 - val_acc: 0.8288 - val_binary_accuracy: 0.8288\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 12s 292us/step - loss: 0.0801 - acc: 0.9801 - binary_accuracy: 0.9801 - val_loss: 0.8342 - val_acc: 0.7997 - val_binary_accuracy: 0.7997\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 12s 307us/step - loss: 0.0768 - acc: 0.9812 - binary_accuracy: 0.9812 - val_loss: 0.9335 - val_acc: 0.7860 - val_binary_accuracy: 0.7860\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 12s 298us/step - loss: 0.0752 - acc: 0.9827 - binary_accuracy: 0.9827 - val_loss: 0.7506 - val_acc: 0.8228 - val_binary_accuracy: 0.8228\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 12s 311us/step - loss: 0.0765 - acc: 0.9820 - binary_accuracy: 0.9820 - val_loss: 0.8461 - val_acc: 0.7930 - val_binary_accuracy: 0.7930\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 12s 305us/step - loss: 0.0696 - acc: 0.9843 - binary_accuracy: 0.9843 - val_loss: 0.9088 - val_acc: 0.7867 - val_binary_accuracy: 0.7867\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 12s 301us/step - loss: 0.0669 - acc: 0.9856 - binary_accuracy: 0.9856 - val_loss: 0.8455 - val_acc: 0.7954 - val_binary_accuracy: 0.7954\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/100\n",
      "37888/40000 [===========================>..] - ETA: 0s - loss: 0.0666 - acc: 0.9860 - binary_accuracy: 0.9860"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-db3cb97a8fd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcallbacks\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mckpt_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mverbose\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# save callback\n",
    "ckpt_callback = ModelCheckpoint('sentiment_weights.{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1, \n",
    "                                 save_best_only=True, \n",
    "                                 mode='auto')\n",
    "\n",
    "# train model\n",
    "history = model.fit(\n",
    "    x                = X,\n",
    "    y                = y,\n",
    "    epochs           = epochs,\n",
    "    batch_size       = batch_size,\n",
    "    validation_split = 0.2,\n",
    "    callbacks        = [ckpt_callback],\n",
    "    verbose          = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f1e397e7b5ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot training & validation accuracy values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation binary accuracy values\n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('Model binary accuracy')\n",
    "plt.ylabel('Binary Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_lstm = model.predict(x=term_idx_train, batch_size=batch_size)\n",
    "accuracy_train_lstm = (y_train == y_pred_lstm).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.497457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.499093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.499093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.499108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.500543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  25000.000000\n",
       "mean       0.499034\n",
       "std        0.000301\n",
       "min        0.497457\n",
       "25%        0.499093\n",
       "50%        0.499093\n",
       "75%        0.499108\n",
       "max        0.500543"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred_lstm).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred_lstm = model.predict(x=term_idx_test, batch_size=batch_size)\n",
    "accuracy_test_lstm = (y_test == y_test_pred_lstm).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.497457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.499093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.499093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.499108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.500543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  25000.000000\n",
       "mean       0.499034\n",
       "std        0.000301\n",
       "min        0.497457\n",
       "25%        0.499093\n",
       "50%        0.499093\n",
       "75%        0.499108\n",
       "max        0.500543"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred_lstm).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = model.layers[0].get_weights()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = indexer.get_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 9], [5, 8], [5, 8], [3, 8], [1], [6], [5, 8], [7, 5], [5, 8], [6, 3, 9, 7]]\n",
      "[[5 9 0 0 0]\n",
      " [5 8 0 0 0]\n",
      " [5 8 0 0 0]\n",
      " [3 8 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [6 0 0 0 0]\n",
      " [5 8 0 0 0]\n",
      " [7 5 0 0 0]\n",
      " [5 8 0 0 0]\n",
      " [6 3 9 7 0]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 5, 32)             320       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 481\n",
      "Trainable params: 481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 0.800\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conclusion, we're doomed to fail, not able to train the embedding layer\n",
    "# accuracy is stuck at a local minima but why always same? (optimizer is not improving from one epoch to the next)\n",
    "# I will retry by hot encoding 'y', also check this https://jovianlin.io/embeddings-in-keras/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
