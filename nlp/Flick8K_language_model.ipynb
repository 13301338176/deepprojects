{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flick8K language model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo3MJtrlPt5i",
        "colab_type": "text"
      },
      "source": [
        "- http://mlexplained.com/2018/02/15/language-modeling-tutorial-in-torchtext-practical-torchtext-part-2/\n",
        "- http://anie.me/On-Torchtext/\n",
        "- https://github.com/mjc92/TorchTextTutorial/blob/master/01.%20Getting%20started.ipynb\n",
        "- https://colab.research.google.com/drive/1bcsRgkCpiFxgvmMMAipr-itLIsl4QQCz#scrollTo=2cOQ5YwCvY58\n",
        "- https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FUud47TUxEm",
        "colab_type": "code",
        "outputId": "cb9164a0-483e-46c1-fb60-56d921b754c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRjZe62dU35h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4w_YlO9VN6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtNKQ9LmVUu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext as tt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxl_ZPTbVBiX",
        "colab_type": "code",
        "outputId": "77d5a44c-fdf7-427d-c240-f737d1854681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lYEcNiXVF2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = Path('/gdrive/My Drive/data/flick8k')\n",
        "images = PATH/'Flicker8k_Dataset'\n",
        "images_train = images/'train'\n",
        "images_test = images/'test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1IIVhUXSZfd",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tvUlzpJVkYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjjaTHUUVnIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ijKJLCsu5f2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embedding dimension (size of the word vectors)\n",
        "embed_size = 300\n",
        "# batch size\n",
        "batch_size = 64\n",
        "# BPTT (backpropagation through time) length\n",
        "seq_len = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHYNRjLvplmk",
        "colab_type": "text"
      },
      "source": [
        "### Flickr8k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39v92FEpVKGt",
        "colab_type": "code",
        "outputId": "1375a22f-c9ab-428b-e0bf-7b3f29d1b9c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df = pd.read_csv(PATH/'Flickr8k.token.txt', names=['id', 'caption'], delimiter='\\t') \n",
        "df['number'] = df['id'].apply(lambda x: int(x.split('#')[1]))\n",
        "df['id'] = df['id'].apply(lambda x: x.split('#')[0])\n",
        "df.head()"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>caption</th>\n",
              "      <th>number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A child in a pink dress is climbing up a set o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A girl going into a wooden building .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A little girl climbing into a wooden playhouse .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A little girl climbing the stairs to her playh...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A little girl in a pink dress going into a woo...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          id  ... number\n",
              "0  1000268201_693b08cb0e.jpg  ...      0\n",
              "1  1000268201_693b08cb0e.jpg  ...      1\n",
              "2  1000268201_693b08cb0e.jpg  ...      2\n",
              "3  1000268201_693b08cb0e.jpg  ...      3\n",
              "4  1000268201_693b08cb0e.jpg  ...      4\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbXV0RGcVeDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size = len(df)\n",
        "train_size = int(size * 0.9)\n",
        "valid_size = size - train_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSYVg2g2qsdX",
        "colab_type": "text"
      },
      "source": [
        "#### Save text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niYC17wrViJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[:train_size].to_csv(PATH/'train.csv',columns=['caption'], header=False, index=False)\n",
        "df[train_size:].to_csv(PATH/'valid.csv',columns=['caption'], header=False, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm-DJBcnqz7f",
        "colab_type": "text"
      },
      "source": [
        "#### Load text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ilgoeTQWFee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = tt.data.Field(tokenize=tokenizer,\n",
        "                     lower=True,\n",
        "                     batch_first=True,\n",
        "                     init_token='<bos>',\n",
        "                     eos_token='<eos>',\n",
        "                     fix_length=seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUYg0ZIBWajE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, valid = tt.data.TabularDataset.splits(path=PATH,\n",
        "                                             train='train.csv',\n",
        "                                             validation='valid.csv',\n",
        "                                             format='csv',\n",
        "                                             fields=[('text', TEXT)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M_kkVGsZhz6",
        "colab_type": "code",
        "outputId": "c296ee5d-2ae0-4b22-c9ea-cfc81641dd72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# print information about the data\n",
        "print('train.fields', train.fields)\n",
        "print('len(train)', len(train))\n",
        "print('vars(train[0])', vars(train[0])['text'][:10])"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.fields {'text': <torchtext.data.field.Field object at 0x7fe22427f128>}\n",
            "len(train) 36414\n",
            "vars(train[0]) ['a', 'child', 'in', 'a', 'pink', 'dress', 'is', 'climbing', 'up', 'a']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v2p8AI6CU_z",
        "colab_type": "code",
        "outputId": "05a9d37d-1eac-4f7b-d82c-d031c4a33894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(TEXT.pad([vars(train[0])['text']]))"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['<bos>', 'a', 'child', 'in', 'a', 'pink', 'dress', 'is', 'climbing', 'up', 'a', 'set', 'of', 'stairs', 'in', '<eos>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fr1b2SmXWSM",
        "colab_type": "code",
        "outputId": "6afe488e-cd52-4f93-b695-6249b5f9a3c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train), len(valid)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36414, 4046)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFmnNykZw-gz",
        "colab_type": "text"
      },
      "source": [
        "#### Load Vocab\n",
        "Check list of vocab vectors [here](https://torchtext.readthedocs.io/en/latest/vocab.html#torchtext.vocab.Vocab.load_vectors)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpwldIWaW6x2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(train, vectors='glove.6B.300d')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djgPVw30dGtJ",
        "colab_type": "code",
        "outputId": "5d169895-589b-40b6-94de-8d7688ff0fd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = TEXT.vocab\n",
        "print('Vocabulary shape:', vocab.vectors.shape)"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary shape: torch.Size([8161, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROg-q9sl1AMJ",
        "colab_type": "text"
      },
      "source": [
        "#### Iterator\n",
        "transform the train/valid dataset to make them compatible with [bpttiterator](https://torchtext.readthedocs.io/en/latest/data.html#bpttiterator)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TU8AzuO8zc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataset2example(dataset, field):\n",
        "    examples = list(map(lambda example: ['_bos_']+ example.text + ['_eos_'], dataset.examples))\n",
        "    examples = [item for example in examples for item in example]\n",
        "    example = tt.data.Example()\n",
        "    setattr(example, 'text', examples)\n",
        "    return tt.data.Dataset([example], fields={'text': field})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2LLmSYz3WPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_example = dataset2example(train, TEXT)\n",
        "valid_example = dataset2example(valid, TEXT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxa4CWA1ayj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iter, valid_iter = tt.data.BPTTIterator.splits((train_example, valid_example), batch_size=batch_size, bptt_len=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKd2cS0qXM3G",
        "colab_type": "code",
        "outputId": "3ac30b04-abf1-4e4d-b5e5-89a688268fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_iter), len(valid_iter)"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMBlZzxBwJ57",
        "colab_type": "text"
      },
      "source": [
        "look at data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXTyA1ArzyU6",
        "colab_type": "code",
        "outputId": "51d8254d-881c-413d-ab9a-b0c9ed361240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "example = train_iter.dataset[0]\n",
        "print(example.text) # tokens of the sample at index 0"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMxgnnLWwJNs",
        "colab_type": "code",
        "outputId": "95b3ae05-71f0-4f63-e7df-1ca6391b2407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch = next(iter(train_iter))\n",
        "vars(batch).keys()"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['batch_size', 'dataset', 'fields', 'text', 'target'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6Uu13b8Hong",
        "colab_type": "code",
        "outputId": "9a944829-ee14-4c2b-fd32-13102b55717d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch = next(iter(valid_iter))\n",
        "vars(batch).keys()"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['batch_size', 'dataset', 'fields', 'text', 'target'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGgaa1Sjpdqw",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACLIvN_7di3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleLM(nn.Module):\n",
        "    def __init__(self, vocab, embed_dim, batch_size, num_layers=1, bidirectional=False, hidden_state=None):\n",
        "        super().__init__()\n",
        "        self.vocab_size = len(vocab)\n",
        "        self.embed_dim, self.batch_size, self.num_layers = embed_dim, batch_size, num_layers\n",
        "        self.num_directions = 2 if bidirectional==True else 1\n",
        "        # emebedding layer\n",
        "        self.embed = nn.Embedding(self.vocab_size, embed_dim)\n",
        "        self.embed.weight.data.copy_(vocab.vectors)\n",
        "        # lstm layer\n",
        "        self.init_hidden(hidden_state)\n",
        "        self.lstm = nn.LSTM(embed_dim, embed_dim, num_layers, bidirectional=bidirectional)\n",
        "        self.batchnorm = nn.BatchNorm1d(batch_size)\n",
        "        # output layer\n",
        "        self.dense = nn.Linear(embed_dim, self.vocab_size)\n",
        "        \n",
        "    def init_hidden(self, hidden_state=None):\n",
        "        if hidden_state is not None:\n",
        "            self.hidden_state = hidden_state\n",
        "            return\n",
        "        # num_layers * num_directions, batch, hidden_size\n",
        "        dim1 = self.num_layers * self.num_directions\n",
        "        h = torch.zeros(dim1, self.batch_size, self.embed_dim).cuda()\n",
        "        c = torch.zeros(dim1, self.batch_size, self.embed_dim).cuda()\n",
        "        self.hidden_state = (h, c)\n",
        "        \n",
        "    def forward(self, X, lengths=None):\n",
        "        embed_out = self.embed(X) # (bs, embed_dim)\n",
        "        lstm_out, hidden_state = self.lstm(embed_out, self.hidden_state)\n",
        "        self.hidden_state = hidden_state #.detach()\n",
        "        batchnorm_out = self.batchnorm(lstm_out)\n",
        "        output = self.dense(batchnorm_out)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SLCyzGG34tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SimpleLM(TEXT.vocab, embed_size, batch_size).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr_aRgym4tNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.7, 0.99))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAlD_oD48CaK",
        "colab_type": "code",
        "outputId": "47602b91-5ab6-40ba-f015-143c687a1185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_tokens = vocab.vectors.size(0); n_tokens"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8161"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3_9RQj1pgBQ",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV--PXNfpfMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB_XrT8EqHJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_train_epoch(epoch):\n",
        "    \"\"\"One epoch of a training loop\"\"\"\n",
        "    # train mode\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in tqdm(train_iter):\n",
        "        # reset the hidden state\n",
        "        model.init_hidden()\n",
        "        text, target = batch.text.cuda(), batch.target.cuda()\n",
        "        prediction = model(text)\n",
        "        loss = criterion(prediction.view(-1, n_tokens), target.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        \n",
        "    train_loss /= len(train_iter)\n",
        "\n",
        "    # eval mode & deactivate autograd engine \n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in valid_iter:\n",
        "            model.init_hidden()\n",
        "            text, target = batch.text.cuda(), batch.target.cuda()\n",
        "            prediction = model(text)\n",
        "            loss = criterion(prediction.view(-1, n_tokens), target.view(-1))\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(valid_iter)\n",
        "    # record epoch stats\n",
        "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, train_loss, val_loss))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TrwqhIpqt5I",
        "colab_type": "code",
        "outputId": "6c90656c-2494-41eb-fe82-d65a04155696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1):\n",
        "    run_train_epoch(epoch)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/262 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/262 [00:00<00:35,  7.35it/s]\u001b[A\n",
            "  2%|▏         | 5/262 [00:00<00:26,  9.68it/s]\u001b[A\n",
            "  3%|▎         | 9/262 [00:00<00:20, 12.41it/s]\u001b[A\n",
            "  6%|▌         | 15/262 [00:00<00:15, 16.12it/s]\u001b[A\n",
            "  8%|▊         | 21/262 [00:00<00:11, 20.64it/s]\u001b[A\n",
            " 11%|█         | 28/262 [00:00<00:09, 25.70it/s]\u001b[A\n",
            " 13%|█▎        | 34/262 [00:00<00:07, 30.92it/s]\u001b[A\n",
            " 15%|█▌        | 40/262 [00:00<00:06, 36.03it/s]\u001b[A\n",
            " 18%|█▊        | 46/262 [00:00<00:05, 40.83it/s]\u001b[A\n",
            " 20%|█▉        | 52/262 [00:01<00:04, 44.71it/s]\u001b[A\n",
            " 22%|██▏       | 58/262 [00:01<00:04, 48.09it/s]\u001b[A\n",
            " 24%|██▍       | 64/262 [00:01<00:03, 50.63it/s]\u001b[A\n",
            " 27%|██▋       | 70/262 [00:01<00:03, 52.54it/s]\u001b[A\n",
            " 29%|██▉       | 76/262 [00:01<00:03, 54.28it/s]\u001b[A\n",
            " 32%|███▏      | 83/262 [00:01<00:03, 55.94it/s]\u001b[A\n",
            " 34%|███▍      | 89/262 [00:01<00:03, 56.65it/s]\u001b[A\n",
            " 36%|███▋      | 95/262 [00:01<00:02, 57.10it/s]\u001b[A\n",
            " 39%|███▊      | 101/262 [00:01<00:02, 57.50it/s]\u001b[A\n",
            " 41%|████      | 107/262 [00:02<00:02, 57.78it/s]\u001b[A\n",
            " 43%|████▎     | 113/262 [00:02<00:02, 58.28it/s]\u001b[A\n",
            " 45%|████▌     | 119/262 [00:02<00:02, 58.01it/s]\u001b[A\n",
            " 48%|████▊     | 125/262 [00:02<00:02, 57.82it/s]\u001b[A\n",
            " 50%|█████     | 131/262 [00:02<00:02, 57.95it/s]\u001b[A\n",
            " 52%|█████▏    | 137/262 [00:02<00:02, 57.80it/s]\u001b[A\n",
            " 55%|█████▍    | 143/262 [00:02<00:02, 58.27it/s]\u001b[A\n",
            " 57%|█████▋    | 149/262 [00:02<00:01, 58.14it/s]\u001b[A\n",
            " 59%|█████▉    | 155/262 [00:02<00:01, 58.57it/s]\u001b[A\n",
            " 61%|██████▏   | 161/262 [00:02<00:01, 58.64it/s]\u001b[A\n",
            " 64%|██████▎   | 167/262 [00:03<00:01, 58.34it/s]\u001b[A\n",
            " 66%|██████▌   | 173/262 [00:03<00:01, 58.49it/s]\u001b[A\n",
            " 68%|██████▊   | 179/262 [00:03<00:01, 58.79it/s]\u001b[A\n",
            " 71%|███████   | 185/262 [00:03<00:01, 58.74it/s]\u001b[A\n",
            " 73%|███████▎  | 191/262 [00:03<00:01, 58.66it/s]\u001b[A\n",
            " 75%|███████▌  | 197/262 [00:03<00:01, 58.59it/s]\u001b[A\n",
            " 77%|███████▋  | 203/262 [00:03<00:01, 58.89it/s]\u001b[A\n",
            " 80%|███████▉  | 209/262 [00:03<00:00, 58.97it/s]\u001b[A\n",
            " 82%|████████▏ | 215/262 [00:03<00:00, 58.86it/s]\u001b[A\n",
            " 84%|████████▍ | 221/262 [00:03<00:00, 58.94it/s]\u001b[A\n",
            " 87%|████████▋ | 227/262 [00:04<00:00, 59.11it/s]\u001b[A\n",
            " 89%|████████▉ | 233/262 [00:04<00:00, 58.96it/s]\u001b[A\n",
            " 91%|█████████ | 239/262 [00:04<00:00, 59.01it/s]\u001b[A\n",
            " 94%|█████████▎| 245/262 [00:04<00:00, 58.79it/s]\u001b[A\n",
            " 96%|█████████▌| 251/262 [00:04<00:00, 58.92it/s]\u001b[A\n",
            " 98%|█████████▊| 257/262 [00:04<00:00, 58.33it/s]\u001b[A\n",
            "100%|██████████| 262/262 [00:04<00:00, 55.92it/s]\u001b[A\n",
            "  0%|          | 0/262 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/262 [00:00<00:30,  8.56it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training Loss: 4.0877, Validation Loss: 3.1586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  3%|▎         | 8/262 [00:00<00:22, 11.53it/s]\u001b[A\n",
            "  5%|▌         | 14/262 [00:00<00:16, 15.19it/s]\u001b[A\n",
            "  8%|▊         | 20/262 [00:00<00:12, 19.56it/s]\u001b[A\n",
            " 10%|▉         | 26/262 [00:00<00:09, 24.38it/s]\u001b[A\n",
            " 12%|█▏        | 32/262 [00:00<00:07, 29.43it/s]\u001b[A\n",
            " 15%|█▍        | 38/262 [00:00<00:06, 34.54it/s]\u001b[A\n",
            " 17%|█▋        | 44/262 [00:00<00:05, 39.33it/s]\u001b[A\n",
            " 19%|█▉        | 50/262 [00:00<00:04, 43.64it/s]\u001b[A\n",
            " 21%|██▏       | 56/262 [00:01<00:04, 46.55it/s]\u001b[A\n",
            " 24%|██▎       | 62/262 [00:01<00:04, 49.79it/s]\u001b[A\n",
            " 26%|██▌       | 68/262 [00:01<00:03, 52.13it/s]\u001b[A\n",
            " 28%|██▊       | 74/262 [00:01<00:03, 53.85it/s]\u001b[A\n",
            " 31%|███       | 80/262 [00:01<00:03, 55.04it/s]\u001b[A\n",
            " 33%|███▎      | 86/262 [00:01<00:03, 56.24it/s]\u001b[A\n",
            " 35%|███▌      | 92/262 [00:01<00:02, 57.15it/s]\u001b[A\n",
            " 37%|███▋      | 98/262 [00:01<00:02, 57.67it/s]\u001b[A\n",
            " 40%|███▉      | 104/262 [00:01<00:02, 58.07it/s]\u001b[A\n",
            " 42%|████▏     | 110/262 [00:01<00:02, 58.46it/s]\u001b[A\n",
            " 44%|████▍     | 116/262 [00:02<00:02, 57.92it/s]\u001b[A\n",
            " 47%|████▋     | 122/262 [00:02<00:02, 58.53it/s]\u001b[A\n",
            " 49%|████▉     | 128/262 [00:02<00:02, 58.35it/s]\u001b[A\n",
            " 51%|█████     | 134/262 [00:02<00:02, 58.10it/s]\u001b[A\n",
            " 53%|█████▎    | 140/262 [00:02<00:02, 58.18it/s]\u001b[A\n",
            " 56%|█████▌    | 146/262 [00:02<00:02, 57.82it/s]\u001b[A\n",
            " 58%|█████▊    | 152/262 [00:02<00:01, 57.78it/s]\u001b[A\n",
            " 60%|██████    | 158/262 [00:02<00:01, 57.40it/s]\u001b[A\n",
            " 63%|██████▎   | 164/262 [00:02<00:01, 57.32it/s]\u001b[A\n",
            " 65%|██████▍   | 170/262 [00:03<00:01, 57.53it/s]\u001b[A\n",
            " 67%|██████▋   | 176/262 [00:03<00:01, 57.71it/s]\u001b[A\n",
            " 69%|██████▉   | 182/262 [00:03<00:01, 57.99it/s]\u001b[A\n",
            " 72%|███████▏  | 188/262 [00:03<00:01, 58.06it/s]\u001b[A\n",
            " 74%|███████▍  | 194/262 [00:03<00:01, 57.93it/s]\u001b[A\n",
            " 76%|███████▋  | 200/262 [00:03<00:01, 58.06it/s]\u001b[A\n",
            " 79%|███████▊  | 206/262 [00:03<00:00, 58.06it/s]\u001b[A\n",
            " 81%|████████  | 212/262 [00:03<00:00, 57.90it/s]\u001b[A\n",
            " 83%|████████▎ | 218/262 [00:03<00:00, 57.78it/s]\u001b[A\n",
            " 85%|████████▌ | 224/262 [00:03<00:00, 57.67it/s]\u001b[A\n",
            " 88%|████████▊ | 230/262 [00:04<00:00, 57.49it/s]\u001b[A\n",
            " 90%|█████████ | 236/262 [00:04<00:00, 57.74it/s]\u001b[A\n",
            " 92%|█████████▏| 242/262 [00:04<00:00, 57.87it/s]\u001b[A\n",
            " 95%|█████████▍| 248/262 [00:04<00:00, 57.72it/s]\u001b[A\n",
            " 97%|█████████▋| 254/262 [00:04<00:00, 57.62it/s]\u001b[A\n",
            " 99%|█████████▉| 260/262 [00:04<00:00, 57.61it/s]\u001b[A\n",
            "100%|██████████| 262/262 [00:04<00:00, 56.75it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2, Training Loss: 2.9167, Validation Loss: 2.9422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VCv56VOXGvK",
        "colab_type": "text"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmyBqgzr9GoD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "6441e28e-f7aa-4019-ad32-3261280dbf78"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleLM(\n",
              "  (embed): Embedding(8161, 300)\n",
              "  (lstm): LSTM(300, 300)\n",
              "  (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dense): Linear(in_features=300, out_features=8161, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzfHgxdQ_pnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i2w = TEXT.vocab.itos\n",
        "w2i = dict([(w,i) for i,w in enumerate(TEXT.vocab.itos)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJeoZ43qNlqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_text(text, target_length, padding=TEXT.pad_token):\n",
        "    current_length = len(text)\n",
        "    for i in range(current_length, target_length):\n",
        "        text.append(padding)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA-t-l1pDzyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = pad_text([TEXT.init_token, 'a', 'boy'], batch_size, TEXT.init_token)\n",
        "in_tensor = torch.tensor([w2i[w] for w in text])\n",
        "in_tensor = in_tensor.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qnx7QfCMpmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_tensor = in_tensor.view(1, batch_size)\n",
        "out_tensor = model(in_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJTjXJ65Oypa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b5288b48-eaa0-4d9f-a7c7-5308e73fdc9a"
      },
      "source": [
        "out_array = out_tensor.cpu().data.numpy()\n",
        "indexes = np.argmax(out_array, axis=2)\n",
        "\n",
        "' '.join([i2w[i] for i in indexes.tolist()[0]])"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'. man in a while a a . a a . a . a two a a . two a . . . . a a a a a a a a a a a a a two a a a a a a a a a . a a a a with a a a a a a a two a a a'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCoBJahaIsTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}