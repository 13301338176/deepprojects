{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dlfs_swift_training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "68lucfzaL47E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Custom Mini-Batch and Training loop"
      ]
    },
    {
      "metadata": {
        "id": "PlafVnVaMHNC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "caUx5DHwMMXF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ]
    },
    {
      "metadata": {
        "id": "kZRlD4utdPuX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import Python\n",
        "let request = Python.import(\"urllib.request\")\n",
        "let pickle = Python.import(\"pickle\")\n",
        "let gzip = Python.import(\"gzip\")\n",
        "let np = Python.import(\"numpy\")\n",
        "let plt = Python.import(\"matplotlib.pyplot\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DmMgP48gMHxE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import TensorFlow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YZ2vRWf1MU4i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### MNIST"
      ]
    },
    {
      "metadata": {
        "id": "m5yz_bJiVDVU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Data"
      ]
    },
    {
      "metadata": {
        "id": "RXa8AcVvMR-b",
        "colab_type": "code",
        "outputId": "9a37dcce-3c04-482c-9170-7d28d0a1755a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "let result = request.urlretrieve(\n",
        "    \"https://github.com/mnielsen/neural-networks-and-deep-learning/raw/master/data/mnist.pkl.gz\",\n",
        "    \"mnist.pkl.gz\")\n",
        "let filename = result[0]; filename"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mnist.pkl.gz\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "fMcwiuAvMW0U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "let mnist = pickle.load(gzip.open(filename), encoding:\"latin-1\")\n",
        "// read train, validation and test datasets\n",
        "let train_mnist = mnist[0]\n",
        "let valid_mnist = mnist[1]\n",
        "let test_mnist = mnist[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eQyxWPZVdGqn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "func unsequeeze(_ array: PythonObject, _ dtype: PythonObject = np.float32) -> PythonObject {\n",
        "    return np.expand_dims(array, axis:-1).astype(dtype)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6jyLf16Ib30O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "// read training tuple into separate variables\n",
        "let pyobj_train_x = train_mnist[0]\n",
        "let pyobj_train_y = train_mnist[1].astype(np.int32) // expand dimension\n",
        "// read validation tuple into separate variables\n",
        "let pyobj_valid_x = valid_mnist[0]\n",
        "let pyobj_valid_y = valid_mnist[1].astype(np.int32) // expand dimension\n",
        "// read test tuple into separate variables\n",
        "let pyobj_test_x = test_mnist[0]\n",
        "let pyobj_test_y = test_mnist[1].astype(np.int32) // expand dimension"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FjrMRXlsdNhL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "// read tensorflow arrays into Tensors\n",
        "let X_train = Tensor<Float32>(numpy: pyobj_train_x)! // ! to unwrap optionals\n",
        "let y_train = Tensor<Int32>(numpy: pyobj_train_y)! // ! to unwrap optionals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UBUV2Wu7dRWl",
        "colab_type": "code",
        "outputId": "b198e90d-f8f0-4e9b-9c5d-0c1c925cd263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "▿ TensorShape\n",
              "  ▿ dimensions : 2 elements\n",
              "    - 0 : 50000\n",
              "    - 1 : 784\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "ibW7z2ayVEdB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Model"
      ]
    },
    {
      "metadata": {
        "id": "r3ubzdW5bw6h",
        "colab_type": "code",
        "outputId": "436759e1-54e0-4b84-a234-5b6ec36e5b26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "let m : Int = Int(X_train.shape[0]) // number of samples\n",
        "let n_in: Int = Int(X_train.shape[1]) // number of features\n",
        "let nh: Int = 50 // number of \n",
        "let n_out: Int = 10 //number of classes\n",
        "\n",
        "print(\"\\(n_in) -> \\(nh) -> \\(n_out)\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "784 -> 50 -> 10\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WuyFuzbDMYaT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "struct Model: Layer {\n",
        "    var layer1 = Dense<Float>(inputSize: n_in, outputSize: nh, activation: relu)\n",
        "    var layer2 = Dense<Float>(inputSize: nh, outputSize: n_out)\n",
        "\n",
        "    @differentiable\n",
        "    func applied(to input: Tensor<Float>, in context: Context) -> Tensor<Float> {\n",
        "        return input.sequenced(in: context, through: layer1, layer2)\n",
        "    }\n",
        "    \n",
        "    var description: String {\n",
        "        return \"description here\"\n",
        "    }\n",
        "}\n",
        "\n",
        "var model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JLgNOx2xDWfv",
        "colab_type": "code",
        "outputId": "0bfe72a3-8b8a-4371-ea63-c7d3011c560f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "let ctx = Context(learningPhase: .training)\n",
        "\n",
        "// Apply the model to a batch of features.\n",
        "let preds = model.applied(to: X_train, in: ctx)\n",
        "preds[0..<2]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.5411263, 0.3102402, 0.41393316, 0.17374031, -0.2054505, 0.45775208, 0.13550594, -1.2340554, -0.13964355, 0.8585694], [0.6222204, 0.15639141, 0.8304158, 0.3665827, 0.27860576, 0.51567, -0.117491305, 0.065558776, -0.095890775, 0.1879227]]\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "1NNiQ1O_hcic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "// test helper functions\n",
        "func test_near_zero(_ val: Float32, _ msg: String) -> Void {\n",
        "    assert(val < 1e-3, msg)\n",
        "}\n",
        "\n",
        "func test_almost_eq(_ t1: Tensor<Float32>, _ t2: Tensor<Float32>, _ msg: String, _ epsilon: Float32 = 1e-3) -> Void {\n",
        "    assert(t1 - t2 < epsilon, msg)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g3U48Q0Hd5mi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Custom loss function\n",
        "We need to compute the softmax of our activations, then apply a log:\n",
        "$$ i = \\frac{e^{x_i}}{\\sum_{0 \\leq  j \\leq n-1} e^{x_j}} $$"
      ]
    },
    {
      "metadata": {
        "id": "TVQ9ZvjXdzaI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "func log_softmax(_ x: Tensor<Float>) -> Tensor<Float> {\n",
        "    let softmax = exp(x) / (exp(x).sum(alongAxes: -1))\n",
        "    return log(softmax)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xOEAeEPXhRl7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "with a sample check that our implementation is equal to tensorflow implementation"
      ]
    },
    {
      "metadata": {
        "id": "QE0-YEG-fao6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "let x: Tensor<Float> = Tensor<Float>(arrayLiteral: [1, 2, 3, 4], [4, 3, 2, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qOybByyDfbiw",
        "colab_type": "code",
        "outputId": "72a84d83-d21e-4fad-c34f-229c604ae58c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "log_softmax(x)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-3.4401896, -2.4401896, -1.4401897, -0.44018975], [-0.44018975, -1.4401897, -2.4401896, -3.4401896]]\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "IKg3C5A9hJpS",
        "colab_type": "code",
        "outputId": "fb2e5dc9-6ddc-4e22-b0f9-51c35adf12cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "logSoftmax(x)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-3.4401896, -2.4401896, -1.4401897, -0.4401897], [-0.4401897, -1.4401897, -2.4401896, -3.4401896]]\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "KmeN-cO5hLpR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_almost_eq(log_softmax(x), logSoftmax(x), \"Our impl should be same as Tensorflow impl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fnQR3maHDrZR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "let y_hat: Tensor<Float> = log_softmax(preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PDoABxvTh-0t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Given  $x$ and its prediction $p(x)$, the **Cross Entropy** loss is: \n",
        "$$ - \\sum x \\log p(x) $$\n",
        "\n",
        "Now as the output of the NN is a 1-hot encoded array,  we can rewrite the formula for the index $i$ of a desired target as follows: \n",
        "$$-\\log(p_{i})$$\n",
        "Technically, if the predictions are of shape (m, 10) and target is (m, 1) then result should be `predictions[:, target]`."
      ]
    },
    {
      "metadata": {
        "id": "H3WHH9sjpQiN",
        "colab_type": "code",
        "outputId": "584d8c02-856d-4129-ad1b-d9d5934d85b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "let x1: Tensor<Float> = Tensor<Float>(arrayLiteral: [2], [3])\n",
        "let x2: Tensor<Float> = log_softmax(x)\n",
        "\n",
        "print(\"\\(x1.shape) \\(x2.shape)\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape(dimensions: [2, 1]) TensorShape(dimensions: [2, 4])\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nmnAQ8XcpZRP",
        "colab_type": "code",
        "outputId": "ada027ff-f6bb-4da5-e6c6-3ef32577f81c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x2[1..<2]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-0.44018975, -1.4401897, -2.4401896, -3.4401896]]\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "xhyHSfPJA6tX",
        "colab_type": "code",
        "outputId": "618f2af2-92ea-4698-abda-2baecebc1d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "let i: Int32 = 0\n",
        "let pos: Int32 = Int32(x1[i][0].scalar!)\n",
        "x2[i][pos].scalar! "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.4401897\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "LVtLxelqDCl1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finnally a minually calculated loss looks like:"
      ]
    },
    {
      "metadata": {
        "id": "k0w_Aj9vA99m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "func nll(labels: Tensor<Int32>, logits: Tensor<Float>) -> Float {\n",
        "    let size = labels.shape[0]\n",
        "    var sum : Float = 0\n",
        "    for i in 0..<size {\n",
        "        let pos: Int32 = labels[i][0].scalar!\n",
        "        sum += logits[i][pos].scalar!\n",
        "    }\n",
        "    return sum / Float(size)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h6NfWKNPAjQp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "c81d6b84-bcd6-4118-dd0e-eb673c8fe807"
      },
      "cell_type": "code",
      "source": [
        "// our way\n",
        "let loss1: Float = nll(labels: y_train, logits: y_hat)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fatal error: Dimension -1 must be >= 0: file /swift-base/swift/stdlib/public/TensorFlow/CompilerRuntime.swift, line 2094\r\n",
            "Current stack trace:\r\n",
            "0    libswiftCore.so                    0x00007f2d761b4f40 _swift_stdlib_reportFatalErrorInFile + 115\r\n",
            "1    libswiftCore.so                    0x00007f2d760fd3dc <unavailable> + 3003356\r\n",
            "2    libswiftCore.so                    0x00007f2d760fd4ce <unavailable> + 3003598\r\n",
            "3    libswiftCore.so                    0x00007f2d75f44e12 <unavailable> + 1199634\r\n",
            "4    libswiftCore.so                    0x00007f2d760c76b2 <unavailable> + 2782898\r\n",
            "5    libswiftCore.so                    0x00007f2d75f44259 <unavailable> + 1196633\r\n",
            "6    libswiftTensorFlow.so              0x00007f2d64d19ad2 <unavailable> + 441042\r\n",
            "7    libswiftTensorFlow.so              0x00007f2d64d18230 checkOk(_:file:line:) + 491\r\n",
            "8    libswiftTensorFlow.so              0x00007f2d64d3b270 _TFCCheckOk(_:) + 81\r\n",
            "9    libswiftTensorFlow.so              0x00007f2d64d3b260 _swift_tfc_CheckOk + 9\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "",
          "evalue": "ignored",
          "traceback": [
            "Current stack trace:",
            "\tframe #8: 0x00007f2d5802a3c9 $__lldb_expr196`nll(labels=[5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5, 9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5, 6, 1, 0, 0, 1, 7, 1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9, 0, 4, 6, 7, 4, 6, 8, 0, 7, 8, 3, 1, 5, 7, 1, 7, 1, 1, 6, 3, 0, 2, 9, 3, 1, 1, 0, 4, 9, 2, 0, 0, 2, 0, 2, 7, 1, 8, 6, 4, 1, 6, 3, 4, 5, 9, 1, 3, 3, 8, 5, 4, 7, 7, 4, 2, 8, 5, 8, 6, 7, 3, 4, 6, 1, 9, 9, 6, 0, 3, 7, 2, 8, 2, 9, 4, 4, 6, 4, 9, 7, 0, 9, 2, 9, 5, 1, 5, 9, 1, 2, 3, 2, 3, 5, 9, 1, 7, 6, 2, 8, 2, 2, 5, 0, 7, 4, 9, 7, 8, 3, 2, 1, 1, 8, 3, 6, 1, 0, 3, 1, 0, 0, 1, 7, 2, 7, 3, 0, 4, 6, 5, 2, 6, 4, 7, 1, 8, 9, 9, 3, 0, 7, 1, 0, 2, 0, 3, 5, 4, 6, 5, 8, 6, 3, 7, 5, 8, 0, 9, 1, 0, 3, 1, 2, 2, 3, 3, 6, 4, 7, 5, 0, 6, 2, 7, 9, 8, 5, 9, 2, 1, 1, 4, 4, 5, 6, 4, 1, 2, 5, 3, 9, 3, 9, 0, 5, 9, 6, 5, 7, 4, 1, 3, 4, 0, 4, 8, 0, 4, 3, 6, 8, 7, 6, 0, 9, 7, 5, 7, 2, 1, 1, 6, 8, 9, 4, 1, 5, 2, 2, 9, 0, 3, 9, 6, 7, 2, 0, 3, 5, 4, 3, 6, 5, 8, 9, 5, 4, 7, 4, 2, 7, 3, 4, 8, 9, 1, 9, 2, 8, 7, 9, 1, 8, 7, 4, 1, 3, 1, 1, 0, 2, 3, 9, 4, 9, 2, 1, 6, 8, 4, 7, 7, 4, 4, 9, 2, 5, 7, 2, 4, 4, 2, 1, 9, 7, 2, 8, 7, 6, 9, 2, 2, 3, 8, 1, 6, 5, 1, 1, 0, 2, 6, 4, 5, 8, 3, 1, 5, 1, 9, 2, 7, 4, 4, 4, 8, 1, 5, 8, 9, 5, 6, 7, 9, 9, 3, 7, 0, 9, 0, 6, 6, 2, 3, 9, 0, 7, 5, 4, 8, 0, 9, 4, 1, 2, 8, 7, 1, 2, 6, 1, 0, 3, 0, 1, 1, 8, 2, 0, 3, 9, 4, 0, 5, 0, 6, 1, 7, 7, 8, 1, 9, 2, 0, 5, 1, 2, 2, 7, 3,...\nexpression produced error: error: Execution was interrupted, reason: signal SIGILL: illegal instruction operand.\nThe process has been returned to the state before expression evaluation.) at <Cell 22>:5:35",
            "\tframe #9: 0x00007f2d58037a5c $__lldb_expr202`main at <Cell 23>:2:20"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "aN52ao9jspfG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "// tensorflow-way\n",
        "let loss2: Float = softmaxCrossEntropy(logits: preds, labels: y_train).scalar!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "01ANconHpc63",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_near_zero(loss1-loss2, \"Loss manually calculated should be similar to Tensorflow-way\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3JxwsbLaRjpi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Accuracy function:"
      ]
    },
    {
      "metadata": {
        "id": "2BRsf16cqt0o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "func accuracy(_ logits: Tensor<Float>, _ labels: Tensor<Int32>) -> Float {\n",
        "    return Tensor<Float>(logits.argmax(squeezingAxis: -1) .== labels).mean().scalarized()\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VRh3T0heSHrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "accuracy(preds, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WJrDnlu9VYeV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Basic training loop\n",
        "- Grap a batch from the dataset\n",
        "- Do a forward pass to get the output of the model on this batch\n",
        "- compute a loss by comparint the output with the labels \n",
        "- Do a backward pass to calculate the gradients of the loss \n",
        "- update the model parameters with the gradients "
      ]
    },
    {
      "metadata": {
        "id": "cnp_Z-SZSLu0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "let bs: Int32 = 64\n",
        "\n",
        "// grap batch\n",
        "let X_batch: Tensor<Float> = X_train[0..<bs]\n",
        "let y_batch: Tensor<Int32> = y_train[0..<bs]\n",
        "\n",
        "let ctx = Context(learningPhase: .training)\n",
        "\n",
        "let (loss, grads) = model.valueWithGradient { model -> Tensor<Float> in\n",
        "    // forward pass\n",
        "    let preds = model.applied(to: X_batch, in: ctx)\n",
        "    // compute loss\n",
        "    return softmaxCrossEntropy(logits: preds, labels: y_batch)\n",
        "}\n",
        "// backward pass\n",
        "\n",
        "/**\n",
        "print(\"Current loss: \\(loss)\")\n",
        "print(\"Current accuracy: \\(accuracy(preds, y_batch))\")\n",
        "\n",
        "Continue from 47:00\n",
        "*/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aRx4LkXXS3Lm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for l in model {\n",
        "    print(l)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ITrIp_QS6o9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}