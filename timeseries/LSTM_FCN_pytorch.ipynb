{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-FCN-pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "NreY7BzeqHVd",
        "colab_type": "code",
        "outputId": "ec1c11a2-c547-4f4a-bdd0-4674f7a9500c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1397
        }
      },
      "cell_type": "code",
      "source": [
        "!curl https://course-v3.fast.ai/setup/colab | bash"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   665  100   665    0     0   3064      0 --:--:-- --:--:-- --:--:--  3064\n",
            "Collecting pillow==4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e5/88b3d60924a3f8476fa74ec086f5fbaba56dd6cee0d82845f883b6b6dd18/Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.7MB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow==4.1.1) (0.46)\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-4.1.1\n",
            "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
            "Collecting torch_nightly\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/cu92/torch_nightly-1.0.0.dev20181126-cp36-cp36m-linux_x86_64.whl (576.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 576.5MB 24kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x62abe000 @  0x7f09f96102a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch-nightly\n",
            "Successfully installed torch-nightly-1.0.0.dev20181126\n",
            "Cloning into 'course-v3'...\n",
            "remote: Enumerating objects: 2450, done.\u001b[K\n",
            "remote: Total 2450 (delta 0), reused 0 (delta 0), pack-reused 2450\u001b[K\n",
            "Receiving objects: 100% (2450/2450), 59.09 MiB | 26.75 MiB/s, done.\n",
            "Resolving deltas: 100% (1338/1338), done.\n",
            "Collecting fastai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/fe/9686231cc2ed81a7096abda19d93ca43532d7b130a12d1ada8746ba75e72/fastai-1.0.28-py3-none-any.whl (120kB)\n",
            "\u001b[K    100% |████████████████████████████████| 122kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: typing in /usr/local/lib/python3.6/dist-packages (from fastai) (3.6.6)\n",
            "Requirement already satisfied, skipping upgrade: thinc==6.12.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (6.12.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (2.1.2)\n",
            "Collecting numexpr (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/ea/efd9e16283637eb5b6c0042b6cc3521f1b9a5b47767ac463c88bbd37670c/numexpr-2.6.8-cp36-cp36m-manylinux1_x86_64.whl (162kB)\n",
            "\u001b[K    100% |████████████████████████████████| 163kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: spacy==2.0.16 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.0.16)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.22.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem==2.0.2 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.0.2)\n",
            "Collecting torchvision-nightly (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/bd/d0f9a33c81c79710eb7ee428b66869b49a8be16c7f1e446c211a7fbfb7be/torchvision_nightly-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 6.9MB/s \n",
            "\u001b[?25hCollecting dataclasses (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Collecting bottleneck (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/ae/cedf5323f398ab4e4ff92d6c431a3e1c6a186f9b41ab3e8258dff786a290/Bottleneck-1.2.1.tar.gz (105kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.18.4)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from fastai) (2018.1.10)\n",
            "Collecting fastprogress>=0.1.15 (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/dc/b8/7ce2b3c6f886f5cb1b16e62d368456b4fdb7e16bba962571bc50dae49b30/fastprogress-0.1.15-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (1.10.11)\n",
            "Requirement already satisfied, skipping upgrade: dill<0.3.0,>=0.2.7 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.2.8.2)\n",
            "Requirement already satisfied, skipping upgrade: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: msgpack-numpy<0.4.4.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: msgpack<1.0.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.5.6)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.9.0.1)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.0.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2018.7)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (1.35)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai) (0.46)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2018.10.15)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc==6.12.0->fastai) (0.9.0)\n",
            "Building wheels for collected packages: bottleneck\n",
            "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f2/bf/ec/e0f39aa27001525ad455139ee57ec7d0776fe074dfd78c97e4\n",
            "Successfully built bottleneck\n",
            "Installing collected packages: numexpr, torchvision-nightly, dataclasses, bottleneck, fastprogress, fastai\n",
            "Successfully installed bottleneck-1.2.1 dataclasses-0.6 fastai-1.0.28 fastprogress-0.1.15 numexpr-2.6.8 torchvision-nightly-0.2.1\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CKP2ikW1ngNl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OblomiW9n4bg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from fastai import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEwnf-gdntsa",
        "colab_type": "code",
        "outputId": "787e2dfe-de5b-4a7e-f0a2-2a53086377df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!curl -O http://www.timeseriesclassification.com/Downloads/Earthquakes.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  516k  100  516k    0     0   425k      0  0:00:01  0:00:01 --:--:--  425k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qsr9wx88nyRG",
        "colab_type": "code",
        "outputId": "c6329ce1-9103-4d2e-c16d-8802d81ebbde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip Earthquakes.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Earthquakes.zip\n",
            "  inflating: Earthquakes.txt         \n",
            "  inflating: Earthquakes_TEST.arff   \n",
            "  inflating: Earthquakes_TEST.txt    \n",
            "  inflating: Earthquakes_TRAIN.arff  \n",
            "  inflating: Earthquakes_TRAIN.txt   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "onhUsHlhsWvc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bs = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O1pj6M8Vn-0D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATASET = 'Earthquakes'\n",
        "classes = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9EMN9yFin1cW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = pathlib.Path('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tDncQ40aHJkX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot_encode(input, labels):\n",
        "    m = input.shape[0]\n",
        "    output = np.zeros((m, labels), dtype=int)\n",
        "    row_index = np.arange(m)\n",
        "    output[row_index, input] = 1\n",
        "    return output\n",
        "\n",
        "def split_xy(data, classes):\n",
        "    X = data[:, 1:]\n",
        "    y = data[:, 0].astype(int)\n",
        "    # hot encode\n",
        "    #y = one_hot_encode(y, classes)\n",
        "    return X, y\n",
        "\n",
        "def create_dataset(X, y, device):\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32, device=device)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.long, device=device)\n",
        "    return TensorDataset(X_tensor, y_tensor)\n",
        "\n",
        "def load_data(path, classes):\n",
        "    data = np.loadtxt(path)\n",
        "    return split_xy(data, classes)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jNG4E5F-Tpcf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The outputs of the model should be of size (minibatch, C). On the other hand the target `y` should contain the indices of the classes."
      ]
    },
    {
      "metadata": {
        "id": "A69YvILXoA5e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load training dataset\n",
        "X_train, y_train = load_data(path/'Earthquakes_TRAIN.txt', classes) \n",
        "\n",
        "# load testing dataset\n",
        "X_test, y_test = load_data(path/'Earthquakes_TEST.txt', classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOrCEhRicN27",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ed145a73-743a-4d66-d42b-c3160e7be018"
      },
      "cell_type": "code",
      "source": [
        "print('X_train %s   y_train %s' % (X_train.shape, y_train.shape))\n",
        "print('X_test  %s   y_test  %s' % (X_test.shape, y_test.shape))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train (322, 512)   y_train (322,)\n",
            "X_test  (139, 512)   y_test  (139,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MWAHekuN7mqq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As the classes are imbalanced, get the count for each class, to use later in the sampling"
      ]
    },
    {
      "metadata": {
        "id": "tQ4U0nAa7RV3",
        "colab_type": "code",
        "outputId": "f8f547c2-7fbf-400c-edb8-671cae341a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "class_0_count = (y_train==0).sum()\n",
        "class_1_count = (y_train==1).sum()\n",
        "\n",
        "class_0_count, class_1_count"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(264, 58)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "9307nee9rz4Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "load the numpy training and test sets into pytorch Dataset object"
      ]
    },
    {
      "metadata": {
        "id": "gmqg-MVhaHFY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cuda = torch.device('cuda')     # Default CUDA device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Wqt26B1oD_g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_ds = create_dataset(X_train, y_train, cuda)\n",
        "test_ds  = create_dataset(X_test, y_test, cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2uSDLS9-sBYl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "pass the Dataset objects into a DataLoader"
      ]
    },
    {
      "metadata": {
        "id": "DVMtIjJl6jcr",
        "colab_type": "code",
        "outputId": "014cf776-27cf-46b9-b45c-94c9ff378dd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "class_sample_count = [class_0_count, class_1_count] # dataset has 10 class-1 samples, 1 class-2 samples, etc.\n",
        "weights = 1 / torch.Tensor(class_sample_count)\n",
        "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, bs)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.weights = torch.tensor(weights, dtype=torch.double)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5rckvuLErUGq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=False)#, sampler = sampler)\n",
        "test_dl = DataLoader(test_ds, batch_size=bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3A86zi48tdPG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## LSTM-FCN\n",
        "### LSMT block\n",
        "A shuffle layer + LSTM layer + Dropout layer"
      ]
    },
    {
      "metadata": {
        "id": "JDYfUKc8tQhu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BlockLSTM(nn.Module):\n",
        "    def __init__(self, time_steps, num_layers, lstm_hs, dropout=0.8, attention=False):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size=time_steps, hidden_size=lstm_hs, num_layers=num_layers)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "    def forward(self, x):\n",
        "        # input is of the form (batch_size, num_layers, time_steps), e.g. (128, 1, 512)\n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        # lstm layer is of the form (num_layers, batch_size, time_steps)\n",
        "        x, (h_n, c_n) = self.lstm(x)\n",
        "        # dropout layer input shape (Sequence Length, Batch Size, Hidden Size * Num Directions)\n",
        "        y = self.dropout(x)\n",
        "        # output shape is same as Dropout intput\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PskMJhzL8_Ao",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### FCN block\n",
        "\n",
        "#### Convolutional block"
      ]
    },
    {
      "metadata": {
        "id": "4oam7px91HYa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BlockFCNConv(nn.Module):\n",
        "    def __init__(self, in_channel=1, out_channel=128, kernel_size=8, momentum=0.99, epsilon=0.001, squeeze=False):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(in_channel, out_channel, kernel_size=kernel_size)\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=out_channel, eps=epsilon, momentum=momentum)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        # input (batch_size, num_variables, time_steps), e.g. (128, 1, 512)\n",
        "        x = self.conv(x)\n",
        "        # input (batch_size, out_channel, L_out)\n",
        "        x = self.batch_norm(x)\n",
        "        # same shape as input\n",
        "        y = self.relu(x)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sxIcU-lx9GeV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### FCN block"
      ]
    },
    {
      "metadata": {
        "id": "lNDU3Mij89dR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BlockFCN(nn.Module):\n",
        "    def __init__(self, time_steps, channels=[1, 128, 256, 128], kernels=[8, 5, 3], mom=0.99, eps=0.001):\n",
        "        super().__init__()\n",
        "        self.conv1 = BlockFCNConv(channels[0], channels[1], kernels[0], momentum=mom, epsilon=eps, squeeze=True)\n",
        "        self.conv2 = BlockFCNConv(channels[1], channels[2], kernels[1], momentum=mom, epsilon=eps, squeeze=True)\n",
        "        self.conv3 = BlockFCNConv(channels[2], channels[3], kernels[2], momentum=mom, epsilon=eps)\n",
        "        output_size = time_steps - sum(kernels) + len(kernels)\n",
        "        self.global_pooling = nn.AvgPool1d(kernel_size=output_size)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        # apply Global Average Pooling 1D\n",
        "        y = self.global_pooling(x)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mFYGCNCqPQfq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM-FCN"
      ]
    },
    {
      "metadata": {
        "id": "QQznEOKCKygx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LSTMFCN(nn.Module):\n",
        "    def __init__(self, time_steps, num_variables=1, lstm_hs=256, channels=[1, 128, 256, 128]):\n",
        "        super().__init__()\n",
        "        self.lstm_block = BlockLSTM(time_steps, 1, lstm_hs)\n",
        "        self.fcn_block = BlockFCN(time_steps)\n",
        "        self.dense = nn.Linear(channels[-1] + lstm_hs, num_variables)\n",
        "        self.softmax = nn.LogSoftmax(dim=1) #nn.Softmax(dim=1)\n",
        "    def forward(self, x):\n",
        "        # input is (batch_size, time_steps), it has to be (batch_size, 1, time_steps)\n",
        "        x = x.unsqueeze(1)\n",
        "        # pass input through LSTM block\n",
        "        x1 = self.lstm_block(x)\n",
        "        x1 = torch.squeeze(x1)\n",
        "        # pass input through FCN block\n",
        "        x2 = self.fcn_block(x)\n",
        "        x2 = torch.squeeze(x2)\n",
        "        # concatenate blocks output\n",
        "        x = torch.cat([x1, x2], 1)\n",
        "        # pass through Linear layer\n",
        "        x = self.dense(x)\n",
        "        #x = torch.squeeze(x)\n",
        "        # pass through Softmax activation\n",
        "        y = self.softmax(x)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZXyATnq7WOKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "BCHDSTVzRKGR",
        "colab_type": "code",
        "outputId": "a56c7276-953d-4d66-f925-3fb95330edb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "time_steps = X_train.shape[1]\n",
        "num_variables = classes\n",
        "\n",
        "time_steps, num_variables"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "i9eJ3zlrWV7A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = LSTMFCN(time_steps, num_variables).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b27y39-dh0Ik",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "look at the different blocks of the Model"
      ]
    },
    {
      "metadata": {
        "id": "i0c4x4NViexX",
        "colab_type": "code",
        "outputId": "4e57e2a6-05a7-4b77-b4c2-6c7d73346c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "# model summary\n",
        "for m in model.children():\n",
        "    print(m.training)#, m)\n",
        "    for j in m.children():\n",
        "        print(j.training, j)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True LSTM(512, 256)\n",
            "True Dropout(p=0.8)\n",
            "True\n",
            "True BlockFCNConv(\n",
            "  (conv): Conv1d(1, 128, kernel_size=(8,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "True BlockFCNConv(\n",
            "  (conv): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(256, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "True BlockFCNConv(\n",
            "  (conv): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "True AvgPool1d(kernel_size=(499,), stride=(499,), padding=(0,))\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xeWqQhn9XPUU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "look at the parameters (i.e. weights) in each layer"
      ]
    },
    {
      "metadata": {
        "id": "-F4_pcUqW8He",
        "colab_type": "code",
        "outputId": "e182d538-c2ec-40c6-e868-60ea73500d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "[p.shape for p in model.parameters()]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([1024, 512]),\n",
              " torch.Size([1024, 256]),\n",
              " torch.Size([1024]),\n",
              " torch.Size([1024]),\n",
              " torch.Size([128, 1, 8]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([256, 128, 5]),\n",
              " torch.Size([256]),\n",
              " torch.Size([256]),\n",
              " torch.Size([256]),\n",
              " torch.Size([128, 256, 3]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([2, 384]),\n",
              " torch.Size([2])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "vUO4oNKkxAYs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define a learner class to automate the learning process"
      ]
    },
    {
      "metadata": {
        "id": "RnEiGUWHw_kX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SimpleLearner():\n",
        "    def __init__(self, data, model, loss_func, wd = 1e-5):\n",
        "        self.data, self.model, self.loss_func = data, model, loss_func\n",
        "        self.wd = wd\n",
        "        \n",
        "    def update(self, x,y,lr):\n",
        "        y_hat = model(x)\n",
        "        # weight decay\n",
        "        w2 = 0.\n",
        "        for p in model.parameters(): w2 += (p**2).sum()\n",
        "        # add to regular loss\n",
        "        loss = loss_func(y_hat, y) + w2 * self.wd\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            for p in model.parameters():\n",
        "                p.sub_(lr * p.grad)\n",
        "                p.grad.zero_()\n",
        "        return loss.item()\n",
        "\n",
        "    def fit(self, epochs=1, lr=1e-3):\n",
        "        history = {\n",
        "            'losses'  : [],\n",
        "            'accuracy': []\n",
        "        }\n",
        "        for i in tqdm(range(epochs)):\n",
        "            losses = []\n",
        "            for x,y in self.data[0]:\n",
        "                losses.append(self.update(x, y , lr))\n",
        "            history['losses'].append(np.mean(losses))\n",
        "        return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "txh5ujbKXhuz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "train the model using the DataLoader"
      ]
    },
    {
      "metadata": {
        "id": "GMAfJH9KAY0h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# depending on the number of classes, use a Binary Cross Entropy or a Negative Log Likelihood loss for more than two classes\n",
        "loss_func = nn.NLLLoss().cuda() # weight=weights\n",
        "acc_func = accuracy_thresh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xxVx2A1pXtuY",
        "colab_type": "code",
        "outputId": "16d43dd0-5616-4276-f6c9-b8708ba73a1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "lr = 2e-2\n",
        "learner = SimpleLearner([train_dl, test_dl], model, loss_func)\n",
        "history = learner.fit(10)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  3.68it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4W1s1mql_ELt",
        "colab_type": "code",
        "outputId": "f3837b10-36b6-4bf7-bec6-2c9246d63d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history['losses'])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc06621a978>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYQIQBLuQggRgP4/U5R+qeNWZCkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc06a48acc0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IDwkjDH5rXCy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = DataBunch(train_dl=train_dl, valid_dl=test_dl, path=path)\n",
        "learner = Learner(data, model, loss_func=loss_func, metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jhv_-NkEknVO",
        "colab_type": "code",
        "outputId": "b4666c8a-08a5-4894-a705-ac93cce563cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "cell_type": "code",
      "source": [
        "learner.unfreeze()\n",
        "learner.lr_find()\n",
        "learner.recorder.plot()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "        \t/* Turns off some styling */\n",
              "        \tprogress {\n",
              "\n",
              "            \t/* gets rid of default border in Firefox and Opera. */\n",
              "            \tborder: none;\n",
              "\n",
              "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "            \tbackground-size: auto;\n",
              "            }\n",
              "\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='15' class='' max='17', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      88.24% [15/17 00:04<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>0.740351</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>2</th>\n",
              "    <th>0.749706</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>3</th>\n",
              "    <th>0.757423</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>4</th>\n",
              "    <th>0.758472</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>5</th>\n",
              "    <th>0.754108</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>6</th>\n",
              "    <th>0.750802</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>7</th>\n",
              "    <th>0.741937</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>8</th>\n",
              "    <th>0.721828</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>9</th>\n",
              "    <th>0.687558</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>10</th>\n",
              "    <th>0.637464</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>11</th>\n",
              "    <th>0.579710</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>12</th>\n",
              "    <th>0.515537</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>13</th>\n",
              "    <th>0.461293</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>14</th>\n",
              "    <th>0.453481</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>15</th>\n",
              "    <th>0.688830</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "\n",
              "  </tr>\n",
              "</table>\n",
              "\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "        \t/* Turns off some styling */\n",
              "        \tprogress {\n",
              "\n",
              "            \t/* gets rid of default border in Firefox and Opera. */\n",
              "            \tborder: none;\n",
              "\n",
              "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "            \tbackground-size: auto;\n",
              "            }\n",
              "\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='6', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl8lPW5///XTCb7DhlCwg6Bi10E\nRHADRa3UpVpR29oqnvZ0OdavPd2Onvac1vb46+n51eOxPeerbU9ba1u3WjfcFRdQUJBVAlzsa0J2\nsm+Tme8fM4kxJBAg99yT5Ho+Hj7M3HPfc78nCbnms9yf2xMKhTDGGGMAvG4HMMYYEzusKBhjjOlg\nRcEYY0wHKwrGGGM6WFEwxhjTwed2gDNVVlbr+PSp7OwUqqoanD6NYyy/uyy/u/p7fnDmPfj96Z7u\ntltLoRd8vji3I5wRy+8uy++u/p4fovserCgYY4zpYEXBGGNMBysKxhhjOlhRMMYY08GKgjHGmA5W\nFIwxxnSwomCMMaZDv794bTALhUK8X1jCjoNVJCbEkZzgIykxjqzURIYPTSE3O4WUJPsRG2N6z/5i\nOKyhqZX/fWE7xRX1yOgspowZwuQx2aQl+2hoClDfFKChKUBOVhIZKQm9ft2ahhb++PIONu4qP+F+\nGakJpCXHEwgECREiFII4rwefz4vP6yU+3ktGSgKZaQlkpSaQk5nMWQU5VkyMGaTsX76DaupbuO+J\nTRwqrSPe52Xl5mJWbi7ucf+czCTG5WUwNi+d9OQEEuK9JMTHkRgfR3pKPBkp4T/wW/dV8vuXtlNT\n38Lk0VncdMlEAJpaAjQ2t1FZ28TRygaOVjZQUtlAY3OAUCiEx+PB44HWliCBxlZa24K0BoJ0vc9S\ngs/LvCm5LJyVz/j8DDyebq+GN8YMQI4WBRG5H5gPhIA7VXVdZPsI4C+ddh0P3AUkAD8F9kS2v66q\n9zqZ0SkV1U384olNlFQ2sOjsEXzh0okcKq1j+4EqdhyoojUQJDU5ntQkH0kJPkqqGthbVMO6HaWs\n21Ha4+t6PHR82r/x4gIunzcK70n+aPv96ZSV1Xb7XDAUoq6xleq6Fqrrmtl/tJZVW4p496Ni3v2o\nmLyhKcycMJRp44YwaWQWCfH9f8kAY0zPPE7djlNEFgLfU9WrRGQK8HtVXdDNfj7gbeAKYCkwXVW/\n29vzRGNBvBP9Ue3OodI6HnhqM5U1zSyZP5qlCyf06tN2KBSivLqJgyW1NDa30RJoo6U1SFNLgNqG\nVmrqW6hpaCHB5+WGiwsYnZvuSP5gKMT2/VW8vekIm3dXEGgLAuCL8zIuL528oSkMH5LK8CEpDB+a\nQk5mEr445+YsnGr+WGP53dXf84Mz76GnBfGcbCksBp4FUNXtIpItIhmqWtNlv2XA31S1TkQcjHNi\nbcEgpVWNkS6XRkqqGmhpbSMEJCbE09LSypjhGUwfN4S8oSnH/ZFvDbSxXst4Z1MReugYANcvHM+V\nC8b2OoPH48GflYw/K7kP39mp83o8TBs3hGnjhtDS2sauw9UU7qukcH8lu49Us+tw9XH752QmMWxI\nMpmpCZEBbx8piT6GZCTiz0pmWHYyyYk+SirDLaK9RTUUV9QTCIYIBUMEQyGSEnxMGJHBpFFZTMjP\nJDnRejeNiTYn/9UNB9Z3elwW2da1KHwFuLzT44Ui8goQD3xXVTc6mBEI9/3/7C8bKKk88dK0awpL\nABiSkcikUVmEQtDYHKCxOUBReT31TQEApozJ5rK5o5g1Mcfp6I5LiI/rKBAArYEgpVUNFFc0UFzZ\nQGllAyVV4SK6dW/lCV/LF+ch0PbJhp3HEy4qXq+HQCDI9gNVwAG8Hg/j8tOZM2kYly0Yi3VaGRMd\n0fwodlxTRUQWADs6tR7eB8pU9cXIc48AM070otnZKWe0rGygLch9T26mpLKBc6cNR8ZkM3JYGvn+\nNFIS4/F4wn+4mlvbKNxTwcadZWzaWcr7kQIB4eeHZCRxxYKxXH7uGPL9aaedxyl+f++6mnojPy+T\nWd1sr29spbahhYamAA1NrdQ3tlJS1cDRigaKy+uprGlidG46k0ZnI2OyGZefQXynn11dYys79ldS\nuLeCrXvK2Xmwij1Hanjyrd1MGJnJ2ZOGMT4/k7H5GeT704jz9p8B8L78/rvB8rsvWu/ByTGFHwPF\nqvrryOO9wFmqWttpn3uB7ar65x5e4ygwQlXbejrPmY4p/Pk15c0NR5grfr5x7fRu+/679ucFgyHK\nqhtJ8MWRlBD+L5Zn6PTXPtWahhY27izjo31VbN5VRlvw4x91QryXiSOzmFWQw6yCHIZmJrmY9MT6\n6/e/neV330AZU3gNuAf4tYjMBoo6F4SIc4DH2x+IyPeBQ6r6mIhMJ9xq6LEgnKmVm4t4c8MRRvpT\n+bsrp/T6D7vX6yE3O8WpWCYiIyWBhbNGsPSyyRw4VMmBo7UcKq3jYGkdB0pqw+Mc+yr5y+s7GTUs\njfOnD+eCmXmkJMW7Hd2YfsuxoqCqq0VkvYisBoLA7SKyDKhW1Wciu+UBnedfPgr8SUS+Hsn2Zafy\n7T5SzZ9fU1KTfHzz+pkkJdigZixLSYpnytghTBk7pGNbZU0Tm3eXs3F3OTsOVPH4m7t5ZtU+Fkwf\nzuLZIxgRg914xsQ6x7qPouV0u49+8fhGth+o4ts3zWJapz803envzc/BkL+usZWVm4t4a8NhKmqa\ngfCA/+I5I5lVkIPXxfGHwfD9j2X9PT8MnO6jmHb9wgk0NQc+8cnT9F9pyfF8ev4Yrpg3mk27y3nj\nw0NsP1DF9gNVDM1IYvGckSyclW/TXI05iUH7L2RcXobbEYwDvF4Psyf5mT3Jz+GyOt5cf5jVhUd5\n8q3dvLhmP5fNHcWlc0fauIMxPbCls82ANdKfxi1XTOa+28/nuovGA/Dsu/v43oOreXrlXmobWlxO\naEzsGbQtBTN4pCbFc/V5Y7l0zkje3niEV9Ye5IXV+3l93SEWnZ3Pp+aNJist0e2YxsQEKwpm0EhO\n9LFk/hgumTOSlZuKePmDA7y69hAr1h/h/BnDufjsEb1eT8qYgcqKghl0EuPjuOycUSw6ewTvbS3m\n5fcP8M6mIt7ZVMSEERksmjWCeVOGfeJqa2MGCysKZtCK93lZNGsEF83MZ8ueCt7edISP9lSw50gN\nT6/cy9JFEzh3au5JlyY3ZiCxomAGPa/Xw6yJOcyamEPZsUbe3HCYFeuP8Nvl21ix/jCfXzyRCSMy\n3Y5pTFTY7CNjOvFnJXPTJRO59+/PZe7kYewtquHeP63nyTd3098v9DSmN6ylYEw3/FnJ/MO109l5\n6Bh/fGUHr6w9SENzK7d8arKrV0cb4zRrKRhzApNGZXHXzbMZk5vOys3F/PaFbR13ojNmILKiYMxJ\npKck8L3Pn03ByEw+2FbCg89upbnVscV7jXGVFQVjeiElycd3bpzF1LHZbNxVzl2/XsPrHx6iNWDF\nwQwsVhSM6aXEhDjuXDqTKxeMoam5jcfe2MU/PbSGFesP0xa0LiUzMFhRMOYUxPviuH7hBP7jGwtY\nMn80jc1t/OX1nfz8LxspP9bodjxjzpgVBWNOQ3pKAjcsKuDn31jAvCnD2H2kmh/9YR3rdpSe/GBj\nYpgVBWPOQEZKAl+7Zhq3LZlMWzDIg89u5Q8vbaepJeB2NGNOi12nYMwZ8ng8XHhWPgUjM3nouUJW\nbSlmx8EqvnzlVCaNynI7njGnxFoKxvSRvKGp/PCWuSyZP5ry6iZ+/pcNPPnWblps+qrpR6woGNOH\n4n1eblhUwN03z8GflcwrHxzk2//1DkfK6tyOZkyvWFEwxgEFIzO55+/mcfHZIzhwtJaf/vFDVm4u\nsvWTTMyzomCMQxIT4vjSp4S7bz0HX5yXh1/ewW+Wb6Ox2QahTeyyomCMw86bmc+PbzuHCfkZfLCt\nhJ88vI7D1p1kTsHh0lq+8z/vsW1/pePncnT2kYjcD8wHQsCdqrousn0E8JdOu44H7gL+CjwMjAHa\ngNtUda+TGY2JhpysZP7p5tk8vXIvr3xwkH975ENuWzKFc6fmuh3N9AM79ldRVdvMa+sOMXXsEEfP\n5VhLQUQWAhNVdQHwZeCX7c+p6hFVXaSqi4BLgYPA88AXgGOqegFwL/Azp/IZE22+OC83XlzAP1w7\nHa/Hw6+fL+SxN3bZqqvmpGobWgDYureSmvoWR8/lZPfRYuBZAFXdDmSLSEY3+y0D/qaqdZFjnols\nfwM438F8xrhi7uRh/Mutc8kbmsLrHx7ijy/vcDuSiXHtRSEYCrF2e4mj53Ky+2g4sL7T47LItpou\n+30FuLzTMWUAqhoUkZCIJKhqj6UxOzsFXxRusO73pzt+DidZfnd1ze/3p/PAd3L4/q9WsabwKMuu\nmc7woakupTu5gfb97286tw7W7yzn80umOnauaF7RfNztqkRkAbBDVbsWih6P6aqqquFMc52U359O\nWVmt4+dxiuV314nyXzZ3JL9dvo0nXtvBFy6dFOVkvTOQv//9RXtLYXRuGnqwiq1aQu6QlDN6zZ4K\npZPdR0WEP/m3yweKu+xzFeFuouOOEZF4wHOiVoIx/d05k4eRnZ7Iqi3FNDS1uh3HxKja+vDvxqVz\nRgGwpvCoY+dysii8BiwFEJHZQJGqdi3X5wCbuxxzQ+Trq4G3HMxnjOt8cV4unTOS5pY23tlU5HYc\nE6NqG1pIToxj7mQ/CfFe3i8scexCSMeKgqquBtaLyGrCM49uF5FlInJdp93ygM5rDT8BxInIu8Dt\nwN1O5TMmViyclU9iQhxvrD9sM5FMt2rqW0hNiicpwcfsiX5KjzWyt6inXvcz4+iYgqre1WXT5i7P\nz+jyuA24zclMxsSalKR4LpyZxxsfHmbdjlIWTBt+8oPMoBEKhahtaGFETngiwvxpw3l/WwlrCo8y\nYURmn5/Prmg2JgZcNncUHg+8uvagrY9kPqGlNUhrIEhacjwA08Zlk54Sz9rtpY60LK0oGBMD/FnJ\nzJnk52BJHYVRWMrA9B91jeFB5vaiEOf1cu6UXOoaWzlU2vfLpVhRMCZGfOrc0QD88qmPWP7ePhtf\nMMDHRSE1UhQArr1wHMuWTGZ0blqfn8+KgjExYkJ+JrdfN4PUZB/PrNrHj36/lp2Hjrkdy7isrumT\nLQUIj0NddFY+cd6+/xNuRcGYGDJH/Nz7lflcPHsERysa+Pe/bOC1dYfcjmVcVN94fFFwkhUFY2JM\nSpKPL10u3P2lOWSmJfD4il2891HX6z7NYPFx91F0FqCwomBMjCoYkcl3bppFapKPP7y0g407y9yO\nZFzQdaDZaVYUjIlhI/1pfOuGs4j3eXnwuUK2H6hyO5KJMisKxphPmDAik29+dgahUIhf/m0L+4qd\nuZLVxKaOMYUkKwrGmIhp44bwtWum0dLaxv1PbqaovN7tSCZK6hrD9/ROtZaCMaazuZOHcesVk6lr\nbOW+JzZRUd3kdiQTBXWNrfjiPCQlOH/fGLCiYEy/ctFZ+dywaAJVtc384olNjt+a0bivvrGV9JQE\nPJ6T3l6mT1hRMKafWTJ/DEvOHU1JZQP3P7mZppaA25GMg+oaW0lPTYja+awoGNMPLV00gQtn5nGg\npJY/vLTDFtEboNqCQRqaA6SnWFEwxpyAx+PhS58SCkZmsm5HKa+utaueB6KGpnArMMNaCsaYk/HF\nebn92ulkpiXw17d3s81WVx1w2q9RsJaCMaZXMtMSuf26GXg9Hh56rpDy6ka3I5k+VB+ZjpqeEp3p\nqGBFwZh+r2BEJl+4bBJ1ja38zzNbaQ3YktsDRXtLwbqPjDGnZNGsfM6fMZwDR2t56u09bscxfcS6\nj4wxp8Xj8fDFy4S8oSm8/uEhNu0udzuS6QMdRcFaCsaYU5WYEMfXPzMdX5yX37+4naraZrcjmTNU\n32QtBWPMGRg1LI3PLS6grrGV3y4vJBi06xf6MxtTMMacsYvPHsHsSX52HDzGi2v2ux3HnAE3xhQc\nvZWPiNwPzAdCwJ2quq7Tc6OAx4AEYIOqfl1EFgF/BQoju32kqnc4mdGYgcbj8bBsyWT2HKnm5Q8O\n8ql5o0mIj85iaqZv1XcUhXgqm6KzzpVjLQURWQhMVNUFwJeBX3bZ5T7gPlWdB7SJyOjI9ndUdVHk\nPysIxpyGtOR4zpsxnKaWNrbsqXA7jjlNdY2tJCf6iIuLXqeOk2daDDwLoKrbgWwRyQAQES9wIfB8\n5PnbVfWgg1mMGXTOnZILwAfbS1xOYk5XXWMraVG6N3M7J882HFjf6XFZZFsN4AdqgftFZDawSlXv\njuw3VUSeB4YA96jq6yc6SXZ2Cj6f801jvz/d8XM4yfK7y438OTlpjMpNY8ueClLSks7oJi32/Y++\nUChEfVOAsXkZQPTeQzRLkKfL1yOAB4D9wIsiciWwCbgHeBIYD7wlIgWq2mNnWlVVg2OB2/n96ZSV\n1Tp+HqdYfne5mX/uJD/PrNrH62v2cf6MvNN6Dfv+u6O5pY3WQJDE+HCHTl+/h56KjJPdR0WEWwbt\n8oHiyNflwAFV3aOqbcAKYJqqHlHVJ1Q1pKp7gKOEi4cx5jTMmxrpQtpmXUj9TfvMo7Qo3YaznZNF\n4TVgKUCki6hIVWsBVDUA7BWRiZF95wAqIjeLyHcjxwwHcoEjDmY0ZkDLzU5hXF462/ZXUdNgd2nr\nTzqKQtIAKQqquhpYLyKrCc88ul1ElonIdZFdvgX8IfJ8NbCc8MDzQhFZBTwHfONEXUfGmJM7d0ou\nwVCID3eUuh3FnIK6JndaCo6OKajqXV02be703G7ggi7P1wJXO5nJmMHmnCm5PPHmbj7YVsIls0e6\nHcf0Uvs1CmcyQeB02BXNxgxw2emJyOgsdh2upqK6ye04ppcG4piCMSZGtA84v7/tqMtJTG9ZUTDG\nOGauDCMxPo5nVu7jzQ2H3Y5jesGKgjHGMWnJ8fzjjWeRmuzjz6/t5JFXlUCb3aEtln08phDdK5qt\nKBgzSEwalcW/3noOo4al8fbGI9z3+KaOT6Mm9tRF7s9sLQVjjGOGZibxz1+cwxzxo4eO8ZvlhYRC\nds+FWFTX2IovzkNilFe4taJgzCCTmBDHN66dzrSx2WzdW8n7drVzTKpvbCU1OR6Px3PynfuQFQVj\nBiGvx8MtV0wmId7LY2/ssqudY1B4hdTodh2BFQVjBi1/VjKfvXA8dY2tPP7GLrfjmE7agkEamgNR\nX+ICrCgYM6hdOncU4/LSeX9bCVv2lLsdx0TUN7kzyAxWFIwZ1LxeD8uWTCHO6+GRV5XG5oDbkQzu\nLXEBVhSMGfRGDUtjyfwxVNY088dXdthspBhQURNejiQ7PTHq57aiYIzhmvPHMnFkJmu3l/LS+wfc\njjPolUfWqMrJTIr6ua0oGGPwxXn5h+tmkJ2eyNPv7GXLngq3Iw1q5cfCRcGflRz1c1tRMMYAkJma\nwDc/OwOfz8uvny/kaKXzt7o13SuvbgSspWCMcdm4vAxuvUJobA7wq79tsYFnl5QdayLO6yErLUbH\nFERkjohcFfn6XhFZISIXOhvNGOOG86bncdncURRXNPDUO3vcjjMolVc3MjQzCa83ulczQ+9bCr8k\nfA/lC4FzgDuAexxLZYxx1dJFE8gbmsJbG46wbZ+NL0RTU0uA2oZW/C50HUHvi0KTqu4CrgF+o6rb\nAFt315gBKt7nZdmSyXiAXz25idZAm9uRBo32u+PluDDIDL0vCqkicgNwHfCaiAwBsp2LZYxx28SR\nWVw8ewSHS+tYvtqmqUZLmYvTUaH3ReFu4Gbgn1W1Bvg/wH86lsoYExOuXziBnMwkXn7/AIdK69yO\nMyiUHwvPPHJjOir0siio6lvALar6pIjkAiuAxxxNZoxxXXKij39YehZtwRAPv7ydYNCudnZa+4Vr\nQ2O5pSAivwJuiHQbrQa+CTzoZDBjTGw4Z+pw5k0Zxr7iWlZuKXI7zoBX1t5SyHSnpdDbm3+erap3\niMjXgYdV9acisuJkB4nI/cB8IATcqarrOj03inBrIwHYoKpfP9kxxhh33HTJRDbvruDpd/ZyzuRh\npLqwpPNgUVHdREK8l/QUd77HvR1TaJ8sexWwPPL1Ca+qEJGFwERVXQB8mfC01s7uA+5T1XlAm4iM\n7sUxxhgXZKcnctV5Y6hrbOW5d/e5HWdAK6tuwp+ZHPU7rrXrbVHYKSLbgHRV3SQitwCVJzlmMfAs\ngKpuB7JFJANARLzAhcDzkedvV9WDJzrGGOOuy88ZzbCsZN5cf4Qj5fVuxxmQ6ptaaWwOuDbzCHrf\nffQVYAawLfK4kMgf9BMYDqzv9Lgssq0G8AO1wP0iMhtYpap3n+SYbmVnp+DzOX9ja78/3fFzOMny\nu2ug5P/qdTP4tz+s5W8r9/KTry5w7dPsqeov3//qw8cAGJWXcVzmaL2H3haFZOBq4CciEgLeB/7r\nFM/l6fL1COABYD/woohceZJjulVV5fyiXX5/OmVltY6fxymW310DKf+4YalMHzeETTvLeH31Ps6e\n5Hc53cn1p+//rsjV46kJcZ/I7MR76KnI9Lb76LdABvDryNe5kf+fSBHhT/nt8oHiyNflwAFV3aOq\nbYSnuE47yTHGGJd5PB4+f+lE4rwennhrN0G7IU+f+vg+Cu7MPILeF4VcVf2eqr6oqi+o6reAkSc5\n5jVgKUCki6hIVWsBVDUA7BWRiZF95wB6omOMMbEhb2gqC6YPp7SqkR0HqtyOM6C0L5ntz3JvTOFU\nlrlIaX8gIqnACVOr6mpgvYisJjyL6HYRWSYi10V2+Rbwh8jz1cDy7o45tbdjjImGC2fmAfDeR9aQ\n70ux0FLo7ZjCr4EdIvJh5PEc4F9OdpCq3tVl0+ZOz+0GLujFMcaYGFMwIpNh2cms1zK+eHmA5MTe\n/ikxJ1J2rJHUJB8pSe59P3u7zMXvgfOBPwIPA+cBU52LZYyJZR6Ph/OnD6clEGTdjlK34wwIoVCI\niuomV1sJ0PuWAqp6CDjU/lhE5jmSyBjTL5w3PY9nV+3jvY+KueisfLfj9Hs19S20BIKuXqMAZ3Y7\nzv4xQdkY44ihmUlMHpPNrsPVlERhavhA17FktouDzHBmRcHmohkzyF0wo33A+ajLSfq/9plHMd19\nJCKH6P6PvwfIcSSRMabfmD3JT1JCHKu3FnPthePw9pMrnGNR+bFwS8HN6ahw8jGF42YHGWNMu8SE\nOM6ZPIxVW4rZcaCKqWOHuB2p3+oXLQVVtXvwGWNO6PwZeazaUszbG49YUTgDZcfcvQ1nuzMZUzDG\nGCaOzGT0sDQ+1DJeW3vQ7Tj9Vnl1IxmpCSTEO7/A54lYUTDGnBGPx8M3r59BVloCj7+5m7XbS9yO\n1O8EgyEqa5rxu9xKACsKxpg+kJOZzD/eOIvkxDj+94VtbLc1kU5JTUMLbcEQ2RlWFIwxA8SoYWl8\n87MzAfjvp7dwqLTO5UT9R3VdCwBZqQkuJ7GiYIzpQ1PGZPOVq6bS2NzGb5YX0hYMuh2pXzhW1wxA\nZpoVBWPMADNvSi4XzMzjSFk9KzcVuR2nX6iuj7QU0hJdTmJFwRjjgOsvGk9SQhzPrNpHfVOr23Fi\nnrUUjDEDWmZaIledN5a6xlaWv7ff7Tgx7+MxBWspGGMGqMvmjsKflcSK9Ycprqh3O05Ms5aCMWbA\ni/d5ufHiibQFQzzx5m6348S06voW4rwe0pLj3Y5iRcEY45zZk3KYPDqLLXsq2Lq3wu04Mau6rpnM\ntAQ8MbCgoBUFY4xjPB4Pn1s8EY8HHluxi0CbTVHtKhQKUV3fQmYMjCeAFQVjjMNG56Zz0Vn5FFc0\n8I5NUT1OfVOAQFuIrBgYTwArCsaYKLjuwvEkJ8bx7Kq91DXaFNXOPh5ktpaCMWaQyEhN4OrzxlHf\nFOD5d/e5HSemxNISF2BFwRgTJZfOHcmw7GTe3HCEonKbotoulqajwsnvvHZGROR+YD7hW3reqarr\nOj23HzgEtEU23QxMBP4KFEa2faSqdziZ0RgTHb44LzddUsCv/vYRj7+5i2/fOMvtSDGhvSjEwhIX\n4GBREJGFwERVXSAiU4DfAwu67LZEVes6HTMReEdVlzqVyxjjnlkFOUwZk83WvZVs3VvB9PFD3Y7k\nuo7uoxgpCk52Hy0GngVQ1e1AtohkOHg+Y0yM83g83HRJAQDPvbePUCjkciL3HYsshjcYuo+GA+s7\nPS6LbKvptO0hERkLvAvcHdk2VUSeB4YA96jq6yc6SXZ2Cj6f87ev8/vTHT+Hkyy/uyz/J1/r3GnD\n+aDwKEdrmplZ4O+z1z7ROWNVQ3MArwfGjxlKnLfni9ei9R4cHVPoouu7/VfgFaCScIviemANcA/w\nJDAeeEtEClS1pacXrapqcCZtJ35/OmVltY6fxymW312W/3iXzx3JB4VH+dOL2/j+F2b36Wt3Fevf\n//KqRtJTEqis6PmmRE68h56KjJNFoYhwy6BdPlDc/kBVH2n/WkReAmao6lPAE5HNe0TkKDACsDls\nxgwg4/IymD5uCFv3VbLr8DEmjsxyO5IrQqEQx+qbGT4kxe0oHZwcU3gNWAogIrOBIlWtjTzOFJFX\nRaS9E20hsFVEbhaR70b2GQ7kAkcczGiMccnV548FYPnq/a7mcFNTSxstrcGYGWQGB1sKqrpaRNaL\nyGogCNwuIsuAalV9JtI6eF9EGoGNwFNAGvCoiHwGSAC+caKuI2NM/zVxZBaTR2exdW8l+4prGJc3\n+OahdFyjECMXroHDYwqqeleXTZs7PfcA8ECX52uBq53MZIyJHVefN5YdBzfxwur93HH9TLfjRF37\ndNRYWeIC7IpmY4yLJo/JZsKIDDbuKmf/0ZqTHzDAHKtvv3AtdloKVhSMMa7xeDx89qIJAPz5tZ0E\nB9l1Cx0thRhZNhusKBhjXDZlTDbzpgxjb1EN724pPvkBA8jHVzNbS8EYYzrcdMlEEuPjeOrtPYNq\nae327qNYuZoZrCgYY2JAdnoin7lgHHWNrTy9cq/bcaLGuo+MMaYHl84dSd7QFN7ZeGTQDDofq2sm\nNclHvC92/hTHThJjzKDmi/PyxcsmEQL+9OrgGHSurmuJqQvXwIqCMSaGTBk7hLmTh7GvuIbCfZVu\nx3FUS2sbDc2BmBpPACsKxpjbaXa9AAASRklEQVQYc+X8MQC8vu6Qy0mc1bFkdgyNJ4AVBWNMjBkz\nPJ1Jo7LYuq+SIwP4tp3VdbF34RpYUTDGxKDL5o4CYMWHA7e1EItLXIAVBWNMDDp7Yg45mUms3np0\nwF63cMxaCsYY0zter4dL54ykJRDknU0Dc/X86vrYujdzOysKxpiYdMHMfBIT4nhzwxECbUG34/S5\njmWzraVgjDEnl5Lk48KZeVTVNrNey9yO0+c61j2y2UfGGNM7l84ZiQd4Ze3BAXcx27G6FpIS4khM\niHM7yidYUTDGxKxh2SmcM2UYB47Wsmpzkdtx+kxzSxslVQ34s5LdjnIcKwrGmJh20yUTSU6M48m3\n9nT0w/d32/ZX0hoIMnPCULejHMeKgjEmpmWnJ7J0UQGNzQEefWOX23H6xMbd5QDMmpjjcpLjWVEw\nxsS8hbPyKRiRyYc7Stm0q9ztOGckGAyxeXc5GakJjMvLcDvOcawoGGNintfj4dYrhDivhz+/rjQ2\nB9yOdNr2FtdQ29DKWROG4vV43I5zHCsKxph+YYQ/jU/PH0NlTTPPrOq/N+Jpb+nEYtcRWFEwxvQj\nV503hmHZyby14QglVQ1uxzktm3aXE+/zMnXsELejdMvn5IuLyP3AfCAE3Kmq6zo9tx84BLRFNt2s\nqkdOdIwxZnCL98Vx/cIJPPjsVp5ZuZevf2a625FOSWlVA0Xl9cwqyCExPrauT2jnWFEQkYXARFVd\nICJTgN8DC7rstkRV607xGGPMIDZX/IzLS2ft9lI+Na8mJgdre7JpdwUQu11H4Gz30WLgWQBV3Q5k\ni8jJfnqnc4wxZhDxeDwsXVQAwFNv7yHUj6503rQrvFzHWTF4fUI7J7uPhgPrOz0ui2zrfEfuh0Rk\nLPAucHcvj/mE7OwUfD7nm2F+f7rj53CS5XeX5e9bfn86KzYeYcOOUg5XNTFbhp10f7fVNbSw83A1\nk0ZnUTDu1FsK0XoPjo4pdNF17tW/Aq8AlYRbB9f34pjjVEVhsMnvT6esrNbx8zjF8rvL8jvjmgVj\n2LijlN89+xEjbjunx+mdsZL//cKjBIMhpo0dcsp5nHgPPRUZJ7uPigh/ym+XDxS3P1DVR1S1VFUD\nwEvAjJMdY4wx7UbnpnPutFwOltbxQWGJ23FOavOe8HjC2QWxO54AzhaF14ClACIyGyhS1drI40wR\neVVE2hcSXwhsPdExxhjT1XUXjife5+XRN3ZSWdPkdpwTOlRaR3JiHCP8qW5HOSHHioKqrgbWi8hq\n4JfA7SKyTESuU9Vqwq2D90XkPcJjB091d4xT+Ywx/Z8/K5nPXzqR+qYADz1fSFswNm/GEwyFKK1q\nZFh2Cp4YvIq5M0fHFFT1ri6bNnd67gHggV4cY4wxPVp4Vj47DlSxdnspz67ax/ULJ7gd6TiVNU0E\n2oLkZsfeUtld2RXNxph+zePxcOsVkxmWlcxLaw6wdV+F25GOU1LVCEBudorLSU7OioIxpt9LTvTx\n9Wun4fV6+O3ybVTVxtZ9F0orw7Mkc4dYS8EYY6Ji7PAMbrykgNqGVu7904ccOBo7c1SspWCMMS64\ndM5IPnvReKpqmvnZn9ezdntsTFUt6WgpWFEwxpio8Xg8XHXeWO64fiZer4eHnivkkZe2EXR5KYyS\nqkZSk3ykJce7mqM3rCgYYwacWRNz+MEtcxmWlcxfV+zixdX7XcvSFgxSdiw8HbU/sKJgjBmQRuSk\n8oNb5pCTmcRz7+5nz5FqV3JU1DTTFgz1i0FmsKJgjBnA0lMS+PYX5hAKhfjN8kJXbuPZMfPIWgrG\nGOO+GQU5LJk/hrJjTTz6+s6on//jmUfWUjDGmJhw7YXjGDs8nfe2Ho36jKT+NPMIrCgYYwYBX5yX\nr14zjYR4L398RTlWF72L26ylYIwxMWj4kBRuWFRAY3OAl9YciNp5S6oaSEuOJyUp9qejghUFY8wg\nsnBWPjmZSby9qSgqS2EE2oKUH2vqNzOPwIqCMWYQ8cV5ufq8sQTagry4Zr/j56uobiIYCvWbmUdg\nRcEYM8gsmD4cf1YSKzcXUVHt7I15Sqrap6NaS8EYY2KSL87LNeePI9AW6tPWQlVtM6+tO0RzS1vH\ntpLKyCBzP5l5BFYUjDGD0PxpueRmJ7NqSzHlxxrP+PVqG1r4/x/byOMrdvH86n0d2z9uKVhRMMaY\nmBXn9XLNBeNoC4Z4Yc3+M3qtppYA//XXzRytbCDO6+GNDw93DGK3T0cdZt1HxhgT286dkkve0BTe\n3XKUwv2Vp/UagbYg//P0R+wrruWCGXl88fJJtAaCLH8v3FooqWwgIzWB5ERH73zcp6woGGMGJa/X\nw21LpuD1woPPbKW4ov6Ujm8LBvndi9sp3F/FrIIcbl0iXDAzj9whKazcXMyRsjoqapr61SAzWFEw\nxgxiBSMzWbZkMg3NAR54agt1ja29Ok4PVvHjP6zjg20lFIzM5GufmUac10uc18v1F40nGArxuxe3\nEwr1r/EEgP7TpjHGGAecNz2P4ooGXlxzgP/7zEd8+6ZZ+OK6/7xcWdPEk2/tZu32UjzARWflc+PF\nBSTGx3XsM0f8jB2ezv7I7UD704VrYC0FY4zhuovGM3uSnx0Hj/HIK9rtndr2HKnmX373AWu3lzIu\nL4Mf3jqXZUsmk5L0yc/WHo+HpYsmdDy2lkInInI/MB8IAXeq6rpu9vkZsEBVF4nIIuCvQGHk6Y9U\n9Q4nMxpjjNfj4e+vmsq/P7qBdz8qxuOBW6+YjNfrAeBQaR33P7mZ5pYgX7p8EgvPHoHX4+nx9aaO\nHcLUsdls219Ffk5qtN5Gn3CsKIjIQmCiqi4QkSnA74EFXfaZClwEdO7Ie0dVlzqVyxhjupOYEMd3\nbprFfU9sYtWWYgJtQf7uyimUH2vivic20dAc4CtXTeG86Xm9er2vXTONPUU1/a4oONl9tBh4FkBV\ntwPZIpLRZZ/7gB84mMEYY3otLTme731uFhPyM1hTWML/fWYrv3h8IzX1LXzx8km9LggQvuvbrIIc\nB9M6w8nuo+HA+k6PyyLbagBEZBnwDrC/y3FTReR5YAhwj6q+fqKTZGen4PPFnWiXPuH3pzt+DidZ\nfndZfnedav7/7/YL+MnvPmDjrnIAbvn0FG5YPMmJaL0WrZ9BNGcfdXTAicgQ4DbgUmBEp312AfcA\nTwLjgbdEpEBVW3p60arIZeRO8vvTKSurdfw8TrH87rL87jrd/N+8djqPvrGTvKGpLJqZ5+r3wImf\nQU9FxsmiUES4ZdAuHyiOfH0J4AdWAYnABBG5X1X/EXgiss8eETlKuGjswxhjoigxIY7bPj3F7RhR\n5+SYwmvAUgARmQ0UqWotgKo+papTVXU+cB2wQVX/UURuFpHvRo4ZDuQCRxzMaIwxphPHWgqqulpE\n1ovIaiAI3B4ZR6hW1Wd6OOx54FER+QyQAHzjRF1Hxhhj+pajYwqqeleXTZu72Wc/sCjydS1wtZOZ\njDHG9MyuaDbGGNPBioIxxpgOVhSMMcZ0sKJgjDGmgxUFY4wxHTyhbpaINcYYMzhZS8EYY0wHKwrG\nGGM6WFEwxhjTwYqCMcaYDlYUjDHGdLCiYIwxpoMVBWOMMR2ieee1mCEi04HngPtV9b97ecwo4E9A\nHOGbBX1JVZtF5Czgd5HdnlPVnzqRuZs8ffkeWoH3Ou26WFXb+jpzlyx9lr/T848Bzaq6rO8TH5el\nL7///wosIXx3whdU9d8cit05S1/mvwn4DuEl8leoquP3Xe/j/NnAY0Cdqi51KnOnHKecvcvx3wNu\nAEKEb1n8kohkAo8CmUAd8AVVrTydfIOupSAiqcCvgBWneOhPgP9R1QuB3cDfRbb/BvgqMI/w/aVT\n+iprTxx4D9WquqjTf04XhL7Oj4hcBkzos5An0Jf5RWQsMENVFwDnA7eKSH5f5u2qj/OnAD8HFgML\ngEtFZGpf5u3Kgd+fh4B3+y5hz84ge/vx44DPARcAVwH/KSJxwLeAt1X1AuBp4J9ON+NgbCk0A5+m\n0zct8kv834Qrby2wTFWPdTluEfD1yNfLge+KyNNAmqpuiGz/vIO5O+uz9wA86HTYbvRpfhFJBH4I\n/BvwWUeTh/VZflV9kPCnPoBswp+2axxLHtan+UVkRvtdFUWkAhjqbPw+//3/CjAHmOVo6rBTyi4i\ni4BFqvrjyO4XAy9Hbj5WJiIHgKmEi3J7kVsOvHC6AQddS0FVA6ra2GXzr4CvqepiwrcRvb2bQ1M7\ndVWUAnnAWKBSRB4WkfdE5FtO5e6sj98DQJKIPBp5D992JvXHHMh/N+F/3E7/MQUcyY+IPAAUAj9V\n1ToHYnfo6/ydCsIMwv8m3ncidzun8kfDGWRvNxwo6/S4/X103v6J361TNRhbCt2ZB/xWRAASgXUn\n2d/T6f/jgGuBRmCNiLyuqoVOBT2B030PEP7E9GfCn1RWishKVf3QkZQ9O638IjIRmKuqP458qnLL\nmXz/UdU7ReTHwNsi8p6q7nMkZc/OKH/k5/Ao4b7sVkcSntgZ5XfZcdlF5ALCLd8sICvyu93dbYy7\nex9n9N6sKIQ1ABerasfqgCKyAPhZ5OHNQJ2IJEeq/AigCCgBClW1InLMu8A0wp/4ou103wOq+lCn\nY1YAM4BoF4XTzX8lMFpE3gcyAL+IfF9V/yO68U8vf2TwM1dVP1TVKhF5DzgHiHZROO3fHxEZCTxL\neOB2U3Rjdzjt/DHguOwRi7p2H0Xucy+d9ml/H0WEWwvVnOF7s6IQthm4AnhZRD4HlKnqCiL3jgYQ\nkTeA6wl/or4eeEVV94lIuogMAY4R7pP8TbTDR5zWe5Dwx5MfEf5HE0d4sPOp6EYHTv9n8L/Af0We\nX0S4PzbaBQFOMz/gJzwusoBwS20O7vwOnW5+CM+++0ansTU3nEl+t/WUvTtvAt8WkR8BOYQLwDbC\n3U43EG5dnNF7G3RLZ4vIHOA+wn2frcAR4AfAvxMe5Gukm+lcIpIHPAIkAQeA21S1VUTOBX5J+B/0\nK50GhPrTe/g5cEnk2OdV9d7+lL/T84sIF4Vl/Sm/iNxNuAvSA7yoqvf0l/yEu083AWs77fqfqvp8\nP8kfJDwTKIvwH9hC4Ceq+mYsZe/yGncQ/hAXAn6oqitEJI1wsRtK+APqF1W1+nQyDrqiYIwxpmeD\nbvaRMcaYnllRMMYY08GKgjHGmA5WFIwxxnSwomCMMaaDXadgBpzIInPvqurIKJ7zbfpgdVkRCQEr\nCU83hPD0yf9Q1adPctwXgMdVNXgm5zfGioIxfUBVF/Xhyy1W1QCAiOQCm0Xk7ZMshXwP8CThue7G\nnDYrCmZQEZEbgTsIXyhWBnxFVStE5BvALUAL0ATcpKrHRGQ/8AQwHvge8DzwKnAukA5cqapFkU/4\n8YRXax0KjAQmAm+p6h0ikgT8kfBFS4eBAPB65IrsHqlqiYgUAxNE5BjhZZ4nE14j5wNV/T8icg9Q\nAKwQkeuAswhfpe4hfIHU37uwlpLpp2xMwQwakXWGfgBcGll3/m3gnyNPJwOXq+pCYD/wxU6H7lLV\n9uWtpwIPq+pFhK/kvambU50NLCW8htFtEr6JyxeBeFU9l/AqmJf3MvMcIB/YTnhp7S2qelHkdS4X\nkemq+qPI7osJF7SHgM9G3suvgF/05lzGgLUUzOCygPCSwq92WpGy/RN0BfCSiAQJf5ov7nTc6k5f\nl3daBfcAMKSb87wbGVtoFJHyyD6zCBchVPVoZPHEnqyItDxyCS97cLWq1olIIzBKRNYQXpc/j/D6\nN51Nj2x/OvIe4/h4fMKYk7KiYAaTZmCtql7VeWNklc9fANNUtVREun6ybun0daDLc90tU9zdPl4+\n2d9/ogHpxaoaEJFzCK/V81Fk++cItz4ujDzf3Uq2zcDBPh7jMIOIdR+ZwWQdME9EhgOIyA0i8hlg\nGOEWQGlkxdvLCbci+tIO4LzIeYcRvp3iCanqOsLjF+33bM4Nb9ZApFupoFPO9jGNnUCOhO8DjIhc\nJCJf7cs3YgY2aymYgcofmSbabq2qfl9E7gReEJEGwuvY30p4wHmXiKwF9hAepH1QRF7swzwPA1dF\nun72Aas4vkXRnR8CW0TkKeCvwHIReQd4j3Dr5pciMp/wUskfAtcQHr/4nYg0RV7DioLpNVsl1Zgo\nEJERwHmq+lcR8QIbCN+DYI3L0Yz5BCsKxkSBiKQSHh8YRbir501VvdvdVMYcz4qCMcaYDjbQbIwx\npoMVBWOMMR2sKBhjjOlgRcEYY0wHKwrGGGM6/D+9GlpKzuIv0wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc06a43b6d8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Lex4Hkn078kn",
        "colab_type": "code",
        "outputId": "d1d6b21a-7449-4302-a9b5-da7e3b0b63a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1768
        }
      },
      "cell_type": "code",
      "source": [
        "learner.fit(100, lr=3e-4)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time: 00:33\n",
            "epoch  train_loss  valid_loss  accuracy\n",
            "1      0.712581    0.649617    0.654676  (00:00)\n",
            "2      0.664425    0.618619    0.726619  (00:00)\n",
            "3      0.625972    0.595880    0.741007  (00:00)\n",
            "4      0.593602    0.575832    0.748201  (00:00)\n",
            "5      0.564764    0.562584    0.748201  (00:00)\n",
            "6      0.535529    0.551809    0.748201  (00:00)\n",
            "7      0.513129    0.543273    0.748201  (00:00)\n",
            "8      0.486962    0.537386    0.748201  (00:00)\n",
            "9      0.466235    0.532222    0.748201  (00:00)\n",
            "10     0.448556    0.529090    0.748201  (00:00)\n",
            "11     0.431822    0.527098    0.748201  (00:00)\n",
            "12     0.415911    0.526845    0.748201  (00:00)\n",
            "13     0.401786    0.526445    0.748201  (00:00)\n",
            "14     0.387030    0.526163    0.748201  (00:00)\n",
            "15     0.373763    0.526536    0.748201  (00:00)\n",
            "16     0.362194    0.526799    0.748201  (00:00)\n",
            "17     0.349430    0.528924    0.748201  (00:00)\n",
            "18     0.337556    0.529330    0.748201  (00:00)\n",
            "19     0.325096    0.530054    0.748201  (00:00)\n",
            "20     0.314107    0.531043    0.748201  (00:00)\n",
            "21     0.303019    0.530854    0.748201  (00:00)\n",
            "22     0.291284    0.532219    0.748201  (00:00)\n",
            "23     0.279892    0.535246    0.748201  (00:00)\n",
            "24     0.269519    0.533276    0.748201  (00:00)\n",
            "25     0.258821    0.536636    0.748201  (00:00)\n",
            "26     0.248198    0.534605    0.748201  (00:00)\n",
            "27     0.237437    0.540469    0.748201  (00:00)\n",
            "28     0.227047    0.534678    0.748201  (00:00)\n",
            "29     0.216865    0.539396    0.748201  (00:00)\n",
            "30     0.206758    0.535454    0.748201  (00:00)\n",
            "31     0.196862    0.545332    0.748201  (00:00)\n",
            "32     0.186956    0.540239    0.748201  (00:00)\n",
            "33     0.178130    0.552407    0.748201  (00:00)\n",
            "34     0.169715    0.529219    0.748201  (00:00)\n",
            "35     0.161379    0.558379    0.748201  (00:00)\n",
            "36     0.152811    0.546326    0.748201  (00:00)\n",
            "37     0.144230    0.538730    0.748201  (00:00)\n",
            "38     0.136419    0.554248    0.748201  (00:00)\n",
            "39     0.129073    0.564351    0.748201  (00:00)\n",
            "40     0.121363    0.549838    0.748201  (00:00)\n",
            "41     0.114553    0.562445    0.748201  (00:00)\n",
            "42     0.107786    0.567837    0.748201  (00:00)\n",
            "43     0.101498    0.565335    0.748201  (00:00)\n",
            "44     0.095703    0.550600    0.748201  (00:00)\n",
            "45     0.090367    0.593394    0.748201  (00:00)\n",
            "46     0.084862    0.556504    0.748201  (00:00)\n",
            "47     0.079712    0.567831    0.748201  (00:00)\n",
            "48     0.074560    0.581032    0.748201  (00:00)\n",
            "49     0.070121    0.600995    0.748201  (00:00)\n",
            "50     0.066121    0.566735    0.755396  (00:00)\n",
            "51     0.061845    0.629520    0.748201  (00:00)\n",
            "52     0.058332    0.549883    0.755396  (00:00)\n",
            "53     0.054725    0.607777    0.748201  (00:00)\n",
            "54     0.051745    0.586342    0.748201  (00:00)\n",
            "55     0.048642    0.611480    0.748201  (00:00)\n",
            "56     0.045822    0.591324    0.748201  (00:00)\n",
            "57     0.043429    0.610014    0.748201  (00:00)\n",
            "58     0.040734    0.590249    0.748201  (00:00)\n",
            "59     0.038379    0.606261    0.748201  (00:00)\n",
            "60     0.036278    0.612256    0.748201  (00:00)\n",
            "61     0.034253    0.625110    0.748201  (00:00)\n",
            "62     0.032279    0.620247    0.748201  (00:00)\n",
            "63     0.030605    0.604660    0.748201  (00:00)\n",
            "64     0.028810    0.630394    0.748201  (00:00)\n",
            "65     0.027323    0.616064    0.748201  (00:00)\n",
            "66     0.025689    0.675187    0.748201  (00:00)\n",
            "67     0.024368    0.598956    0.741007  (00:00)\n",
            "68     0.023171    0.640880    0.748201  (00:00)\n",
            "69     0.021991    0.649661    0.748201  (00:00)\n",
            "70     0.020693    0.611901    0.755396  (00:00)\n",
            "71     0.019350    0.668086    0.748201  (00:00)\n",
            "72     0.018198    0.632823    0.748201  (00:00)\n",
            "73     0.017279    0.658344    0.748201  (00:00)\n",
            "74     0.016317    0.661377    0.748201  (00:00)\n",
            "75     0.015504    0.620019    0.748201  (00:00)\n",
            "76     0.014766    0.702881    0.748201  (00:00)\n",
            "77     0.013965    0.657446    0.748201  (00:00)\n",
            "78     0.013365    0.671513    0.748201  (00:00)\n",
            "79     0.012783    0.665826    0.748201  (00:00)\n",
            "80     0.012151    0.690167    0.748201  (00:00)\n",
            "81     0.011551    0.683514    0.748201  (00:00)\n",
            "82     0.010997    0.665494    0.755396  (00:00)\n",
            "83     0.010525    0.694804    0.748201  (00:00)\n",
            "84     0.010040    0.703548    0.748201  (00:00)\n",
            "85     0.009603    0.684989    0.748201  (00:00)\n",
            "86     0.009167    0.705249    0.748201  (00:00)\n",
            "87     0.008760    0.697330    0.748201  (00:00)\n",
            "88     0.008374    0.764778    0.748201  (00:00)\n",
            "89     0.007970    0.675680    0.755396  (00:00)\n",
            "90     0.007542    0.712099    0.755396  (00:00)\n",
            "91     0.007226    0.695132    0.726619  (00:00)\n",
            "92     0.006921    0.685197    0.748201  (00:00)\n",
            "93     0.006538    0.780169    0.748201  (00:00)\n",
            "94     0.006253    0.691649    0.748201  (00:00)\n",
            "95     0.005940    0.673147    0.755396  (00:00)\n",
            "96     0.005642    0.758250    0.748201  (00:00)\n",
            "97     0.005504    0.721279    0.748201  (00:00)\n",
            "98     0.005246    0.786579    0.748201  (00:00)\n",
            "99     0.004986    0.687871    0.755396  (00:00)\n",
            "100    0.004860    0.776084    0.741007  (00:00)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nwkS7lQ6Nbq8",
        "colab_type": "code",
        "outputId": "8cde1ed5-5b26-43c9-8ca5-99b0b787952c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "data = DataBunch(train_dl=train_dl, valid_dl=test_dl, path=path)\n",
        "learner = Learner(data, model, loss_func=loss_func, metrics=accuracy)\n",
        "learner.fit(10, lr=5e-5)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time: 00:03\n",
            "epoch  train_loss  valid_loss  accuracy\n",
            "1      0.003275    0.785197    0.762590  (00:00)\n",
            "2      0.003349    0.800480    0.762590  (00:00)\n",
            "3      0.003107    0.804093    0.762590  (00:00)\n",
            "4      0.002767    0.812344    0.762590  (00:00)\n",
            "5      0.002825    0.806561    0.762590  (00:00)\n",
            "6      0.002692    0.815485    0.755396  (00:00)\n",
            "7      0.002587    0.823958    0.755396  (00:00)\n",
            "8      0.002495    0.824159    0.755396  (00:00)\n",
            "9      0.002463    0.840908    0.755396  (00:00)\n",
            "10     0.002364    0.839903    0.755396  (00:00)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b8Pcr02Khxsy",
        "colab_type": "code",
        "outputId": "fe0ed6b4-c1e6-424e-88b4-780c223ceb44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "model.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMFCN(\n",
              "  (lstm_block): BlockLSTM(\n",
              "    (lstm): LSTM(512, 256)\n",
              "    (dropout): Dropout(p=0.8)\n",
              "  )\n",
              "  (fcn_block): BlockFCN(\n",
              "    (conv1): BlockFCNConv(\n",
              "      (conv): Conv1d(1, 128, kernel_size=(8,), stride=(1,))\n",
              "      (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (conv2): BlockFCNConv(\n",
              "      (conv): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
              "      (batch_norm): BatchNorm1d(256, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (conv3): BlockFCNConv(\n",
              "      (conv): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
              "      (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (global_pooling): AvgPool1d(kernel_size=(499,), stride=(499,), padding=(0,))\n",
              "  )\n",
              "  (dense): Linear(in_features=384, out_features=2, bias=True)\n",
              "  (softmax): LogSoftmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "metadata": {
        "id": "mTTetDTNVH-p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}