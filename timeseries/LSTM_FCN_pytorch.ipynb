{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-FCN-pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "NreY7BzeqHVd",
        "colab_type": "code",
        "outputId": "f8e50caf-3dd9-4635-cee2-05271e60addf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1397
        }
      },
      "cell_type": "code",
      "source": [
        "!curl https://course-v3.fast.ai/setup/colab | bash"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   665  100   665    0     0   3197      0 --:--:-- --:--:-- --:--:--  3197\n",
            "Collecting pillow==4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e5/88b3d60924a3f8476fa74ec086f5fbaba56dd6cee0d82845f883b6b6dd18/Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.7MB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow==4.1.1) (0.46)\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-4.1.1\n",
            "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
            "Collecting torch_nightly\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/cu92/torch_nightly-1.0.0.dev20181126-cp36-cp36m-linux_x86_64.whl (576.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 576.5MB 25kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x61cc2000 @  0x7fd912e4d2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch-nightly\n",
            "Successfully installed torch-nightly-1.0.0.dev20181126\n",
            "Cloning into 'course-v3'...\n",
            "remote: Enumerating objects: 2450, done.\u001b[K\n",
            "remote: Total 2450 (delta 0), reused 0 (delta 0), pack-reused 2450\u001b[K\n",
            "Receiving objects: 100% (2450/2450), 59.09 MiB | 27.22 MiB/s, done.\n",
            "Resolving deltas: 100% (1338/1338), done.\n",
            "Collecting fastai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/fe/9686231cc2ed81a7096abda19d93ca43532d7b130a12d1ada8746ba75e72/fastai-1.0.28-py3-none-any.whl (120kB)\n",
            "\u001b[K    100% |████████████████████████████████| 122kB 4.2MB/s \n",
            "\u001b[?25hCollecting fastprogress>=0.1.15 (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/dc/b8/7ce2b3c6f886f5cb1b16e62d368456b4fdb7e16bba962571bc50dae49b30/fastprogress-0.1.15-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.22.0)\n",
            "Collecting dataclasses (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.18.4)\n",
            "Collecting numexpr (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/ea/efd9e16283637eb5b6c0042b6cc3521f1b9a5b47767ac463c88bbd37670c/numexpr-2.6.8-cp36-cp36m-manylinux1_x86_64.whl (162kB)\n",
            "\u001b[K    100% |████████████████████████████████| 163kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from fastai) (2018.1.10)\n",
            "Requirement already satisfied, skipping upgrade: cymem==2.0.2 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: typing in /usr/local/lib/python3.6/dist-packages (from fastai) (3.6.6)\n",
            "Collecting torchvision-nightly (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/bd/d0f9a33c81c79710eb7ee428b66869b49a8be16c7f1e446c211a7fbfb7be/torchvision_nightly-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (2.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: spacy==2.0.16 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.0.16)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.0)\n",
            "Collecting bottleneck (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/ae/cedf5323f398ab4e4ff92d6c431a3e1c6a186f9b41ab3e8258dff786a290/Bottleneck-1.2.1.tar.gz (105kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: thinc==6.12.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (6.12.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.7)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2018.10.15)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision-nightly->fastai) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchvision-nightly->fastai) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai) (0.46)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (0.2.8.2)\n",
            "Requirement already satisfied, skipping upgrade: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (0.4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (1.35)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (1.10.11)\n",
            "Requirement already satisfied, skipping upgrade: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.9.0.1)\n",
            "Requirement already satisfied, skipping upgrade: msgpack<1.0.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.5.6)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc==6.12.0->fastai) (0.9.0)\n",
            "Building wheels for collected packages: bottleneck\n",
            "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f2/bf/ec/e0f39aa27001525ad455139ee57ec7d0776fe074dfd78c97e4\n",
            "Successfully built bottleneck\n",
            "Installing collected packages: fastprogress, dataclasses, numexpr, torchvision-nightly, bottleneck, fastai\n",
            "Successfully installed bottleneck-1.2.1 dataclasses-0.6 fastai-1.0.28 fastprogress-0.1.15 numexpr-2.6.8 torchvision-nightly-0.2.1\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CKP2ikW1ngNl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OblomiW9n4bg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from fastai import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEwnf-gdntsa",
        "colab_type": "code",
        "outputId": "d0655b02-fe3c-4255-d1f2-8d27c4ce3912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!curl -O http://www.timeseriesclassification.com/Downloads/Earthquakes.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  516k  100  516k    0     0   420k      0  0:00:01  0:00:01 --:--:--  420k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qsr9wx88nyRG",
        "colab_type": "code",
        "outputId": "52eb4701-1b44-4c15-cf73-507b34d67842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip Earthquakes.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Earthquakes.zip\n",
            "  inflating: Earthquakes.txt         \n",
            "  inflating: Earthquakes_TEST.arff   \n",
            "  inflating: Earthquakes_TEST.txt    \n",
            "  inflating: Earthquakes_TRAIN.arff  \n",
            "  inflating: Earthquakes_TRAIN.txt   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "onhUsHlhsWvc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bs = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O1pj6M8Vn-0D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATASET = 'Earthquakes'\n",
        "classes = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9EMN9yFin1cW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = pathlib.Path('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tDncQ40aHJkX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot_encode(input, labels):\n",
        "    m = input.shape[0]\n",
        "    output = np.zeros((m, labels), dtype=int)\n",
        "    row_index = np.arange(m)\n",
        "    output[row_index, input] = 1\n",
        "    return output\n",
        "\n",
        "def split_xy(data, classes):\n",
        "    X = data_train[:, 1:]\n",
        "    y = data_train[:, 0].astype(int)\n",
        "    # hot encode\n",
        "    #y = one_hot_encode(y, classes)\n",
        "    return X, y\n",
        "\n",
        "def create_dataset(X, y, device):\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32, device=device)\n",
        "    y_tensor = torch.tensor(y_train, dtype=torch.long, device=device)\n",
        "    return TensorDataset(X_tensor, y_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jNG4E5F-Tpcf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The outputs of the model should be of size (minibatch, C). On the other hand the target `y` should contain the indices of the classes."
      ]
    },
    {
      "metadata": {
        "id": "A69YvILXoA5e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load training dataset\n",
        "data_train = np.loadtxt(path/'Earthquakes_TRAIN.txt')\n",
        "X_train, y_train = split_xy(data_train[:, 1:], classes)\n",
        "\n",
        "# load testing dataset\n",
        "data_test = np.loadtxt(path/'Earthquakes_TEST.txt')\n",
        "X_test, y_test = split_xy(data_test[:, 1:], classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MWAHekuN7mqq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As the classes are imbalanced, get the count for each class, to use later in the sampling"
      ]
    },
    {
      "metadata": {
        "id": "tQ4U0nAa7RV3",
        "colab_type": "code",
        "outputId": "87b57f25-bcb9-453d-9045-f1c441817c4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "class_0_count = (y_train==0).sum()\n",
        "class_1_count = (y_train==1).sum()\n",
        "\n",
        "class_0_count, class_1_count"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(264, 58)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "metadata": {
        "id": "9307nee9rz4Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "load the numpy training and test sets into pytorch Dataset object"
      ]
    },
    {
      "metadata": {
        "id": "gmqg-MVhaHFY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cuda = torch.device('cuda')     # Default CUDA device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Wqt26B1oD_g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_ds = create_dataset(X_train, y_train, cuda)\n",
        "test_ds  = create_dataset(X_test, y_test, cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2uSDLS9-sBYl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "pass the Dataset objects into a DataLoader"
      ]
    },
    {
      "metadata": {
        "id": "DVMtIjJl6jcr",
        "colab_type": "code",
        "outputId": "915ea231-f770-4daa-8e46-f11c55f9acc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "class_sample_count = [class_0_count, class_1_count] # dataset has 10 class-1 samples, 1 class-2 samples, etc.\n",
        "weights = 1 / torch.Tensor(class_sample_count)\n",
        "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, bs)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.weights = torch.tensor(weights, dtype=torch.double)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5rckvuLErUGq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=False)#, sampler = sampler)\n",
        "test_dl = DataLoader(test_ds, batch_size=bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3A86zi48tdPG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## LSTM-FCN\n",
        "### LSMT block\n",
        "A shuffle layer + LSTM layer + Dropout layer"
      ]
    },
    {
      "metadata": {
        "id": "JDYfUKc8tQhu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BlockLSTM(nn.Module):\n",
        "    def __init__(self, time_steps, num_layers, lstm_hs, dropout=0.8, attention=False):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size=time_steps, hidden_size=lstm_hs, num_layers=num_layers)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "    def forward(self, x):\n",
        "        # input is of the form (batch_size, num_layers, time_steps), e.g. (128, 1, 512)\n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        # lstm layer is of the form (num_layers, batch_size, time_steps)\n",
        "        x, (h_n, c_n) = self.lstm(x)\n",
        "        # dropout layer input shape (Sequence Length, Batch Size, Hidden Size * Num Directions)\n",
        "        y = self.dropout(x)\n",
        "        # output shape is same as Dropout intput\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PskMJhzL8_Ao",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### FCN block\n",
        "\n",
        "#### Convolutional block"
      ]
    },
    {
      "metadata": {
        "id": "4oam7px91HYa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BlockFCNConv(nn.Module):\n",
        "    def __init__(self, in_channel=1, out_channel=128, kernel_size=8, momentum=0.99, epsilon=0.001, squeeze=False):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(in_channel, out_channel, kernel_size=kernel_size)\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=out_channel, eps=epsilon, momentum=momentum)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        # input (batch_size, num_variables, time_steps), e.g. (128, 1, 512)\n",
        "        x = self.conv(x)\n",
        "        # input (batch_size, out_channel, L_out)\n",
        "        x = self.batch_norm(x)\n",
        "        # same shape as input\n",
        "        y = self.relu(x)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sxIcU-lx9GeV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### FCN block"
      ]
    },
    {
      "metadata": {
        "id": "lNDU3Mij89dR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BlockFCN(nn.Module):\n",
        "    def __init__(self, time_steps, channels=[1, 128, 256, 128], kernels=[8, 5, 3], mom=0.99, eps=0.001):\n",
        "        super().__init__()\n",
        "        self.conv1 = BlockFCNConv(channels[0], channels[1], kernels[0], momentum=mom, epsilon=eps, squeeze=True)\n",
        "        self.conv2 = BlockFCNConv(channels[1], channels[2], kernels[1], momentum=mom, epsilon=eps, squeeze=True)\n",
        "        self.conv3 = BlockFCNConv(channels[2], channels[3], kernels[2], momentum=mom, epsilon=eps)\n",
        "        output_size = time_steps - sum(kernels) + len(kernels)\n",
        "        self.global_pooling = nn.AvgPool1d(kernel_size=output_size)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        # apply Global Average Pooling 1D\n",
        "        y = self.global_pooling(x)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mFYGCNCqPQfq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM-FCN"
      ]
    },
    {
      "metadata": {
        "id": "QQznEOKCKygx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LSTMFCN(nn.Module):\n",
        "    def __init__(self, time_steps, num_variables=1, lstm_hs=256, channels=[1, 128, 256, 128]):\n",
        "        super().__init__()\n",
        "        self.lstm_block = BlockLSTM(time_steps, 1, lstm_hs)\n",
        "        self.fcn_block = BlockFCN(time_steps)\n",
        "        self.dense = nn.Linear(channels[-1] + lstm_hs, num_variables)\n",
        "        self.softmax = nn.LogSoftmax(dim=1) #nn.Softmax(dim=1)\n",
        "    def forward(self, x):\n",
        "        # input is (batch_size, time_steps), it has to be (batch_size, 1, time_steps)\n",
        "        x = x.unsqueeze(1)\n",
        "        # pass input through LSTM block\n",
        "        x1 = self.lstm_block(x)\n",
        "        x1 = torch.squeeze(x1)\n",
        "        # pass input through FCN block\n",
        "        x2 = self.fcn_block(x)\n",
        "        x2 = torch.squeeze(x2)\n",
        "        # concatenate blocks output\n",
        "        x = torch.cat([x1, x2], 1)\n",
        "        # pass through Linear layer\n",
        "        x = self.dense(x)\n",
        "        #x = torch.squeeze(x)\n",
        "        # pass through Softmax activation\n",
        "        y = self.softmax(x)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZXyATnq7WOKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "BCHDSTVzRKGR",
        "colab_type": "code",
        "outputId": "59d50066-a6b5-49fe-f4e5-96e154b80401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "time_steps = X_train.shape[1]\n",
        "num_variables = classes\n",
        "\n",
        "time_steps, num_variables"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "metadata": {
        "id": "i9eJ3zlrWV7A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = LSTMFCN(time_steps, num_variables).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b27y39-dh0Ik",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "look at the different blocks of the Model"
      ]
    },
    {
      "metadata": {
        "id": "i0c4x4NViexX",
        "colab_type": "code",
        "outputId": "f521f461-3fea-4af8-d580-2f38cf154935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "# model summary\n",
        "for m in model.children():\n",
        "    print(m.training)#, m)\n",
        "    for j in m.children():\n",
        "        print(j.training, j)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True LSTM(512, 256)\n",
            "True Dropout(p=0.8)\n",
            "True\n",
            "True BlockFCNConv(\n",
            "  (conv): Conv1d(1, 128, kernel_size=(8,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "True BlockFCNConv(\n",
            "  (conv): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(256, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "True BlockFCNConv(\n",
            "  (conv): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "True AvgPool1d(kernel_size=(499,), stride=(499,), padding=(0,))\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xeWqQhn9XPUU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "look at the parameters (i.e. weights) in each layer"
      ]
    },
    {
      "metadata": {
        "id": "-F4_pcUqW8He",
        "colab_type": "code",
        "outputId": "6a15dec1-d9ab-459c-e3ce-d3bea8166977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "[p.shape for p in model.parameters()]"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([1024, 512]),\n",
              " torch.Size([1024, 256]),\n",
              " torch.Size([1024]),\n",
              " torch.Size([1024]),\n",
              " torch.Size([128, 1, 8]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([256, 128, 5]),\n",
              " torch.Size([256]),\n",
              " torch.Size([256]),\n",
              " torch.Size([256]),\n",
              " torch.Size([128, 256, 3]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([2, 384]),\n",
              " torch.Size([2])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "metadata": {
        "id": "vUO4oNKkxAYs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define a learner class to automate the learning process"
      ]
    },
    {
      "metadata": {
        "id": "RnEiGUWHw_kX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SimpleLearner():\n",
        "    def __init__(self, data, model, loss_func, wd = 1e-5):\n",
        "        self.data, self.model, self.loss_func = data, model, loss_func\n",
        "        self.wd = wd\n",
        "        \n",
        "    def update(self, x,y,lr):\n",
        "        y_hat = model(x)\n",
        "        # weight decay\n",
        "        w2 = 0.\n",
        "        for p in model.parameters(): w2 += (p**2).sum()\n",
        "        # add to regular loss\n",
        "        loss = loss_func(y_hat, y) + w2 * self.wd\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            for p in model.parameters():\n",
        "                p.sub_(lr * p.grad)\n",
        "                p.grad.zero_()\n",
        "        return loss.item()\n",
        "\n",
        "    def fit(self, epochs=1, lr=1e-3):\n",
        "        history = {\n",
        "            'losses'  : [],\n",
        "            'accuracy': []\n",
        "        }\n",
        "        for i in tqdm(range(epochs)):\n",
        "            losses = []\n",
        "            for x,y in self.data[0]:\n",
        "                losses.append(self.update(x, y , lr))\n",
        "            history['losses'].append(np.mean(losses))\n",
        "        return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "txh5ujbKXhuz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "train the model using the DataLoader"
      ]
    },
    {
      "metadata": {
        "id": "GMAfJH9KAY0h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# depending on the number of classes, use a Binary Cross Entropy or a Negative Log Likelihood loss for more than two classes\n",
        "loss_func = nn.NLLLoss().cuda() # weight=weights\n",
        "acc_func = accuracy_thresh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xxVx2A1pXtuY",
        "colab_type": "code",
        "outputId": "8172df73-3fd7-44ad-a9ae-76324a26e195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "lr = 2e-2\n",
        "learner = SimpleLearner([train_dl, test_dl], model, loss_func)\n",
        "history = learner.fit(10)"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  3.58it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4W1s1mql_ELt",
        "colab_type": "code",
        "outputId": "8459ab46-17c5-40e6-e7fc-055c75fcf344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history['losses'])"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5dda031668>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPsra+OUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5dd8e55710>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IDwkjDH5rXCy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = DataBunch(train_dl=train_dl, valid_dl=test_dl, path=path)\n",
        "learner = Learner(data, model, loss_func=loss_func, metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jhv_-NkEknVO",
        "colab_type": "code",
        "outputId": "111e2aa9-5044-450b-ad82-908114e22b81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "cell_type": "code",
      "source": [
        "learner.unfreeze()\n",
        "learner.lr_find()\n",
        "learner.recorder.plot()"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "        \t/* Turns off some styling */\n",
              "        \tprogress {\n",
              "\n",
              "            \t/* gets rid of default border in Firefox and Opera. */\n",
              "            \tborder: none;\n",
              "\n",
              "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "            \tbackground-size: auto;\n",
              "            }\n",
              "\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='15' class='' max='17', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      88.24% [15/17 00:04<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>0.598735</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>2</th>\n",
              "    <th>0.608179</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>3</th>\n",
              "    <th>0.613848</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>4</th>\n",
              "    <th>0.618371</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>5</th>\n",
              "    <th>0.619829</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>6</th>\n",
              "    <th>0.614827</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>7</th>\n",
              "    <th>0.609390</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>8</th>\n",
              "    <th>0.597074</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>9</th>\n",
              "    <th>0.572788</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>10</th>\n",
              "    <th>0.537352</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>11</th>\n",
              "    <th>0.494789</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>12</th>\n",
              "    <th>0.439363</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>13</th>\n",
              "    <th>0.395089</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>14</th>\n",
              "    <th>0.395523</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>15</th>\n",
              "    <th>1.312370</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "\n",
              "  </tr>\n",
              "</table>\n",
              "\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "        \t/* Turns off some styling */\n",
              "        \tprogress {\n",
              "\n",
              "            \t/* gets rid of default border in Firefox and Opera. */\n",
              "            \tborder: none;\n",
              "\n",
              "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "            \tbackground-size: auto;\n",
              "            }\n",
              "\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='6', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIjIgPx/7nXtnK5/dwIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5dda24f4a8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Lex4Hkn078kn",
        "colab_type": "code",
        "outputId": "9900f2c6-aebf-419b-bcd7-b90ea237e58f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1768
        }
      },
      "cell_type": "code",
      "source": [
        "learner.fit(100, lr=5e-3)"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time: 00:38\n",
            "epoch  train_loss  valid_loss  accuracy\n",
            "1      0.437780    0.483696    0.819876  (00:00)\n",
            "2      0.365820    0.430517    0.819876  (00:00)\n",
            "3      0.309986    0.299840    0.875776  (00:00)\n",
            "4      0.252181    0.139254    0.956522  (00:00)\n",
            "5      0.207332    0.055020    0.984472  (00:00)\n",
            "6      0.169240    0.021992    0.996894  (00:00)\n",
            "7      0.140646    0.010572    1.000000  (00:00)\n",
            "8      0.118082    0.006690    1.000000  (00:00)\n",
            "9      0.099006    0.005146    1.000000  (00:00)\n",
            "10     0.084225    0.003939    1.000000  (00:00)\n",
            "11     0.072080    0.003410    1.000000  (00:00)\n",
            "12     0.061807    0.002807    1.000000  (00:00)\n",
            "13     0.053771    0.002144    1.000000  (00:00)\n",
            "14     0.046621    0.001970    1.000000  (00:00)\n",
            "15     0.040551    0.001638    1.000000  (00:00)\n",
            "16     0.035450    0.001421    1.000000  (00:00)\n",
            "17     0.031097    0.000976    1.000000  (00:00)\n",
            "18     0.027262    0.000790    1.000000  (00:00)\n",
            "19     0.024035    0.000694    1.000000  (00:00)\n",
            "20     0.021172    0.000631    1.000000  (00:00)\n",
            "21     0.018678    0.000559    1.000000  (00:00)\n",
            "22     0.016565    0.000468    1.000000  (00:00)\n",
            "23     0.014678    0.000424    1.000000  (00:00)\n",
            "24     0.012989    0.000322    1.000000  (00:00)\n",
            "25     0.011487    0.000274    1.000000  (00:00)\n",
            "26     0.010185    0.000236    1.000000  (00:00)\n",
            "27     0.009093    0.000212    1.000000  (00:00)\n",
            "28     0.008106    0.000199    1.000000  (00:00)\n",
            "29     0.007259    0.000184    1.000000  (00:00)\n",
            "30     0.006438    0.000171    1.000000  (00:00)\n",
            "31     0.005722    0.000156    1.000000  (00:00)\n",
            "32     0.005091    0.000145    1.000000  (00:00)\n",
            "33     0.004559    0.000130    1.000000  (00:00)\n",
            "34     0.004074    0.000119    1.000000  (00:00)\n",
            "35     0.003659    0.000117    1.000000  (00:00)\n",
            "36     0.003278    0.000120    1.000000  (00:00)\n",
            "37     0.002934    0.000119    1.000000  (00:00)\n",
            "38     0.002627    0.000107    1.000000  (00:00)\n",
            "39     0.002361    0.000096    1.000000  (00:00)\n",
            "40     0.002132    0.000088    1.000000  (00:00)\n",
            "41     0.001920    0.000086    1.000000  (00:00)\n",
            "42     0.001724    0.000083    1.000000  (00:00)\n",
            "43     0.001554    0.000069    1.000000  (00:00)\n",
            "44     0.001399    0.000059    1.000000  (00:00)\n",
            "45     0.001272    0.000053    1.000000  (00:00)\n",
            "46     0.001144    0.000049    1.000000  (00:00)\n",
            "47     0.001033    0.000047    1.000000  (00:00)\n",
            "48     0.000927    0.000045    1.000000  (00:00)\n",
            "49     0.000839    0.000044    1.000000  (00:00)\n",
            "50     0.000763    0.000040    1.000000  (00:00)\n",
            "51     0.000696    0.000038    1.000000  (00:00)\n",
            "52     0.000635    0.000037    1.000000  (00:00)\n",
            "53     0.000578    0.000036    1.000000  (00:00)\n",
            "54     0.000523    0.000034    1.000000  (00:00)\n",
            "55     0.000479    0.000035    1.000000  (00:00)\n",
            "56     0.000442    0.000034    1.000000  (00:00)\n",
            "57     0.000409    0.000033    1.000000  (00:00)\n",
            "58     0.000374    0.000033    1.000000  (00:00)\n",
            "59     0.000342    0.000033    1.000000  (00:00)\n",
            "60     0.000312    0.000031    1.000000  (00:00)\n",
            "61     0.000288    0.000030    1.000000  (00:00)\n",
            "62     0.000264    0.000030    1.000000  (00:00)\n",
            "63     0.000247    0.000030    1.000000  (00:00)\n",
            "64     0.000229    0.000030    1.000000  (00:00)\n",
            "65     0.000215    0.000031    1.000000  (00:00)\n",
            "66     0.000206    0.000031    1.000000  (00:00)\n",
            "67     0.000190    0.000029    1.000000  (00:00)\n",
            "68     0.000179    0.000028    1.000000  (00:00)\n",
            "69     0.000165    0.000027    1.000000  (00:00)\n",
            "70     0.000154    0.000023    1.000000  (00:00)\n",
            "71     0.000143    0.000022    1.000000  (00:00)\n",
            "72     0.000134    0.000021    1.000000  (00:00)\n",
            "73     0.000137    0.000019    1.000000  (00:00)\n",
            "74     0.000131    0.000018    1.000000  (00:00)\n",
            "75     0.000122    0.000018    1.000000  (00:00)\n",
            "76     0.000113    0.000017    1.000000  (00:00)\n",
            "77     0.000106    0.000016    1.000000  (00:00)\n",
            "78     0.000099    0.000015    1.000000  (00:00)\n",
            "79     0.000093    0.000015    1.000000  (00:00)\n",
            "80     0.000092    0.000015    1.000000  (00:00)\n",
            "81     0.000087    0.000014    1.000000  (00:00)\n",
            "82     0.000083    0.000015    1.000000  (00:00)\n",
            "83     0.000079    0.000015    1.000000  (00:00)\n",
            "84     0.000074    0.000016    1.000000  (00:00)\n",
            "85     0.000069    0.000015    1.000000  (00:00)\n",
            "86     0.000064    0.000015    1.000000  (00:00)\n",
            "87     0.000059    0.000014    1.000000  (00:00)\n",
            "88     0.000056    0.000013    1.000000  (00:00)\n",
            "89     0.000056    0.000011    1.000000  (00:00)\n",
            "90     0.000053    0.000011    1.000000  (00:00)\n",
            "91     0.000051    0.000010    1.000000  (00:00)\n",
            "92     0.000048    0.000009    1.000000  (00:00)\n",
            "93     0.000046    0.000008    1.000000  (00:00)\n",
            "94     0.000046    0.000006    1.000000  (00:00)\n",
            "95     0.000044    0.000005    1.000000  (00:00)\n",
            "96     0.000043    0.000005    1.000000  (00:00)\n",
            "97     0.000040    0.000004    1.000000  (00:00)\n",
            "98     0.000038    0.000004    1.000000  (00:00)\n",
            "99     0.000037    0.000004    1.000000  (00:00)\n",
            "100    0.000037    0.000004    1.000000  (00:00)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nwkS7lQ6Nbq8",
        "colab_type": "code",
        "outputId": "52f69d41-5f8f-48b8-f12c-58a25b8c4015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "data = DataBunch(train_dl=train_dl, valid_dl=test_dl, path=path)\n",
        "learner = Learner(data, model, loss_func=loss_func, metrics=accuracy)\n",
        "learner.fit(10, lr=5e-5)"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time: 00:04\n",
            "epoch  train_loss  valid_loss  accuracy\n",
            "1      0.000025    0.000000    1.000000  (00:00)\n",
            "2      0.000062    0.000000    1.000000  (00:00)\n",
            "3      0.000049    0.000000    1.000000  (00:00)\n",
            "4      0.000056    0.000000    1.000000  (00:00)\n",
            "5      0.000128    0.000000    1.000000  (00:00)\n",
            "6      0.000108    0.000000    1.000000  (00:00)\n",
            "7      0.000093    0.000000    1.000000  (00:00)\n",
            "8      0.000096    0.000000    1.000000  (00:00)\n",
            "9      0.000140    0.000000    1.000000  (00:00)\n",
            "10     0.000123    0.000000    1.000000  (00:00)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b8Pcr02Khxsy",
        "colab_type": "code",
        "outputId": "fe0ed6b4-c1e6-424e-88b4-780c223ceb44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "model.train()"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMFCN(\n",
              "  (lstm_block): BlockLSTM(\n",
              "    (lstm): LSTM(512, 256)\n",
              "    (dropout): Dropout(p=0.8)\n",
              "  )\n",
              "  (fcn_block): BlockFCN(\n",
              "    (conv1): BlockFCNConv(\n",
              "      (conv): Conv1d(1, 128, kernel_size=(8,), stride=(1,))\n",
              "      (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (conv2): BlockFCNConv(\n",
              "      (conv): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
              "      (batch_norm): BatchNorm1d(256, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (conv3): BlockFCNConv(\n",
              "      (conv): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
              "      (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (global_pooling): AvgPool1d(kernel_size=(499,), stride=(499,), padding=(0,))\n",
              "  )\n",
              "  (dense): Linear(in_features=384, out_features=2, bias=True)\n",
              "  (softmax): LogSoftmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "metadata": {
        "id": "mTTetDTNVH-p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}