{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-FCN-pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "NreY7BzeqHVd",
        "colab_type": "code",
        "outputId": "f8892cbd-955c-4a3f-a2c5-273ac532c17c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        }
      },
      "cell_type": "code",
      "source": [
        "!curl https://course-v3.fast.ai/setup/colab | bash"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   665  100   665    0     0    506      0  0:00:01  0:00:01 --:--:--   506\n",
            "Collecting pillow==4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e5/88b3d60924a3f8476fa74ec086f5fbaba56dd6cee0d82845f883b6b6dd18/Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.7MB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow==4.1.1) (0.46)\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-4.1.1\n",
            "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
            "Collecting torch_nightly\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/cu92/torch_nightly-1.0.0.dev20181126-cp36-cp36m-linux_x86_64.whl (576.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 576.5MB 28kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x62222000 @  0x7f95ebd552a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch-nightly\n",
            "Successfully installed torch-nightly-1.0.0.dev20181126\n",
            "Cloning into 'course-v3'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 2455 (delta 0), reused 3 (delta 0), pack-reused 2450\u001b[K\n",
            "Receiving objects: 100% (2455/2455), 59.35 MiB | 9.86 MiB/s, done.\n",
            "Resolving deltas: 100% (1338/1338), done.\n",
            "Collecting fastai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/fe/9686231cc2ed81a7096abda19d93ca43532d7b130a12d1ada8746ba75e72/fastai-1.0.28-py3-none-any.whl (120kB)\n",
            "\u001b[K    100% |████████████████████████████████| 122kB 3.9MB/s \n",
            "\u001b[?25hCollecting torchvision-nightly (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/bd/d0f9a33c81c79710eb7ee428b66869b49a8be16c7f1e446c211a7fbfb7be/torchvision_nightly-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 15.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: thinc==6.12.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (6.12.0)\n",
            "Requirement already satisfied, skipping upgrade: spacy==2.0.16 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.0.16)\n",
            "Collecting dataclasses (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.18.4)\n",
            "Collecting fastprogress>=0.1.15 (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/dc/b8/7ce2b3c6f886f5cb1b16e62d368456b4fdb7e16bba962571bc50dae49b30/fastprogress-0.1.15-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: typing in /usr/local/lib/python3.6/dist-packages (from fastai) (3.6.6)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.22.0)\n",
            "Collecting bottleneck (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/ae/cedf5323f398ab4e4ff92d6c431a3e1c6a186f9b41ab3e8258dff786a290/Bottleneck-1.2.1.tar.gz (105kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 31.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.0)\n",
            "Collecting numexpr (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/ea/efd9e16283637eb5b6c0042b6cc3521f1b9a5b47767ac463c88bbd37670c/numexpr-2.6.8-cp36-cp36m-manylinux1_x86_64.whl (162kB)\n",
            "\u001b[K    100% |████████████████████████████████| 163kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cymem==2.0.2 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (2.1.2)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from fastai) (2018.1.10)\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision-nightly->fastai) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchvision-nightly->fastai) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: msgpack<1.0.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.5.6)\n",
            "Requirement already satisfied, skipping upgrade: dill<0.3.0,>=0.2.7 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.2.8.2)\n",
            "Requirement already satisfied, skipping upgrade: msgpack-numpy<0.4.4.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.9.0.1)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.0.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (1.10.11)\n",
            "Requirement already satisfied, skipping upgrade: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (1.35)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2018.10.15)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai) (0.46)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc==6.12.0->fastai) (0.9.0)\n",
            "Building wheels for collected packages: bottleneck\n",
            "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f2/bf/ec/e0f39aa27001525ad455139ee57ec7d0776fe074dfd78c97e4\n",
            "Successfully built bottleneck\n",
            "Installing collected packages: torchvision-nightly, dataclasses, fastprogress, bottleneck, numexpr, fastai\n",
            "Successfully installed bottleneck-1.2.1 dataclasses-0.6 fastai-1.0.28 fastprogress-0.1.15 numexpr-2.6.8 torchvision-nightly-0.2.1\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CKP2ikW1ngNl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OblomiW9n4bg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from fastai import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEwnf-gdntsa",
        "colab_type": "code",
        "outputId": "1158ff87-101c-459b-ac20-691ac29d1baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!curl -O http://www.timeseriesclassification.com/Downloads/Earthquakes.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  516k  100  516k    0     0   136k      0  0:00:03  0:00:03 --:--:--  136k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qsr9wx88nyRG",
        "colab_type": "code",
        "outputId": "de12638d-31c5-450c-f72e-f85e0ab2a1e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip Earthquakes.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Earthquakes.zip\n",
            "  inflating: Earthquakes.txt         \n",
            "  inflating: Earthquakes_TEST.arff   \n",
            "  inflating: Earthquakes_TEST.txt    \n",
            "  inflating: Earthquakes_TRAIN.arff  \n",
            "  inflating: Earthquakes_TRAIN.txt   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "onhUsHlhsWvc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bs = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O1pj6M8Vn-0D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATASET = 'Earthquakes'\n",
        "classes = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9EMN9yFin1cW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = pathlib.Path('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tDncQ40aHJkX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot_encode(input, labels):\n",
        "    m = input.shape[0]\n",
        "    output = np.zeros((m, labels), dtype=int)\n",
        "    row_index = np.arange(m)\n",
        "    output[row_index, input] = 1\n",
        "    return output\n",
        "\n",
        "def split_xy(data, classes):\n",
        "    X = data[:, 1:]\n",
        "    y = data[:, 0].astype(int)\n",
        "    # hot encode\n",
        "    #y = one_hot_encode(y, classes)\n",
        "    return X, y\n",
        "\n",
        "def create_dataset(X, y, device):\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32, device=device)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.long, device=device)\n",
        "    return TensorDataset(X_tensor, y_tensor)\n",
        "\n",
        "def load_data(path, classes):\n",
        "    data = np.loadtxt(path)\n",
        "    return split_xy(data, classes)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jNG4E5F-Tpcf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The outputs of the model should be of size (minibatch, C). On the other hand the target `y` should contain the indices of the classes."
      ]
    },
    {
      "metadata": {
        "id": "A69YvILXoA5e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load training dataset\n",
        "X_train, y_train = load_data(path/'Earthquakes_TRAIN.txt', classes) \n",
        "\n",
        "# load testing dataset\n",
        "X_test, y_test = load_data(path/'Earthquakes_TEST.txt', classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOrCEhRicN27",
        "colab_type": "code",
        "outputId": "5b011a23-3eab-469f-c39c-1873b1e2f48f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('X_train %s   y_train %s' % (X_train.shape, y_train.shape))\n",
        "print('X_test  %s   y_test  %s' % (X_test.shape, y_test.shape))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train (322, 512)   y_train (322,)\n",
            "X_test  (139, 512)   y_test  (139,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MWAHekuN7mqq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As the classes are imbalanced, get the count for each class, to use later in the sampling"
      ]
    },
    {
      "metadata": {
        "id": "tQ4U0nAa7RV3",
        "colab_type": "code",
        "outputId": "25eec6a7-1524-41d3-b08a-6183c1f7c1ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "class_0_count = (y_train==0).sum()\n",
        "class_1_count = (y_train==1).sum()\n",
        "\n",
        "class_0_count, class_1_count"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(264, 58)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "9307nee9rz4Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "load the numpy training and test sets into pytorch Dataset object"
      ]
    },
    {
      "metadata": {
        "id": "gmqg-MVhaHFY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cuda = torch.device('cuda')     # Default CUDA device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Wqt26B1oD_g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_ds = create_dataset(X_train, y_train, cuda)\n",
        "test_ds  = create_dataset(X_test, y_test, cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2uSDLS9-sBYl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "pass the Dataset objects into a DataLoader"
      ]
    },
    {
      "metadata": {
        "id": "DVMtIjJl6jcr",
        "colab_type": "code",
        "outputId": "910af72f-05dc-4cba-8b65-4de91043350d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "class_sample_count = [class_0_count, class_1_count] # dataset has 10 class-1 samples, 1 class-2 samples, etc.\n",
        "weights = 1 / torch.Tensor(class_sample_count)\n",
        "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, bs)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.weights = torch.tensor(weights, dtype=torch.double)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5rckvuLErUGq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=False)#, sampler = sampler)\n",
        "test_dl = DataLoader(test_ds, batch_size=bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3A86zi48tdPG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## LSTM-FCN\n",
        "### LSMT block\n",
        "A shuffle layer + LSTM layer + Dropout layer"
      ]
    },
    {
      "metadata": {
        "id": "JDYfUKc8tQhu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BlockLSTM(nn.Module):\n",
        "    def __init__(self, time_steps, num_layers, lstm_hs, dropout=0.8, attention=False):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size=time_steps, hidden_size=lstm_hs, num_layers=num_layers)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "    def forward(self, x):\n",
        "        # input is of the form (batch_size, num_layers, time_steps), e.g. (128, 1, 512)\n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        # lstm layer is of the form (num_layers, batch_size, time_steps)\n",
        "        x, (h_n, c_n) = self.lstm(x)\n",
        "        # dropout layer input shape (Sequence Length, Batch Size, Hidden Size * Num Directions)\n",
        "        y = self.dropout(x)\n",
        "        # output shape is same as Dropout intput\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PskMJhzL8_Ao",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### FCN block\n",
        "\n",
        "#### Convolutional block"
      ]
    },
    {
      "metadata": {
        "id": "4oam7px91HYa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BlockFCNConv(nn.Module):\n",
        "    def __init__(self, in_channel=1, out_channel=128, kernel_size=8, momentum=0.99, epsilon=0.001, squeeze=False):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(in_channel, out_channel, kernel_size=kernel_size)\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=out_channel, eps=epsilon, momentum=momentum)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        # input (batch_size, num_variables, time_steps), e.g. (128, 1, 512)\n",
        "        x = self.conv(x)\n",
        "        # input (batch_size, out_channel, L_out)\n",
        "        x = self.batch_norm(x)\n",
        "        # same shape as input\n",
        "        y = self.relu(x)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sxIcU-lx9GeV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### FCN block"
      ]
    },
    {
      "metadata": {
        "id": "lNDU3Mij89dR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BlockFCN(nn.Module):\n",
        "    def __init__(self, time_steps, channels=[1, 128, 256, 128], kernels=[8, 5, 3], mom=0.99, eps=0.001):\n",
        "        super().__init__()\n",
        "        self.conv1 = BlockFCNConv(channels[0], channels[1], kernels[0], momentum=mom, epsilon=eps, squeeze=True)\n",
        "        self.conv2 = BlockFCNConv(channels[1], channels[2], kernels[1], momentum=mom, epsilon=eps, squeeze=True)\n",
        "        self.conv3 = BlockFCNConv(channels[2], channels[3], kernels[2], momentum=mom, epsilon=eps)\n",
        "        output_size = time_steps - sum(kernels) + len(kernels)\n",
        "        self.global_pooling = nn.AvgPool1d(kernel_size=output_size)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        # apply Global Average Pooling 1D\n",
        "        y = self.global_pooling(x)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mFYGCNCqPQfq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM-FCN"
      ]
    },
    {
      "metadata": {
        "id": "QQznEOKCKygx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LSTMFCN(nn.Module):\n",
        "    def __init__(self, time_steps, num_variables=1, lstm_hs=256, channels=[1, 128, 256, 128]):\n",
        "        super().__init__()\n",
        "        self.lstm_block = BlockLSTM(time_steps, 1, lstm_hs)\n",
        "        self.fcn_block = BlockFCN(time_steps)\n",
        "        self.dense = nn.Linear(channels[-1] + lstm_hs, num_variables)\n",
        "        self.softmax = nn.LogSoftmax(dim=1) #nn.Softmax(dim=1)\n",
        "    def forward(self, x):\n",
        "        # input is (batch_size, time_steps), it has to be (batch_size, 1, time_steps)\n",
        "        x = x.unsqueeze(1)\n",
        "        # pass input through LSTM block\n",
        "        x1 = self.lstm_block(x)\n",
        "        x1 = torch.squeeze(x1)\n",
        "        # pass input through FCN block\n",
        "        x2 = self.fcn_block(x)\n",
        "        x2 = torch.squeeze(x2)\n",
        "        # concatenate blocks output\n",
        "        x = torch.cat([x1, x2], 1)\n",
        "        # pass through Linear layer\n",
        "        x = self.dense(x)\n",
        "        #x = torch.squeeze(x)\n",
        "        # pass through Softmax activation\n",
        "        y = self.softmax(x)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZXyATnq7WOKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "BCHDSTVzRKGR",
        "colab_type": "code",
        "outputId": "40bd7700-7afb-439e-98c2-6b2df632ae39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "time_steps = X_train.shape[1]\n",
        "num_variables = classes\n",
        "\n",
        "time_steps, num_variables"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "i9eJ3zlrWV7A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = LSTMFCN(time_steps, num_variables).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b27y39-dh0Ik",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "look at the different blocks of the Model"
      ]
    },
    {
      "metadata": {
        "id": "i0c4x4NViexX",
        "colab_type": "code",
        "outputId": "8d3e6339-99ff-4245-a2b4-4e8b34e9d908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "# model summary\n",
        "for m in model.children():\n",
        "    print(m.training)#, m)\n",
        "    for j in m.children():\n",
        "        print(j.training, j)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True LSTM(512, 256)\n",
            "True Dropout(p=0.8)\n",
            "True\n",
            "True BlockFCNConv(\n",
            "  (conv): Conv1d(1, 128, kernel_size=(8,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "True BlockFCNConv(\n",
            "  (conv): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(256, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "True BlockFCNConv(\n",
            "  (conv): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "True AvgPool1d(kernel_size=(499,), stride=(499,), padding=(0,))\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xeWqQhn9XPUU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "look at the parameters (i.e. weights) in each layer"
      ]
    },
    {
      "metadata": {
        "id": "-F4_pcUqW8He",
        "colab_type": "code",
        "outputId": "995bce86-136f-45dd-f31b-46020ecfbb79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "[p.shape for p in model.parameters()]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([1024, 512]),\n",
              " torch.Size([1024, 256]),\n",
              " torch.Size([1024]),\n",
              " torch.Size([1024]),\n",
              " torch.Size([128, 1, 8]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([256, 128, 5]),\n",
              " torch.Size([256]),\n",
              " torch.Size([256]),\n",
              " torch.Size([256]),\n",
              " torch.Size([128, 256, 3]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([2, 384]),\n",
              " torch.Size([2])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "vUO4oNKkxAYs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define a learner class to automate the learning process"
      ]
    },
    {
      "metadata": {
        "id": "RnEiGUWHw_kX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SimpleLearner():\n",
        "    def __init__(self, data, model, loss_func, wd = 1e-5):\n",
        "        self.data, self.model, self.loss_func = data, model, loss_func\n",
        "        self.wd = wd\n",
        "    \n",
        "    def update_manualgrad(self, x,y,lr):\n",
        "        y_hat = self.model(x)\n",
        "        # weight decay\n",
        "        w2 = 0.\n",
        "        for p in model.parameters(): w2 += (p**2).sum()\n",
        "        # add to regular loss\n",
        "        loss = self.loss_func(y_hat, y) + w2 * self.wd\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            for p in model.parameters():\n",
        "                p.sub_(lr * p.grad)\n",
        "                p.grad.zero_()\n",
        "        return loss.item()\n",
        "\n",
        "    def update(self, x,y,lr):\n",
        "        opt = optim.Adam(self.model.parameters(), lr)\n",
        "        y_hat = self.model(x)\n",
        "        loss = self.loss_func(y_hat, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        return loss.item()\n",
        "\n",
        "    def fit(self, epochs=1, lr=1e-3):\n",
        "        \"\"\"Train the model\"\"\"\n",
        "        losses = []\n",
        "        for i in tqdm(range(epochs)):\n",
        "            for x,y in self.data[0]:\n",
        "                current_loss = self.update(x, y , lr)\n",
        "                losses.append(current_loss)\n",
        "        return losses\n",
        "    \n",
        "    def evaluate(self, X):\n",
        "        \"\"\"Evaluate the given data loader on the model and return predictions\"\"\"\n",
        "        result = None\n",
        "        for x, y in X:\n",
        "            y_hat = self.model(x)\n",
        "            result = y_hat if result is None else np.concatenate((result, y_hat), axis=0)\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "61O6OGUTqkoK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = LSTMFCN(time_steps, num_variables).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "txh5ujbKXhuz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "train the model using the DataLoader"
      ]
    },
    {
      "metadata": {
        "id": "GMAfJH9KAY0h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# depending on the number of classes, use a Binary Cross Entropy or a Negative Log Likelihood loss for more than two classes\n",
        "loss_func = nn.NLLLoss().cuda() # weight=weights\n",
        "acc_func = accuracy_thresh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xxVx2A1pXtuY",
        "colab_type": "code",
        "outputId": "f022dd0d-aa6b-4135-eaf7-ca720e8ffcda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "lr = 2e-2\n",
        "learner = SimpleLearner([train_dl, test_dl], model, loss_func)\n",
        "losses = learner.fit(10)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  3.96it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4W1s1mql_ELt",
        "colab_type": "code",
        "outputId": "a26bf9f1-957f-4405-9078-8d2e261bd892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(losses)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff4780fde10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD5CAYAAAA6JL6mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff47ca75400>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "XyvN_-cSmWPx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = learner.evaluate(test_dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HiVoIWUqp268",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f209ce0-070c-48b4-8501-8c848c02ece2"
      },
      "cell_type": "code",
      "source": [
        "((y_test - y_pred.argmax(axis=1))**2).mean()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2517985611510791"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "jEA7dKEUmP_e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training with fastai"
      ]
    },
    {
      "metadata": {
        "id": "r3LLF5X9mPJ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = LSTMFCN(time_steps, num_variables).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IDwkjDH5rXCy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = DataBunch(train_dl=train_dl, valid_dl=test_dl, path=path)\n",
        "learner = Learner(data, model, loss_func=loss_func, metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jhv_-NkEknVO",
        "colab_type": "code",
        "outputId": "8e0510fb-6feb-4b91-e6c4-866780c1203f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        }
      },
      "cell_type": "code",
      "source": [
        "learner.unfreeze()\n",
        "learner.lr_find()\n",
        "learner.recorder.plot()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "        \t/* Turns off some styling */\n",
              "        \tprogress {\n",
              "\n",
              "            \t/* gets rid of default border in Firefox and Opera. */\n",
              "            \tborder: none;\n",
              "\n",
              "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "            \tbackground-size: auto;\n",
              "            }\n",
              "\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='17', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      94.12% [16/17 00:04<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>0.693082</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>2</th>\n",
              "    <th>0.687579</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>3</th>\n",
              "    <th>0.690228</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>4</th>\n",
              "    <th>0.690291</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>5</th>\n",
              "    <th>0.689257</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>6</th>\n",
              "    <th>0.688446</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>7</th>\n",
              "    <th>0.681481</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>8</th>\n",
              "    <th>0.668675</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>9</th>\n",
              "    <th>0.637490</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>10</th>\n",
              "    <th>0.593089</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>11</th>\n",
              "    <th>0.543345</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>12</th>\n",
              "    <th>0.485986</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>13</th>\n",
              "    <th>0.439436</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>14</th>\n",
              "    <th>0.431389</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>15</th>\n",
              "    <th>0.723409</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>16</th>\n",
              "    <th>1.657361</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "\n",
              "  </tr>\n",
              "</table>\n",
              "\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "        \t/* Turns off some styling */\n",
              "        \tprogress {\n",
              "\n",
              "            \t/* gets rid of default border in Firefox and Opera. */\n",
              "            \tborder: none;\n",
              "\n",
              "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "            \tbackground-size: auto;\n",
              "            }\n",
              "\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='6', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEKCAYAAAAb7IIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBUoFQESkQP1/XsdjP/bgFC4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff47c97bd30>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Lex4Hkn078kn",
        "colab_type": "code",
        "outputId": "550a3a7d-64ea-46c4-b692-0b70e930f5bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "learner.fit(10, lr=3e-3)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time: 00:03\n",
            "epoch  train_loss  valid_loss  accuracy\n",
            "1      0.541843    0.532397    0.748201  (00:00)\n",
            "2      0.424915    0.625534    0.748201  (00:00)\n",
            "3      0.364389    0.607573    0.748201  (00:00)\n",
            "4      0.313684    0.621339    0.748201  (00:00)\n",
            "5      0.266761    0.619867    0.748201  (00:00)\n",
            "6      0.226095    0.609760    0.748201  (00:00)\n",
            "7      0.191461    0.615065    0.755396  (00:00)\n",
            "8      0.162049    0.633066    0.755396  (00:00)\n",
            "9      0.137363    0.658546    0.748201  (00:00)\n",
            "10     0.117196    0.679793    0.748201  (00:00)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lVO2pL6br0n1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2482
        },
        "outputId": "6b1303f1-c839-4b87-f78b-7738bef867d7"
      },
      "cell_type": "code",
      "source": [
        "learner.get_preds(DatasetType.Valid)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[9.9425e-01, 5.7537e-03],\n",
              "         [7.2724e-01, 2.7276e-01],\n",
              "         [9.9526e-01, 4.7443e-03],\n",
              "         [9.9658e-01, 3.4218e-03],\n",
              "         [6.0188e-01, 3.9812e-01],\n",
              "         [9.9603e-01, 3.9694e-03],\n",
              "         [9.8937e-01, 1.0634e-02],\n",
              "         [9.8595e-01, 1.4051e-02],\n",
              "         [6.0619e-01, 3.9381e-01],\n",
              "         [9.5675e-01, 4.3249e-02],\n",
              "         [9.9305e-01, 6.9478e-03],\n",
              "         [9.5982e-01, 4.0185e-02],\n",
              "         [8.4680e-01, 1.5320e-01],\n",
              "         [9.7382e-01, 2.6183e-02],\n",
              "         [9.9200e-01, 8.0023e-03],\n",
              "         [7.2946e-01, 2.7054e-01],\n",
              "         [9.0504e-01, 9.4956e-02],\n",
              "         [9.9728e-01, 2.7198e-03],\n",
              "         [9.6200e-01, 3.7998e-02],\n",
              "         [8.4773e-01, 1.5227e-01],\n",
              "         [8.2070e-01, 1.7930e-01],\n",
              "         [9.9535e-01, 4.6532e-03],\n",
              "         [9.0245e-01, 9.7546e-02],\n",
              "         [9.6488e-01, 3.5121e-02],\n",
              "         [9.6708e-01, 3.2921e-02],\n",
              "         [9.1114e-01, 8.8860e-02],\n",
              "         [6.7380e-01, 3.2620e-01],\n",
              "         [9.9140e-01, 8.6026e-03],\n",
              "         [9.9147e-01, 8.5279e-03],\n",
              "         [9.9574e-01, 4.2569e-03],\n",
              "         [6.7916e-01, 3.2084e-01],\n",
              "         [8.1221e-01, 1.8779e-01],\n",
              "         [7.2926e-01, 2.7074e-01],\n",
              "         [6.7195e-01, 3.2805e-01],\n",
              "         [9.7636e-01, 2.3637e-02],\n",
              "         [9.8936e-01, 1.0645e-02],\n",
              "         [9.8023e-01, 1.9773e-02],\n",
              "         [9.8331e-01, 1.6693e-02],\n",
              "         [9.8056e-01, 1.9441e-02],\n",
              "         [8.0585e-01, 1.9415e-01],\n",
              "         [8.5409e-01, 1.4591e-01],\n",
              "         [9.6576e-01, 3.4244e-02],\n",
              "         [5.7844e-01, 4.2156e-01],\n",
              "         [8.5839e-01, 1.4161e-01],\n",
              "         [8.3605e-01, 1.6395e-01],\n",
              "         [7.9539e-01, 2.0461e-01],\n",
              "         [9.9599e-01, 4.0103e-03],\n",
              "         [8.9708e-01, 1.0292e-01],\n",
              "         [9.9833e-01, 1.6663e-03],\n",
              "         [9.9922e-01, 7.7785e-04],\n",
              "         [9.3736e-01, 6.2635e-02],\n",
              "         [9.7506e-01, 2.4941e-02],\n",
              "         [9.9683e-01, 3.1704e-03],\n",
              "         [9.6329e-01, 3.6711e-02],\n",
              "         [9.9205e-01, 7.9503e-03],\n",
              "         [8.9988e-01, 1.0012e-01],\n",
              "         [3.4490e-01, 6.5510e-01],\n",
              "         [9.9277e-01, 7.2321e-03],\n",
              "         [9.4736e-01, 5.2636e-02],\n",
              "         [8.4546e-01, 1.5454e-01],\n",
              "         [9.8601e-01, 1.3993e-02],\n",
              "         [9.6343e-01, 3.6571e-02],\n",
              "         [9.6380e-01, 3.6198e-02],\n",
              "         [5.7684e-01, 4.2316e-01],\n",
              "         [7.6970e-01, 2.3030e-01],\n",
              "         [5.4828e-01, 4.5172e-01],\n",
              "         [9.5975e-01, 4.0253e-02],\n",
              "         [6.9527e-01, 3.0473e-01],\n",
              "         [8.5458e-01, 1.4542e-01],\n",
              "         [9.9969e-01, 3.0637e-04],\n",
              "         [9.5228e-01, 4.7721e-02],\n",
              "         [9.5492e-01, 4.5078e-02],\n",
              "         [9.8068e-01, 1.9323e-02],\n",
              "         [7.1458e-01, 2.8542e-01],\n",
              "         [5.6506e-01, 4.3494e-01],\n",
              "         [9.8045e-01, 1.9546e-02],\n",
              "         [9.2896e-01, 7.1041e-02],\n",
              "         [9.9604e-01, 3.9574e-03],\n",
              "         [9.8500e-01, 1.4995e-02],\n",
              "         [9.3539e-01, 6.4615e-02],\n",
              "         [6.9669e-01, 3.0331e-01],\n",
              "         [8.9084e-01, 1.0916e-01],\n",
              "         [9.2574e-01, 7.4258e-02],\n",
              "         [9.9943e-01, 5.7221e-04],\n",
              "         [9.5959e-01, 4.0410e-02],\n",
              "         [9.5426e-01, 4.5743e-02],\n",
              "         [9.8531e-01, 1.4690e-02],\n",
              "         [9.9888e-01, 1.1250e-03],\n",
              "         [6.8742e-01, 3.1258e-01],\n",
              "         [9.9715e-01, 2.8496e-03],\n",
              "         [7.7061e-01, 2.2939e-01],\n",
              "         [6.5534e-01, 3.4466e-01],\n",
              "         [4.4688e-01, 5.5312e-01],\n",
              "         [8.8147e-01, 1.1853e-01],\n",
              "         [9.9980e-01, 1.9565e-04],\n",
              "         [7.6115e-01, 2.3885e-01],\n",
              "         [9.9205e-01, 7.9482e-03],\n",
              "         [6.2418e-01, 3.7582e-01],\n",
              "         [9.5457e-01, 4.5432e-02],\n",
              "         [9.3219e-01, 6.7809e-02],\n",
              "         [9.7844e-01, 2.1556e-02],\n",
              "         [8.5520e-01, 1.4480e-01],\n",
              "         [9.2151e-01, 7.8488e-02],\n",
              "         [9.9145e-01, 8.5452e-03],\n",
              "         [6.2208e-01, 3.7792e-01],\n",
              "         [9.5117e-01, 4.8829e-02],\n",
              "         [5.7008e-01, 4.2992e-01],\n",
              "         [9.8578e-01, 1.4219e-02],\n",
              "         [9.9276e-01, 7.2404e-03],\n",
              "         [6.2644e-01, 3.7356e-01],\n",
              "         [9.4103e-01, 5.8970e-02],\n",
              "         [2.6042e-01, 7.3958e-01],\n",
              "         [8.4114e-01, 1.5886e-01],\n",
              "         [9.9983e-01, 1.7048e-04],\n",
              "         [9.8680e-01, 1.3196e-02],\n",
              "         [8.4676e-01, 1.5324e-01],\n",
              "         [9.6020e-01, 3.9797e-02],\n",
              "         [8.7532e-01, 1.2468e-01],\n",
              "         [9.8866e-01, 1.1343e-02],\n",
              "         [8.3955e-01, 1.6045e-01],\n",
              "         [8.9132e-01, 1.0868e-01],\n",
              "         [9.9871e-01, 1.2883e-03],\n",
              "         [9.8665e-01, 1.3352e-02],\n",
              "         [7.1213e-01, 2.8787e-01],\n",
              "         [9.3852e-01, 6.1476e-02],\n",
              "         [2.2901e-01, 7.7099e-01],\n",
              "         [9.4070e-01, 5.9303e-02],\n",
              "         [9.7276e-01, 2.7241e-02],\n",
              "         [7.0276e-01, 2.9724e-01],\n",
              "         [9.7210e-01, 2.7895e-02],\n",
              "         [9.9671e-01, 3.2880e-03],\n",
              "         [5.3830e-01, 4.6170e-01],\n",
              "         [8.5895e-01, 1.4105e-01],\n",
              "         [8.7945e-01, 1.2055e-01],\n",
              "         [9.9073e-01, 9.2734e-03],\n",
              "         [9.6120e-01, 3.8799e-02],\n",
              "         [5.0640e-01, 4.9360e-01],\n",
              "         [5.9930e-01, 4.0070e-01],\n",
              "         [9.7728e-01, 2.2716e-02]]),\n",
              " tensor([0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "2q4KDLq8smva",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5729
        },
        "outputId": "a97ba90e-51c3-4234-8db6-4d92613681e8"
      },
      "cell_type": "code",
      "source": [
        "learner.get_preds(DatasetType.Train)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[1.5684e-02, 9.8432e-01],\n",
              "         [9.9908e-01, 9.1769e-04],\n",
              "         [9.9926e-01, 7.3570e-04],\n",
              "         [9.9601e-01, 3.9895e-03],\n",
              "         [1.3008e-02, 9.8699e-01],\n",
              "         [9.9925e-01, 7.5358e-04],\n",
              "         [9.9726e-01, 2.7361e-03],\n",
              "         [9.9797e-01, 2.0253e-03],\n",
              "         [9.9942e-01, 5.8129e-04],\n",
              "         [9.9634e-01, 3.6594e-03],\n",
              "         [9.9959e-01, 4.0713e-04],\n",
              "         [9.9776e-01, 2.2447e-03],\n",
              "         [9.9822e-01, 1.7800e-03],\n",
              "         [9.9990e-01, 9.8095e-05],\n",
              "         [9.9535e-01, 4.6463e-03],\n",
              "         [9.9878e-01, 1.2152e-03],\n",
              "         [9.9834e-01, 1.6643e-03],\n",
              "         [9.9819e-01, 1.8071e-03],\n",
              "         [9.9768e-01, 2.3164e-03],\n",
              "         [9.9579e-01, 4.2094e-03],\n",
              "         [9.9694e-01, 3.0576e-03],\n",
              "         [9.9971e-01, 2.8665e-04],\n",
              "         [1.3145e-02, 9.8686e-01],\n",
              "         [9.9311e-01, 6.8919e-03],\n",
              "         [2.1091e-01, 7.8909e-01],\n",
              "         [9.9779e-01, 2.2140e-03],\n",
              "         [9.9712e-01, 2.8802e-03],\n",
              "         [1.3792e-02, 9.8621e-01],\n",
              "         [1.5765e-02, 9.8424e-01],\n",
              "         [8.9634e-03, 9.9104e-01],\n",
              "         [9.9891e-01, 1.0917e-03],\n",
              "         [9.9966e-01, 3.3869e-04],\n",
              "         [9.9783e-01, 2.1692e-03],\n",
              "         [1.3906e-02, 9.8609e-01],\n",
              "         [9.9917e-01, 8.2742e-04],\n",
              "         [9.9382e-01, 6.1754e-03],\n",
              "         [9.9785e-01, 2.1471e-03],\n",
              "         [9.8810e-01, 1.1897e-02],\n",
              "         [9.9942e-01, 5.8150e-04],\n",
              "         [5.0339e-03, 9.9497e-01],\n",
              "         [9.9882e-01, 1.1757e-03],\n",
              "         [9.9909e-01, 9.0666e-04],\n",
              "         [9.9951e-01, 4.8880e-04],\n",
              "         [1.5864e-02, 9.8414e-01],\n",
              "         [9.9967e-01, 3.3191e-04],\n",
              "         [9.9628e-01, 3.7246e-03],\n",
              "         [1.4284e-02, 9.8572e-01],\n",
              "         [9.9714e-01, 2.8641e-03],\n",
              "         [9.9339e-01, 6.6098e-03],\n",
              "         [4.9551e-02, 9.5045e-01],\n",
              "         [9.9892e-01, 1.0769e-03],\n",
              "         [9.9954e-01, 4.5784e-04],\n",
              "         [9.9115e-01, 8.8493e-03],\n",
              "         [9.9771e-01, 2.2883e-03],\n",
              "         [9.9798e-01, 2.0216e-03],\n",
              "         [1.1294e-02, 9.8871e-01],\n",
              "         [9.2261e-03, 9.9077e-01],\n",
              "         [3.8848e-03, 9.9612e-01],\n",
              "         [9.9464e-01, 5.3565e-03],\n",
              "         [9.9808e-01, 1.9165e-03],\n",
              "         [9.9882e-01, 1.1821e-03],\n",
              "         [9.9173e-01, 8.2655e-03],\n",
              "         [9.9776e-01, 2.2422e-03],\n",
              "         [9.9925e-01, 7.4957e-04],\n",
              "         [9.9956e-01, 4.4424e-04],\n",
              "         [9.9945e-01, 5.5181e-04],\n",
              "         [9.9918e-01, 8.1837e-04],\n",
              "         [9.9878e-01, 1.2160e-03],\n",
              "         [9.9861e-01, 1.3866e-03],\n",
              "         [9.9949e-01, 5.0978e-04],\n",
              "         [9.9564e-01, 4.3640e-03],\n",
              "         [1.6268e-02, 9.8373e-01],\n",
              "         [9.9301e-01, 6.9909e-03],\n",
              "         [9.9955e-01, 4.5325e-04],\n",
              "         [9.9673e-01, 3.2714e-03],\n",
              "         [9.9821e-01, 1.7937e-03],\n",
              "         [9.9885e-01, 1.1540e-03],\n",
              "         [9.9879e-01, 1.2076e-03],\n",
              "         [9.9883e-01, 1.1718e-03],\n",
              "         [9.9793e-01, 2.0712e-03],\n",
              "         [9.9932e-01, 6.7820e-04],\n",
              "         [9.9941e-01, 5.8792e-04],\n",
              "         [9.9812e-01, 1.8749e-03],\n",
              "         [9.9841e-01, 1.5929e-03],\n",
              "         [9.9777e-01, 2.2326e-03],\n",
              "         [9.9267e-01, 7.3334e-03],\n",
              "         [9.9397e-01, 6.0259e-03],\n",
              "         [9.9963e-01, 3.7365e-04],\n",
              "         [9.9446e-01, 5.5409e-03],\n",
              "         [2.2584e-02, 9.7742e-01],\n",
              "         [9.9541e-01, 4.5855e-03],\n",
              "         [9.9020e-01, 9.7956e-03],\n",
              "         [9.9947e-01, 5.2887e-04],\n",
              "         [9.9846e-01, 1.5443e-03],\n",
              "         [9.9764e-01, 2.3634e-03],\n",
              "         [9.9695e-01, 3.0542e-03],\n",
              "         [9.9479e-01, 5.2080e-03],\n",
              "         [9.9893e-01, 1.0724e-03],\n",
              "         [9.9810e-01, 1.9017e-03],\n",
              "         [1.7944e-02, 9.8206e-01],\n",
              "         [9.9790e-01, 2.0962e-03],\n",
              "         [9.9694e-01, 3.0603e-03],\n",
              "         [5.8309e-03, 9.9417e-01],\n",
              "         [9.9953e-01, 4.7157e-04],\n",
              "         [9.9554e-01, 4.4635e-03],\n",
              "         [9.9861e-01, 1.3914e-03],\n",
              "         [9.9390e-01, 6.0981e-03],\n",
              "         [9.9651e-01, 3.4945e-03],\n",
              "         [9.9819e-01, 1.8145e-03],\n",
              "         [9.9842e-01, 1.5822e-03],\n",
              "         [9.9856e-01, 1.4421e-03],\n",
              "         [9.9740e-01, 2.5966e-03],\n",
              "         [9.9920e-01, 8.0387e-04],\n",
              "         [9.9851e-01, 1.4922e-03],\n",
              "         [9.9918e-01, 8.2482e-04],\n",
              "         [9.9863e-01, 1.3656e-03],\n",
              "         [9.9950e-01, 5.0205e-04],\n",
              "         [9.9951e-01, 4.9454e-04],\n",
              "         [1.8219e-02, 9.8178e-01],\n",
              "         [1.3734e-02, 9.8627e-01],\n",
              "         [6.0725e-02, 9.3927e-01],\n",
              "         [3.6720e-03, 9.9633e-01],\n",
              "         [9.9756e-01, 2.4367e-03],\n",
              "         [9.3706e-03, 9.9063e-01],\n",
              "         [9.9977e-01, 2.3170e-04],\n",
              "         [1.3413e-02, 9.8659e-01],\n",
              "         [9.9565e-01, 4.3520e-03],\n",
              "         [9.9671e-01, 3.2914e-03],\n",
              "         [8.1441e-03, 9.9186e-01],\n",
              "         [2.9732e-02, 9.7027e-01],\n",
              "         [9.9643e-01, 3.5657e-03],\n",
              "         [9.9340e-01, 6.5991e-03],\n",
              "         [9.9715e-01, 2.8525e-03],\n",
              "         [9.9308e-01, 6.9152e-03],\n",
              "         [9.9776e-01, 2.2390e-03],\n",
              "         [9.9773e-01, 2.2744e-03],\n",
              "         [3.3608e-03, 9.9664e-01],\n",
              "         [9.9163e-01, 8.3748e-03],\n",
              "         [9.9896e-01, 1.0408e-03],\n",
              "         [9.9789e-01, 2.1127e-03],\n",
              "         [9.9785e-01, 2.1541e-03],\n",
              "         [9.9621e-01, 3.7927e-03],\n",
              "         [9.9815e-01, 1.8493e-03],\n",
              "         [9.9828e-01, 1.7234e-03],\n",
              "         [9.9132e-01, 8.6788e-03],\n",
              "         [9.8203e-01, 1.7973e-02],\n",
              "         [1.2204e-02, 9.8780e-01],\n",
              "         [9.9937e-01, 6.3408e-04],\n",
              "         [2.8191e-02, 9.7181e-01],\n",
              "         [9.9778e-01, 2.2194e-03],\n",
              "         [1.1314e-01, 8.8686e-01],\n",
              "         [9.9738e-01, 2.6200e-03],\n",
              "         [1.3777e-02, 9.8622e-01],\n",
              "         [9.9661e-01, 3.3908e-03],\n",
              "         [9.9784e-01, 2.1579e-03],\n",
              "         [9.9836e-01, 1.6353e-03],\n",
              "         [9.9628e-01, 3.7174e-03],\n",
              "         [9.9880e-01, 1.1958e-03],\n",
              "         [9.9799e-01, 2.0128e-03],\n",
              "         [9.9705e-01, 2.9457e-03],\n",
              "         [9.9931e-01, 6.9209e-04],\n",
              "         [9.9953e-01, 4.7330e-04],\n",
              "         [3.2726e-02, 9.6727e-01],\n",
              "         [1.8549e-02, 9.8145e-01],\n",
              "         [9.9788e-01, 2.1175e-03],\n",
              "         [9.9882e-01, 1.1810e-03],\n",
              "         [9.9889e-01, 1.1149e-03],\n",
              "         [9.9633e-01, 3.6737e-03],\n",
              "         [9.9986e-01, 1.4104e-04],\n",
              "         [9.9979e-01, 2.1062e-04],\n",
              "         [9.9780e-01, 2.2007e-03],\n",
              "         [3.8756e-03, 9.9612e-01],\n",
              "         [9.9411e-01, 5.8936e-03],\n",
              "         [9.9736e-01, 2.6351e-03],\n",
              "         [9.9975e-01, 2.5221e-04],\n",
              "         [9.6982e-03, 9.9030e-01],\n",
              "         [9.9853e-01, 1.4686e-03],\n",
              "         [9.9863e-01, 1.3660e-03],\n",
              "         [9.9557e-01, 4.4319e-03],\n",
              "         [9.9948e-01, 5.1874e-04],\n",
              "         [9.8831e-01, 1.1691e-02],\n",
              "         [9.9933e-01, 6.7250e-04],\n",
              "         [9.9910e-01, 9.0280e-04],\n",
              "         [9.9945e-01, 5.4911e-04],\n",
              "         [9.9775e-01, 2.2462e-03],\n",
              "         [7.0621e-03, 9.9294e-01],\n",
              "         [4.4666e-02, 9.5533e-01],\n",
              "         [2.4042e-02, 9.7596e-01],\n",
              "         [9.9735e-01, 2.6492e-03],\n",
              "         [9.9806e-01, 1.9361e-03],\n",
              "         [9.9894e-01, 1.0625e-03],\n",
              "         [9.9674e-01, 3.2550e-03],\n",
              "         [9.9737e-01, 2.6291e-03],\n",
              "         [9.9876e-01, 1.2400e-03],\n",
              "         [9.9569e-01, 4.3109e-03],\n",
              "         [9.9841e-01, 1.5868e-03],\n",
              "         [9.9598e-01, 4.0175e-03],\n",
              "         [9.9377e-01, 6.2294e-03],\n",
              "         [9.9758e-01, 2.4160e-03],\n",
              "         [9.9676e-01, 3.2370e-03],\n",
              "         [9.9138e-01, 8.6193e-03],\n",
              "         [2.1158e-02, 9.7884e-01],\n",
              "         [9.9649e-01, 3.5096e-03],\n",
              "         [1.9968e-02, 9.8003e-01],\n",
              "         [9.9977e-01, 2.2611e-04],\n",
              "         [9.7489e-01, 2.5108e-02],\n",
              "         [9.9714e-01, 2.8623e-03],\n",
              "         [9.9738e-01, 2.6188e-03],\n",
              "         [9.9785e-01, 2.1512e-03],\n",
              "         [9.9707e-01, 2.9314e-03],\n",
              "         [9.9513e-01, 4.8697e-03],\n",
              "         [2.1338e-02, 9.7866e-01],\n",
              "         [9.9596e-01, 4.0449e-03],\n",
              "         [9.9321e-01, 6.7889e-03],\n",
              "         [9.9956e-01, 4.3836e-04],\n",
              "         [9.9827e-01, 1.7332e-03],\n",
              "         [9.9716e-01, 2.8429e-03],\n",
              "         [9.9575e-01, 4.2476e-03],\n",
              "         [9.9919e-01, 8.0834e-04],\n",
              "         [9.9971e-01, 2.9171e-04],\n",
              "         [9.8817e-01, 1.1826e-02],\n",
              "         [9.9912e-01, 8.8389e-04],\n",
              "         [9.9987e-01, 1.2833e-04],\n",
              "         [9.9808e-01, 1.9197e-03],\n",
              "         [9.9686e-01, 3.1416e-03],\n",
              "         [1.9594e-02, 9.8041e-01],\n",
              "         [9.9816e-01, 1.8444e-03],\n",
              "         [9.9924e-01, 7.5560e-04],\n",
              "         [9.9876e-01, 1.2427e-03],\n",
              "         [9.9679e-01, 3.2062e-03],\n",
              "         [1.1991e-02, 9.8801e-01],\n",
              "         [9.9828e-01, 1.7245e-03],\n",
              "         [1.5737e-02, 9.8426e-01],\n",
              "         [9.9975e-01, 2.5152e-04],\n",
              "         [9.9769e-01, 2.3121e-03],\n",
              "         [9.9971e-01, 2.8507e-04],\n",
              "         [9.9924e-01, 7.6309e-04],\n",
              "         [9.9909e-01, 9.0978e-04],\n",
              "         [2.0047e-02, 9.7995e-01],\n",
              "         [9.9777e-01, 2.2324e-03],\n",
              "         [9.9964e-01, 3.6088e-04],\n",
              "         [9.9587e-01, 4.1258e-03],\n",
              "         [9.9663e-01, 3.3678e-03],\n",
              "         [9.8723e-01, 1.2766e-02],\n",
              "         [9.8768e-03, 9.9012e-01],\n",
              "         [9.9814e-01, 1.8581e-03],\n",
              "         [9.9959e-01, 4.0662e-04],\n",
              "         [9.9814e-01, 1.8565e-03],\n",
              "         [9.9341e-01, 6.5885e-03],\n",
              "         [5.9755e-03, 9.9402e-01],\n",
              "         [4.1992e-03, 9.9580e-01],\n",
              "         [9.9921e-01, 7.8859e-04],\n",
              "         [9.9760e-01, 2.3960e-03],\n",
              "         [9.9957e-01, 4.3407e-04],\n",
              "         [9.9874e-01, 1.2570e-03],\n",
              "         [9.9980e-01, 2.0437e-04],\n",
              "         [9.9876e-01, 1.2379e-03],\n",
              "         [9.9644e-01, 3.5619e-03],\n",
              "         [9.9827e-01, 1.7338e-03],\n",
              "         [9.9207e-01, 7.9299e-03],\n",
              "         [9.9815e-01, 1.8469e-03],\n",
              "         [9.9637e-01, 3.6267e-03],\n",
              "         [1.6987e-02, 9.8301e-01],\n",
              "         [9.9560e-01, 4.4036e-03],\n",
              "         [3.8761e-02, 9.6124e-01],\n",
              "         [9.9937e-01, 6.2578e-04],\n",
              "         [9.9903e-01, 9.6519e-04],\n",
              "         [9.9433e-01, 5.6743e-03],\n",
              "         [9.7994e-01, 2.0057e-02],\n",
              "         [9.9916e-01, 8.4396e-04],\n",
              "         [9.9899e-01, 1.0124e-03],\n",
              "         [9.9813e-01, 1.8742e-03],\n",
              "         [9.9763e-01, 2.3675e-03],\n",
              "         [9.9702e-01, 2.9810e-03],\n",
              "         [9.9893e-01, 1.0739e-03],\n",
              "         [9.9985e-01, 1.4594e-04],\n",
              "         [9.9471e-01, 5.2911e-03],\n",
              "         [9.9890e-01, 1.1023e-03],\n",
              "         [9.9517e-01, 4.8344e-03],\n",
              "         [9.9903e-01, 9.6689e-04],\n",
              "         [9.9742e-01, 2.5780e-03],\n",
              "         [9.9225e-01, 7.7456e-03],\n",
              "         [9.9912e-01, 8.8362e-04],\n",
              "         [6.8537e-03, 9.9315e-01],\n",
              "         [9.9991e-01, 9.3584e-05],\n",
              "         [9.9619e-01, 3.8096e-03],\n",
              "         [1.3017e-02, 9.8698e-01],\n",
              "         [9.9825e-01, 1.7463e-03],\n",
              "         [9.9990e-01, 9.6709e-05],\n",
              "         [1.4980e-02, 9.8502e-01],\n",
              "         [9.9600e-01, 4.0002e-03],\n",
              "         [9.9858e-01, 1.4182e-03],\n",
              "         [4.2212e-03, 9.9578e-01],\n",
              "         [9.9807e-01, 1.9338e-03],\n",
              "         [9.8713e-01, 1.2867e-02],\n",
              "         [9.9693e-01, 3.0664e-03],\n",
              "         [2.2541e-02, 9.7746e-01],\n",
              "         [9.9811e-01, 1.8899e-03],\n",
              "         [9.9875e-01, 1.2471e-03],\n",
              "         [9.9989e-01, 1.1344e-04],\n",
              "         [9.9863e-01, 1.3699e-03],\n",
              "         [9.9746e-01, 2.5445e-03],\n",
              "         [9.9791e-01, 2.0931e-03],\n",
              "         [6.0165e-03, 9.9398e-01],\n",
              "         [9.9762e-01, 2.3804e-03],\n",
              "         [9.9983e-01, 1.6660e-04],\n",
              "         [9.9020e-01, 9.8002e-03],\n",
              "         [9.9878e-01, 1.2241e-03],\n",
              "         [9.9857e-01, 1.4280e-03],\n",
              "         [9.9310e-01, 6.9049e-03],\n",
              "         [9.9876e-01, 1.2364e-03],\n",
              "         [9.9792e-01, 2.0841e-03],\n",
              "         [9.9451e-01, 5.4947e-03],\n",
              "         [9.9933e-01, 6.6540e-04],\n",
              "         [9.9859e-01, 1.4115e-03],\n",
              "         [9.9599e-01, 4.0069e-03],\n",
              "         [9.8912e-01, 1.0879e-02],\n",
              "         [7.6852e-03, 9.9231e-01],\n",
              "         [9.9921e-01, 7.9157e-04],\n",
              "         [9.9983e-01, 1.7193e-04],\n",
              "         [9.9989e-01, 1.0621e-04],\n",
              "         [9.9995e-01, 5.1026e-05]]),\n",
              " tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "         1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "metadata": {
        "id": "QokS_SU5sAs-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training one cycle"
      ]
    },
    {
      "metadata": {
        "id": "nwkS7lQ6Nbq8",
        "colab_type": "code",
        "outputId": "8cde1ed5-5b26-43c9-8ca5-99b0b787952c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "data = DataBunch(train_dl=train_dl, valid_dl=test_dl, path=path)\n",
        "learner = Learner(data, model, loss_func=loss_func, metrics=accuracy)\n",
        "learner.fit(10, lr=5e-5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time: 00:03\n",
            "epoch  train_loss  valid_loss  accuracy\n",
            "1      0.003275    0.785197    0.762590  (00:00)\n",
            "2      0.003349    0.800480    0.762590  (00:00)\n",
            "3      0.003107    0.804093    0.762590  (00:00)\n",
            "4      0.002767    0.812344    0.762590  (00:00)\n",
            "5      0.002825    0.806561    0.762590  (00:00)\n",
            "6      0.002692    0.815485    0.755396  (00:00)\n",
            "7      0.002587    0.823958    0.755396  (00:00)\n",
            "8      0.002495    0.824159    0.755396  (00:00)\n",
            "9      0.002463    0.840908    0.755396  (00:00)\n",
            "10     0.002364    0.839903    0.755396  (00:00)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b8Pcr02Khxsy",
        "colab_type": "code",
        "outputId": "fe0ed6b4-c1e6-424e-88b4-780c223ceb44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "model.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMFCN(\n",
              "  (lstm_block): BlockLSTM(\n",
              "    (lstm): LSTM(512, 256)\n",
              "    (dropout): Dropout(p=0.8)\n",
              "  )\n",
              "  (fcn_block): BlockFCN(\n",
              "    (conv1): BlockFCNConv(\n",
              "      (conv): Conv1d(1, 128, kernel_size=(8,), stride=(1,))\n",
              "      (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (conv2): BlockFCNConv(\n",
              "      (conv): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
              "      (batch_norm): BatchNorm1d(256, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (conv3): BlockFCNConv(\n",
              "      (conv): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
              "      (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (global_pooling): AvgPool1d(kernel_size=(499,), stride=(499,), padding=(0,))\n",
              "  )\n",
              "  (dense): Linear(in_features=384, out_features=2, bias=True)\n",
              "  (softmax): LogSoftmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "metadata": {
        "id": "mTTetDTNVH-p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}