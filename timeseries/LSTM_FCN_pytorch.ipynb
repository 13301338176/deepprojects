{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-FCN-pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "NreY7BzeqHVd",
        "colab_type": "code",
        "outputId": "61fbfc23-00e5-46c8-b8ed-fe75e59fa6db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1397
        }
      },
      "cell_type": "code",
      "source": [
        "!curl https://course-v3.fast.ai/setup/colab | bash"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   665  100   665    0     0   3093      0 --:--:-- --:--:-- --:--:--  3093\n",
            "Collecting pillow==4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e5/88b3d60924a3f8476fa74ec086f5fbaba56dd6cee0d82845f883b6b6dd18/Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.7MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow==4.1.1) (0.46)\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-4.1.1\n",
            "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
            "Collecting torch_nightly\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/cu92/torch_nightly-1.0.0.dev20181125-cp36-cp36m-linux_x86_64.whl (576.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 576.5MB 24kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x63866000 @  0x7f1a64a992a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch-nightly\n",
            "Successfully installed torch-nightly-1.0.0.dev20181125\n",
            "Cloning into 'course-v3'...\n",
            "remote: Enumerating objects: 2450, done.\u001b[K\n",
            "remote: Total 2450 (delta 0), reused 0 (delta 0), pack-reused 2450\u001b[K\n",
            "Receiving objects: 100% (2450/2450), 59.09 MiB | 26.76 MiB/s, done.\n",
            "Resolving deltas: 100% (1338/1338), done.\n",
            "Collecting fastai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/fe/9686231cc2ed81a7096abda19d93ca43532d7b130a12d1ada8746ba75e72/fastai-1.0.28-py3-none-any.whl (120kB)\n",
            "\u001b[K    100% |████████████████████████████████| 122kB 4.0MB/s \n",
            "\u001b[?25hCollecting fastprogress>=0.1.15 (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/dc/b8/7ce2b3c6f886f5cb1b16e62d368456b4fdb7e16bba962571bc50dae49b30/fastprogress-0.1.15-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: typing in /usr/local/lib/python3.6/dist-packages (from fastai) (3.6.6)\n",
            "Collecting dataclasses (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Collecting bottleneck (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/ae/cedf5323f398ab4e4ff92d6c431a3e1c6a186f9b41ab3e8258dff786a290/Bottleneck-1.2.1.tar.gz (105kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.14.6)\n",
            "Collecting numexpr (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/ea/efd9e16283637eb5b6c0042b6cc3521f1b9a5b47767ac463c88bbd37670c/numexpr-2.6.8-cp36-cp36m-manylinux1_x86_64.whl (162kB)\n",
            "\u001b[K    100% |████████████████████████████████| 163kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.18.4)\n",
            "Requirement already satisfied, skipping upgrade: cymem==2.0.2 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: thinc==6.12.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (6.12.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (2.1.2)\n",
            "Requirement already satisfied, skipping upgrade: spacy==2.0.16 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.0.16)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from fastai) (2018.1.10)\n",
            "Collecting torchvision-nightly (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/bd/d0f9a33c81c79710eb7ee428b66869b49a8be16c7f1e446c211a7fbfb7be/torchvision_nightly-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.22.0)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai) (0.46)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2018.10.15)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: msgpack<1.0.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.5.6)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.0.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.9.0.1)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: dill<0.3.0,>=0.2.7 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.2.8.2)\n",
            "Requirement already satisfied, skipping upgrade: msgpack-numpy<0.4.4.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (1.10.11)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2018.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (1.35)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc==6.12.0->fastai) (0.9.0)\n",
            "Building wheels for collected packages: bottleneck\n",
            "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f2/bf/ec/e0f39aa27001525ad455139ee57ec7d0776fe074dfd78c97e4\n",
            "Successfully built bottleneck\n",
            "Installing collected packages: fastprogress, dataclasses, bottleneck, numexpr, torchvision-nightly, fastai\n",
            "Successfully installed bottleneck-1.2.1 dataclasses-0.6 fastai-1.0.28 fastprogress-0.1.15 numexpr-2.6.8 torchvision-nightly-0.2.1\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CKP2ikW1ngNl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OblomiW9n4bg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from fastai import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEwnf-gdntsa",
        "colab_type": "code",
        "outputId": "70529199-ec5d-4d75-fb74-6c25f4a1574a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!curl -O http://www.timeseriesclassification.com/Downloads/Earthquakes.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  516k  100  516k    0     0   420k      0  0:00:01  0:00:01 --:--:--  420k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qsr9wx88nyRG",
        "colab_type": "code",
        "outputId": "a3119c74-2055-4246-a6dd-28bc40c99a0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip Earthquakes.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Earthquakes.zip\n",
            "  inflating: Earthquakes.txt         \n",
            "  inflating: Earthquakes_TEST.arff   \n",
            "  inflating: Earthquakes_TEST.txt    \n",
            "  inflating: Earthquakes_TRAIN.arff  \n",
            "  inflating: Earthquakes_TRAIN.txt   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "onhUsHlhsWvc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bs = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O1pj6M8Vn-0D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATASET = 'Earthquakes'\n",
        "classes = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9EMN9yFin1cW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = pathlib.Path('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tDncQ40aHJkX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot_encode(input, labels):\n",
        "    m = input.shape[0]\n",
        "    output = np.zeros((m, labels))\n",
        "    row_index = np.arange(m)\n",
        "    output[row_index, input]\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A69YvILXoA5e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load training dataset\n",
        "data_train = np.loadtxt(path/'Earthquakes_TRAIN.txt')\n",
        "X_train, y_train = data_train[:, 1:], one_hot_encode(data_train[:, 0].astype(np.int), classes)\n",
        "\n",
        "# load testing dataset\n",
        "data_test = np.loadtxt(path/'Earthquakes_TEST.txt')\n",
        "X_test, y_test = data_test[:, 1:], one_hot_encode(data_test[:, 0].astype(np.int), classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9307nee9rz4Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "load the numpy training and test sets into pytorch Dataset object"
      ]
    },
    {
      "metadata": {
        "id": "gmqg-MVhaHFY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cuda = torch.device('cuda')     # Default CUDA device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Wqt26B1oD_g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_ds = TensorDataset(torch.tensor(X_train, dtype=torch.float32, device=cuda), torch.tensor(y_train, dtype=torch.float32, device=cuda))\n",
        "test_ds  = TensorDataset(torch.tensor(X_test, dtype=torch.float32, device=cuda), torch.tensor(y_test, dtype=torch.float32, device=cuda))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2uSDLS9-sBYl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "pass the Dataset objects into a DataLoader"
      ]
    },
    {
      "metadata": {
        "id": "5rckvuLErUGq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=False)\n",
        "test_dl = DataLoader(test_ds, batch_size=bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3A86zi48tdPG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## LSTM-FCN\n",
        "### LSMT block\n",
        "A shuffle layer + LSTM layer + Dropout layer"
      ]
    },
    {
      "metadata": {
        "id": "JDYfUKc8tQhu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BlockLSTM(nn.Module):\n",
        "    def __init__(self, time_steps, num_layers, lstm_hs, dropout=0.8, attention=False):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size=time_steps, hidden_size=lstm_hs, num_layers=num_layers)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "    def forward(self, x):\n",
        "        # input is of the form (batch_size, num_layers, time_steps), e.g. (128, 1, 512)\n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        # lstm layer is of the form (num_layers, batch_size, time_steps)\n",
        "        x, (h_n, c_n) = self.lstm(x)\n",
        "        # dropout layer input shape (Sequence Length, Batch Size, Hidden Size * Num Directions)\n",
        "        y = self.dropout(x)\n",
        "        # output shape is same as Dropout intput\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PskMJhzL8_Ao",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### FCN block\n",
        "\n",
        "#### Convolutional block"
      ]
    },
    {
      "metadata": {
        "id": "4oam7px91HYa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BlockFCNConv(nn.Module):\n",
        "    def __init__(self, in_channel=1, out_channel=128, kernel_size=8, momentum=0.99, epsilon=0.001, squeeze=False):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(in_channel, out_channel, kernel_size=kernel_size)\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=out_channel, eps=epsilon, momentum=momentum)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        # input (batch_size, num_variables, time_steps), e.g. (128, 1, 512)\n",
        "        x = self.conv(x)\n",
        "        # input (batch_size, out_channel, L_out)\n",
        "        x = self.batch_norm(x)\n",
        "        # same shape as input\n",
        "        y = self.relu(x)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sxIcU-lx9GeV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### FCN block"
      ]
    },
    {
      "metadata": {
        "id": "lNDU3Mij89dR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BlockFCN(nn.Module):\n",
        "    def __init__(self, time_steps, channels=[1, 128, 256, 128], kernels=[8, 5, 3], mom=0.99, eps=0.001):\n",
        "        super().__init__()\n",
        "        self.conv1 = BlockFCNConv(channels[0], channels[1], kernels[0], momentum=mom, epsilon=eps, squeeze=True)\n",
        "        self.conv2 = BlockFCNConv(channels[1], channels[2], kernels[1], momentum=mom, epsilon=eps, squeeze=True)\n",
        "        self.conv3 = BlockFCNConv(channels[2], channels[3], kernels[2], momentum=mom, epsilon=eps)\n",
        "        output_size = time_steps - sum(kernels) + len(kernels)\n",
        "        self.global_pooling = nn.AvgPool1d(kernel_size=output_size)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        # apply Global Average Pooling 1D\n",
        "        y = self.global_pooling(x)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mFYGCNCqPQfq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM-FCN"
      ]
    },
    {
      "metadata": {
        "id": "QQznEOKCKygx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LSTMFCN(nn.Module):\n",
        "    def __init__(self, time_steps, num_variables=1, lstm_hs=256, channels=[1, 128, 256, 128]):\n",
        "        super().__init__()\n",
        "        self.lstm_block = BlockLSTM(time_steps, 1, lstm_hs)\n",
        "        self.fcn_block = BlockFCN(time_steps)\n",
        "        self.dense = nn.Linear(channels[-1] + lstm_hs, num_variables)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "    def forward(self, x):\n",
        "        # input is (batch_size, time_steps), it has to be (batch_size, 1, time_steps)\n",
        "        x = x.unsqueeze(1)\n",
        "        # pass input through LSTM block\n",
        "        x1 = self.lstm_block(x)\n",
        "        x1 = torch.squeeze(x1)\n",
        "        # pass input through FCN block\n",
        "        x2 = self.fcn_block(x)\n",
        "        x2 = torch.squeeze(x2)\n",
        "        # concatenate blocks output\n",
        "        x = torch.cat([x1, x2], 1)\n",
        "        # pass through Linear layer\n",
        "        x = self.dense(x)\n",
        "        #x = torch.squeeze(x)\n",
        "        # pass through Softmax activation\n",
        "        y = self.softmax(x)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZXyATnq7WOKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "BCHDSTVzRKGR",
        "colab_type": "code",
        "outputId": "39617bc5-ab60-4979-93a5-c34357b0d514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "time_steps = X_train.shape[1]\n",
        "num_variables = classes\n",
        "\n",
        "time_steps, num_variables"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "metadata": {
        "id": "i9eJ3zlrWV7A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = LSTMFCN(time_steps, num_variables).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b27y39-dh0Ik",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "look at the different blocks of the Model"
      ]
    },
    {
      "metadata": {
        "id": "i0c4x4NViexX",
        "colab_type": "code",
        "outputId": "008682a8-0106-49b7-de5d-4f685696ae3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "# model summary\n",
        "for m in model.children():\n",
        "    print(m.training)#, m)\n",
        "    for j in m.children():\n",
        "        print(j.training, j)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True LSTM(512, 256)\n",
            "True Dropout(p=0.8)\n",
            "True\n",
            "True BlockFCNConv(\n",
            "  (conv): Conv1d(1, 128, kernel_size=(8,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "True BlockFCNConv(\n",
            "  (conv): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(256, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "True BlockFCNConv(\n",
            "  (conv): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "True AvgPool1d(kernel_size=(499,), stride=(499,), padding=(0,))\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xeWqQhn9XPUU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "look at the parameters (i.e. weights) in each layer"
      ]
    },
    {
      "metadata": {
        "id": "-F4_pcUqW8He",
        "colab_type": "code",
        "outputId": "5aac9521-d804-4056-d98e-c4c97e95f7b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "[p.shape for p in model.parameters()]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([1024, 512]),\n",
              " torch.Size([1024, 256]),\n",
              " torch.Size([1024]),\n",
              " torch.Size([1024]),\n",
              " torch.Size([128, 1, 8]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([256, 128, 5]),\n",
              " torch.Size([256]),\n",
              " torch.Size([256]),\n",
              " torch.Size([256]),\n",
              " torch.Size([128, 256, 3]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([128]),\n",
              " torch.Size([2, 384]),\n",
              " torch.Size([2])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "metadata": {
        "id": "vUO4oNKkxAYs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define a learner class to automate the learning process"
      ]
    },
    {
      "metadata": {
        "id": "RnEiGUWHw_kX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SimpleLearner():\n",
        "    def __init__(self, data, model, loss_func, wd = 1e-5):\n",
        "        self.data, self.model, self.loss_func = data, model, loss_func\n",
        "        self.wd = wd\n",
        "        \n",
        "    def update(self, x,y,lr):\n",
        "        y_hat = model(x)\n",
        "        # weight decay\n",
        "        w2 = 0.\n",
        "        for p in model.parameters(): w2 += (p**2).sum()\n",
        "        # add to regular loss\n",
        "        loss = loss_func(y_hat, y) + w2 * self.wd\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            for p in model.parameters():\n",
        "                p.sub_(lr * p.grad)\n",
        "                p.grad.zero_()\n",
        "        return loss.item()\n",
        "\n",
        "    def fit(self, epochs=1, lr=1e-3):\n",
        "        history = {\n",
        "            'losses'  : [],\n",
        "            'accuracy': []\n",
        "        }\n",
        "        for i in tqdm(range(epochs)):\n",
        "            losses = []\n",
        "            for x,y in self.data[0]:\n",
        "                losses.append(self.update(x, y , lr))\n",
        "            history['losses'].append(np.mean(losses))\n",
        "        return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "txh5ujbKXhuz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "train the model using the DataLoader"
      ]
    },
    {
      "metadata": {
        "id": "GMAfJH9KAY0h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_func = nn.BCEWithLogitsLoss().cuda()\n",
        "def acc_func(pred, real):\n",
        "    return np.mean(torch.abs(pred-real))\n",
        "    #return torch.mean(torch.tensor(torch.abs(torch.sign(pred)/2 + .5 - targ) < .01, dtype=torch.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xxVx2A1pXtuY",
        "colab_type": "code",
        "outputId": "6f252606-8541-4eff-8fb8-a643c04fcc0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "lr = 2e-2\n",
        "learner = SimpleLearner([train_dl, test_dl], model, loss_func)\n",
        "history = learner.fit(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  3.61it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4W1s1mql_ELt",
        "colab_type": "code",
        "outputId": "daa2bb67-67ec-4d93-926f-3cf7e6e1ebd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history['losses'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f77429e3da0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD4CAYAAAD2FnFTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIIwxxgzJAoQxxpghWYAwxhgzpP8HAOvoyN6LCyUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f77427a8d30>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IDwkjDH5rXCy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = DataBunch(train_dl=train_dl, valid_dl=test_dl, path=path)\n",
        "learner = Learner(data, model, loss_func=loss_func, metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jhv_-NkEknVO",
        "colab_type": "code",
        "outputId": "9f3d7333-17db-40ab-f428-6eac5b180d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        }
      },
      "cell_type": "code",
      "source": [
        "learner.unfreeze()\n",
        "learner.lr_find()\n",
        "learner.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "        \t/* Turns off some styling */\n",
              "        \tprogress {\n",
              "\n",
              "            \t/* gets rid of default border in Firefox and Opera. */\n",
              "            \tborder: none;\n",
              "\n",
              "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "            \tbackground-size: auto;\n",
              "            }\n",
              "\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='17', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      94.12% [16/17 00:04<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>0.974544</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>2</th>\n",
              "    <th>0.974463</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>3</th>\n",
              "    <th>0.974460</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>4</th>\n",
              "    <th>0.974489</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>5</th>\n",
              "    <th>0.974473</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>6</th>\n",
              "    <th>0.974466</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>7</th>\n",
              "    <th>0.974479</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>8</th>\n",
              "    <th>0.974456</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>9</th>\n",
              "    <th>0.974496</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>10</th>\n",
              "    <th>0.974470</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>11</th>\n",
              "    <th>0.974444</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>12</th>\n",
              "    <th>0.974813</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>13</th>\n",
              "    <th>0.976081</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>14</th>\n",
              "    <th>0.979188</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>15</th>\n",
              "    <th>0.982189</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>16</th>\n",
              "    <th>0.984921</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "\n",
              "  </tr>\n",
              "</table>\n",
              "\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "        \t/* Turns off some styling */\n",
              "        \tprogress {\n",
              "\n",
              "            \t/* gets rid of default border in Firefox and Opera. */\n",
              "            \tborder: none;\n",
              "\n",
              "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "            \tbackground-size: auto;\n",
              "            }\n",
              "\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='6', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7743342d68>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Lex4Hkn078kn",
        "colab_type": "code",
        "outputId": "c659af8a-9488-42a3-fbc2-5a5de3bbafdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1310
        }
      },
      "cell_type": "code",
      "source": [
        "learner.fit(10, lr=5e-5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "        \t/* Turns off some styling */\n",
              "        \tprogress {\n",
              "\n",
              "            \t/* gets rid of default border in Firefox and Opera. */\n",
              "            \tborder: none;\n",
              "\n",
              "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "            \tbackground-size: auto;\n",
              "            }\n",
              "\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/10 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "\n",
              "  </tr>\n",
              "</table>\n",
              "\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "        \t/* Turns off some styling */\n",
              "        \tprogress {\n",
              "\n",
              "            \t/* gets rid of default border in Firefox and Opera. */\n",
              "            \tborder: none;\n",
              "\n",
              "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "            \tbackground-size: auto;\n",
              "            }\n",
              "\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='3', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-196-b5d89f36ce92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 162\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, data, callbacks, metrics)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, data, callbacks, metrics)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'valid_dl'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_dl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 val_loss = validate(model, data.valid_dl, loss_func=loss_func,\n\u001b[0;32m---> 89\u001b[0;31m                                        cb_handler=cb_handler, pbar=pbar)\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dl, loss_func, cb_handler, pbar, average, n_batch)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mnums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_batch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/callback.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;34m\"Handle end of processing one batch with `loss`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/callback.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name, call_mets, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;34m\"Call through to all of the `CallbakHandler` functions.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'on_{cb_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'on_{cb_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/callback.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;34m\"Call through to all of the `CallbakHandler` functions.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'on_{cb_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'on_{cb_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/callback.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, last_output, last_target, train, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlast_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_target\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlast_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlast_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlast_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/metrics.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(input, targs)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0merror_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mRank0Tensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'other'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "nwkS7lQ6Nbq8",
        "colab_type": "code",
        "outputId": "5fcccc7e-080a-430a-ddfa-eb2d813a9789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "data = DataBunch(train_dl=train_dl, valid_dl=test_dl, path=path)\n",
        "learner = Learner(data, model, loss_func=loss_func)\n",
        "learner.fit(10, lr=5e-5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time: 00:03\n",
            "epoch  train_loss  valid_loss\n",
            "1      0.974383    0.974143    (00:00)\n",
            "2      0.974460    0.974143    (00:00)\n",
            "3      0.974481    0.974153    (00:00)\n",
            "4      0.974469    0.974150    (00:00)\n",
            "5      0.974465    0.974148    (00:00)\n",
            "6      0.974442    0.974144    (00:00)\n",
            "7      0.974427    0.974139    (00:00)\n",
            "8      0.974423    0.974138    (00:00)\n",
            "9      0.974426    0.974142    (00:00)\n",
            "10     0.974412    0.974140    (00:00)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b8Pcr02Khxsy",
        "colab_type": "code",
        "outputId": "98458daf-410f-46f6-b3c0-994b68013b32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "model.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMFCN(\n",
              "  (lstm_block): BlockLSTM(\n",
              "    (lstm): LSTM(512, 256)\n",
              "    (dropout): Dropout(p=0.8)\n",
              "  )\n",
              "  (fcn_block): BlockFCN(\n",
              "    (conv1): BlockFCNConv(\n",
              "      (conv): Conv1d(1, 128, kernel_size=(8,), stride=(1,))\n",
              "      (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (conv2): BlockFCNConv(\n",
              "      (conv): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
              "      (batch_norm): BatchNorm1d(256, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (conv3): BlockFCNConv(\n",
              "      (conv): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
              "      (batch_norm): BatchNorm1d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (global_pooling): AvgPool1d(kernel_size=(499,), stride=(499,), padding=(0,))\n",
              "  )\n",
              "  (dense): Linear(in_features=384, out_features=1, bias=True)\n",
              "  (softmax): Softmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    }
  ]
}